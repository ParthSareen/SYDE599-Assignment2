C:\Users\Ahmad\Desktop\fourth_year\SYDE599\SYDE599-Assignment2\venv\Scripts\python.exe C:/Users/Ahmad/Desktop/fourth_year/SYDE599/SYDE599-Assignment2/optuna_optimizer.py
[I 2022-11-03 23:42:41,126] A new study created in memory with name: no-name-e77887e4-2fbc-4a29-8cc1-f4e7d0a8aab8
params: {'num_conv1_channels': 16, 'num_conv2_channels': 64, 'conv2_drop': 0.14177364719522603, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 9.072409918779937e-05}
C:\Users\Ahmad\Desktop\fourth_year\SYDE599\SYDE599-Assignment2\optuna_optimizer.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
Epoch: 0 0/60000 Training loss: 2.297625
Epoch: 0 10000/60000 Training loss: 0.987657
Epoch: 0 20000/60000 Training loss: 0.626200
Epoch: 0 30000/60000 Training loss: 0.302368
Epoch: 0 40000/60000 Training loss: 0.269389
Epoch: 0 50000/60000 Training loss: 0.266665
Training loss: 0.649515
Test loss: 0.169480; Test accuracy: 9504/10000 (95.0%)

Epoch: 1 0/60000 Training loss: 0.250783
Epoch: 1 10000/60000 Training loss: 0.385695
Epoch: 1 20000/60000 Training loss: 0.201737
Epoch: 1 30000/60000 Training loss: 0.129498
Epoch: 1 40000/60000 Training loss: 0.098029
Epoch: 1 50000/60000 Training loss: 0.186004
Training loss: 0.201945
Test loss: 0.099009; Test accuracy: 9695/10000 (96.9%)

Epoch: 2 0/60000 Training loss: 0.170486
Epoch: 2 10000/60000 Training loss: 0.230546
Epoch: 2 20000/60000 Training loss: 0.123426
Epoch: 2 30000/60000 Training loss: 0.150134
Epoch: 2 40000/60000 Training loss: 0.164212
Epoch: 2 50000/60000 Training loss: 0.110776
Training loss: 0.139959
Test loss: 0.080357; Test accuracy: 9764/10000 (97.6%)

Epoch: 3 0/60000 Training loss: 0.136347
Epoch: 3 10000/60000 Training loss: 0.105128
Epoch: 3 20000/60000 Training loss: 0.212521
Epoch: 3 30000/60000 Training loss: 0.151345
Epoch: 3 40000/60000 Training loss: 0.078952
Epoch: 3 50000/60000 Training loss: 0.080390
Training loss: 0.113033
Test loss: 0.062104; Test accuracy: 9796/10000 (98.0%)

Epoch: 4 0/60000 Training loss: 0.077170
Epoch: 4 10000/60000 Training loss: 0.162538
Epoch: 4 20000/60000 Training loss: 0.057244
Epoch: 4 30000/60000 Training loss: 0.072691
Epoch: 4 40000/60000 Training loss: 0.115455
Epoch: 4 50000/60000 Training loss: 0.091812
Training loss: 0.095157
Test loss: 0.050207; Test accuracy: 9838/10000 (98.4%)

Epoch: 5 0/60000 Training loss: 0.038366
Epoch: 5 10000/60000 Training loss: 0.046764
Epoch: 5 20000/60000 Training loss: 0.086375
Epoch: 5 30000/60000 Training loss: 0.152029
Epoch: 5 40000/60000 Training loss: 0.043590
Epoch: 5 50000/60000 Training loss: 0.081658
Training loss: 0.082470
Test loss: 0.048158; Test accuracy: 9850/10000 (98.5%)

Epoch: 6 0/60000 Training loss: 0.089364
Epoch: 6 10000/60000 Training loss: 0.068426
Epoch: 6 20000/60000 Training loss: 0.077041
Epoch: 6 30000/60000 Training loss: 0.042431
Epoch: 6 40000/60000 Training loss: 0.059029
Epoch: 6 50000/60000 Training loss: 0.022765
Training loss: 0.074640
Test loss: 0.039369; Test accuracy: 9864/10000 (98.6%)

Epoch: 7 0/60000 Training loss: 0.041815
Epoch: 7 10000/60000 Training loss: 0.022319
Epoch: 7 20000/60000 Training loss: 0.057703
Epoch: 7 30000/60000 Training loss: 0.020690
Epoch: 7 40000/60000 Training loss: 0.018798
Epoch: 7 50000/60000 Training loss: 0.052466
Training loss: 0.067561
Test loss: 0.037844; Test accuracy: 9875/10000 (98.8%)

Epoch: 8 0/60000 Training loss: 0.041063
Epoch: 8 10000/60000 Training loss: 0.109833
Epoch: 8 20000/60000 Training loss: 0.054362
Epoch: 8 30000/60000 Training loss: 0.036105
Epoch: 8 40000/60000 Training loss: 0.019762
Epoch: 8 50000/60000 Training loss: 0.054542
Training loss: 0.061173
Test loss: 0.034397; Test accuracy: 9886/10000 (98.9%)

Epoch: 9 0/60000 Training loss: 0.085256
Epoch: 9 10000/60000 Training loss: 0.033854
Epoch: 9 20000/60000 Training loss: 0.077698
Epoch: 9 30000/60000 Training loss: 0.034756
Epoch: 9 40000/60000 Training loss: 0.060127
Epoch: 9 50000/60000 Training loss: 0.022728
Training loss: 0.057049
Test loss: 0.033525; Test accuracy: 9893/10000 (98.9%)

Epoch: 10 0/60000 Training loss: 0.024977
Epoch: 10 10000/60000 Training loss: 0.052404
Epoch: 10 20000/60000 Training loss: 0.057448
Epoch: 10 30000/60000 Training loss: 0.076571
Epoch: 10 40000/60000 Training loss: 0.042533
Epoch: 10 50000/60000 Training loss: 0.059021
Training loss: 0.051338
Test loss: 0.030668; Test accuracy: 9899/10000 (99.0%)

Epoch: 11 0/60000 Training loss: 0.061801
Epoch: 11 10000/60000 Training loss: 0.049670
Epoch: 11 20000/60000 Training loss: 0.045521
Epoch: 11 30000/60000 Training loss: 0.055520
Epoch: 11 40000/60000 Training loss: 0.081557
Epoch: 11 50000/60000 Training loss: 0.046697
Training loss: 0.048606
Test loss: 0.030357; Test accuracy: 9897/10000 (99.0%)

Epoch: 12 0/60000 Training loss: 0.050932
Epoch: 12 10000/60000 Training loss: 0.033135
Epoch: 12 20000/60000 Training loss: 0.087837
Epoch: 12 30000/60000 Training loss: 0.011349
Epoch: 12 40000/60000 Training loss: 0.035939
Epoch: 12 50000/60000 Training loss: 0.090502
Training loss: 0.046510
Test loss: 0.028956; Test accuracy: 9910/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.013823
Epoch: 13 10000/60000 Training loss: 0.046660
Epoch: 13 20000/60000 Training loss: 0.062233
Epoch: 13 30000/60000 Training loss: 0.020746
Epoch: 13 40000/60000 Training loss: 0.012985
Epoch: 13 50000/60000 Training loss: 0.024916
Training loss: 0.042299
Test loss: 0.027700; Test accuracy: 9904/10000 (99.0%)

Epoch: 14 0/60000 Training loss: 0.006972
Epoch: 14 10000/60000 Training loss: 0.119418
Epoch: 14 20000/60000 Training loss: 0.033103
Epoch: 14 30000/60000 Training loss: 0.040657
Epoch: 14 40000/60000 Training loss: 0.019353
Epoch: 14 50000/60000 Training loss: 0.024686
Training loss: 0.041159
Test loss: 0.026173; Test accuracy: 9902/10000 (99.0%)

Epoch: 15 0/60000 Training loss: 0.022351
Epoch: 15 10000/60000 Training loss: 0.064524
Epoch: 15 20000/60000 Training loss: 0.031094
Epoch: 15 30000/60000 Training loss: 0.009832
Epoch: 15 40000/60000 Training loss: 0.029513
Epoch: 15 50000/60000 Training loss: 0.047299
Training loss: 0.037278
Test loss: 0.024916; Test accuracy: 9917/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.028391
Epoch: 16 10000/60000 Training loss: 0.044779
Epoch: 16 20000/60000 Training loss: 0.020230
Epoch: 16 30000/60000 Training loss: 0.022863
Epoch: 16 40000/60000 Training loss: 0.042831
Epoch: 16 50000/60000 Training loss: 0.011665
Training loss: 0.035445
Test loss: 0.025089; Test accuracy: 9911/10000 (99.1%)

Epoch: 17 0/60000 Training loss: 0.037849
Epoch: 17 10000/60000 Training loss: 0.022415
Epoch: 17 20000/60000 Training loss: 0.043956
Epoch: 17 30000/60000 Training loss: 0.023688
Epoch: 17 40000/60000 Training loss: 0.016517
Epoch: 17 50000/60000 Training loss: 0.004361
Training loss: 0.035047
Test loss: 0.024770; Test accuracy: 9913/10000 (99.1%)

Epoch: 18 0/60000 Training loss: 0.035070
Epoch: 18 10000/60000 Training loss: 0.011181
Epoch: 18 20000/60000 Training loss: 0.037645
Epoch: 18 30000/60000 Training loss: 0.075496
Epoch: 18 40000/60000 Training loss: 0.054573
Epoch: 18 50000/60000 Training loss: 0.003524
Training loss: 0.031968
Test loss: 0.023241; Test accuracy: 9920/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.014829
Epoch: 19 10000/60000 Training loss: 0.024226
Epoch: 19 20000/60000 Training loss: 0.058396
Epoch: 19 30000/60000 Training loss: 0.059471
Epoch: 19 40000/60000 Training loss: 0.054624
Epoch: 19 50000/60000 Training loss: 0.004543
Training loss: 0.031493
Test loss: 0.022439; Test accuracy: 9921/10000 (99.2%)

[I 2022-11-03 23:48:02,598] Trial 0 finished with value: 0.022439127787947655 and parameters: {'num_conv1_channels': 16, 'num_conv2_channels': 64, 'conv2_drop': 0.14177364719522603, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 9.072409918779937e-05}. Best is trial 0 with value: 0.022439127787947655.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.1854855090716555, 'fc1_neurons': 10, 'optimizer': 'Adam', 'learning_rate': 0.00012405720627910386}
Epoch: 0 0/60000 Training loss: 2.306152
Epoch: 0 10000/60000 Training loss: 1.651620
Epoch: 0 20000/60000 Training loss: 1.472554
Epoch: 0 30000/60000 Training loss: 1.204416
Epoch: 0 40000/60000 Training loss: 1.102625
Epoch: 0 50000/60000 Training loss: 1.252687
Training loss: 1.342513
Test loss: 0.403461; Test accuracy: 9449/10000 (94.5%)

Epoch: 1 0/60000 Training loss: 1.009518
Epoch: 1 10000/60000 Training loss: 0.951353
Epoch: 1 20000/60000 Training loss: 0.892342
Epoch: 1 30000/60000 Training loss: 1.154377
Epoch: 1 40000/60000 Training loss: 1.047525
Epoch: 1 50000/60000 Training loss: 0.829663
Training loss: 0.954518
Test loss: 0.200068; Test accuracy: 9679/10000 (96.8%)

Epoch: 2 0/60000 Training loss: 1.064164
Epoch: 2 10000/60000 Training loss: 0.840556
Epoch: 2 20000/60000 Training loss: 0.875124
Epoch: 2 30000/60000 Training loss: 0.960051
Epoch: 2 40000/60000 Training loss: 0.784132
Epoch: 2 50000/60000 Training loss: 0.861872
Training loss: 0.842290
Test loss: 0.137548; Test accuracy: 9763/10000 (97.6%)

Epoch: 3 0/60000 Training loss: 0.720012
Epoch: 3 10000/60000 Training loss: 0.787241
Epoch: 3 20000/60000 Training loss: 0.746780
Epoch: 3 30000/60000 Training loss: 0.710148
Epoch: 3 40000/60000 Training loss: 0.733861
Epoch: 3 50000/60000 Training loss: 0.814698
Training loss: 0.768001
Test loss: 0.107696; Test accuracy: 9789/10000 (97.9%)

Epoch: 4 0/60000 Training loss: 0.727468
Epoch: 4 10000/60000 Training loss: 0.692747
Epoch: 4 20000/60000 Training loss: 0.571374
Epoch: 4 30000/60000 Training loss: 0.719685
Epoch: 4 40000/60000 Training loss: 0.757189
Epoch: 4 50000/60000 Training loss: 0.607276
Training loss: 0.738204
Test loss: 0.087370; Test accuracy: 9821/10000 (98.2%)

Epoch: 5 0/60000 Training loss: 0.659504
Epoch: 5 10000/60000 Training loss: 0.729491
Epoch: 5 20000/60000 Training loss: 0.732039
Epoch: 5 30000/60000 Training loss: 0.824478
Epoch: 5 40000/60000 Training loss: 0.751300
Epoch: 5 50000/60000 Training loss: 0.715704
Training loss: 0.723619
Test loss: 0.088211; Test accuracy: 9810/10000 (98.1%)

Epoch: 6 0/60000 Training loss: 0.717384
Epoch: 6 10000/60000 Training loss: 0.576577
Epoch: 6 20000/60000 Training loss: 0.728897
Epoch: 6 30000/60000 Training loss: 0.605846
Epoch: 6 40000/60000 Training loss: 0.762382
Epoch: 6 50000/60000 Training loss: 0.739132
Training loss: 0.709988
Test loss: 0.078492; Test accuracy: 9828/10000 (98.3%)

Epoch: 7 0/60000 Training loss: 0.543160
Epoch: 7 10000/60000 Training loss: 0.640052
Epoch: 7 20000/60000 Training loss: 0.854027
Epoch: 7 30000/60000 Training loss: 0.666934
Epoch: 7 40000/60000 Training loss: 0.649229
Epoch: 7 50000/60000 Training loss: 0.584751
Training loss: 0.687555
Test loss: 0.069097; Test accuracy: 9842/10000 (98.4%)

Epoch: 8 0/60000 Training loss: 0.756481
Epoch: 8 10000/60000 Training loss: 0.677820
Epoch: 8 20000/60000 Training loss: 0.565991
Epoch: 8 30000/60000 Training loss: 0.695658
Epoch: 8 40000/60000 Training loss: 0.492861
Epoch: 8 50000/60000 Training loss: 0.743153
Training loss: 0.671788
Test loss: 0.061496; Test accuracy: 9853/10000 (98.5%)

Epoch: 9 0/60000 Training loss: 0.560243
Epoch: 9 10000/60000 Training loss: 0.576927
Epoch: 9 20000/60000 Training loss: 0.613934
Epoch: 9 30000/60000 Training loss: 0.693114
Epoch: 9 40000/60000 Training loss: 0.668364
Epoch: 9 50000/60000 Training loss: 0.706367
Training loss: 0.664732
Test loss: 0.061826; Test accuracy: 9854/10000 (98.5%)

Epoch: 10 0/60000 Training loss: 0.533915
Epoch: 10 10000/60000 Training loss: 0.605469
Epoch: 10 20000/60000 Training loss: 0.640329
Epoch: 10 30000/60000 Training loss: 0.566800
Epoch: 10 40000/60000 Training loss: 0.686872
Epoch: 10 50000/60000 Training loss: 0.622152
Training loss: 0.662790
Test loss: 0.056387; Test accuracy: 9877/10000 (98.8%)

Epoch: 11 0/60000 Training loss: 0.708477
Epoch: 11 10000/60000 Training loss: 0.725058
Epoch: 11 20000/60000 Training loss: 0.690093
Epoch: 11 30000/60000 Training loss: 0.547798
Epoch: 11 40000/60000 Training loss: 0.776961
Epoch: 11 50000/60000 Training loss: 0.689692
Training loss: 0.653808
Test loss: 0.058563; Test accuracy: 9866/10000 (98.7%)

Epoch: 12 0/60000 Training loss: 0.622987
Epoch: 12 10000/60000 Training loss: 0.588250
Epoch: 12 20000/60000 Training loss: 0.599969
Epoch: 12 30000/60000 Training loss: 0.682086
Epoch: 12 40000/60000 Training loss: 0.669178
Epoch: 12 50000/60000 Training loss: 0.628165
Training loss: 0.638072
Test loss: 0.056686; Test accuracy: 9865/10000 (98.6%)

Epoch: 13 0/60000 Training loss: 0.694440
Epoch: 13 10000/60000 Training loss: 0.694254
Epoch: 13 20000/60000 Training loss: 0.617783
Epoch: 13 30000/60000 Training loss: 0.667697
Epoch: 13 40000/60000 Training loss: 0.706403
Epoch: 13 50000/60000 Training loss: 0.648638
Training loss: 0.635601
Test loss: 0.053536; Test accuracy: 9880/10000 (98.8%)

Epoch: 14 0/60000 Training loss: 0.681797
Epoch: 14 10000/60000 Training loss: 0.683386
Epoch: 14 20000/60000 Training loss: 0.595144
Epoch: 14 30000/60000 Training loss: 0.590367
Epoch: 14 40000/60000 Training loss: 0.720653
Epoch: 14 50000/60000 Training loss: 0.537423
Training loss: 0.625686
Test loss: 0.052557; Test accuracy: 9880/10000 (98.8%)

Epoch: 15 0/60000 Training loss: 0.781055
Epoch: 15 10000/60000 Training loss: 0.751241
Epoch: 15 20000/60000 Training loss: 0.698138
Epoch: 15 30000/60000 Training loss: 0.676274
Epoch: 15 40000/60000 Training loss: 0.613572
Epoch: 15 50000/60000 Training loss: 0.649166
Training loss: 0.624652
Test loss: 0.049155; Test accuracy: 9887/10000 (98.9%)

Epoch: 16 0/60000 Training loss: 0.683517
Epoch: 16 10000/60000 Training loss: 0.762651
Epoch: 16 20000/60000 Training loss: 0.617956
Epoch: 16 30000/60000 Training loss: 0.644106
Epoch: 16 40000/60000 Training loss: 0.782963
Epoch: 16 50000/60000 Training loss: 0.680372
Training loss: 0.611680
Test loss: 0.047596; Test accuracy: 9884/10000 (98.8%)

Epoch: 17 0/60000 Training loss: 0.755928
Epoch: 17 10000/60000 Training loss: 0.661422
Epoch: 17 20000/60000 Training loss: 0.584019
Epoch: 17 30000/60000 Training loss: 0.579882
Epoch: 17 40000/60000 Training loss: 0.530650
Epoch: 17 50000/60000 Training loss: 0.559639
Training loss: 0.610015
Test loss: 0.053540; Test accuracy: 9884/10000 (98.8%)

Epoch: 18 0/60000 Training loss: 0.528487
Epoch: 18 10000/60000 Training loss: 0.680463
Epoch: 18 20000/60000 Training loss: 0.622783
Epoch: 18 30000/60000 Training loss: 0.666492
Epoch: 18 40000/60000 Training loss: 0.575752
Epoch: 18 50000/60000 Training loss: 0.616308
Training loss: 0.605312
Test loss: 0.051321; Test accuracy: 9881/10000 (98.8%)

Epoch: 19 0/60000 Training loss: 0.661853
Epoch: 19 10000/60000 Training loss: 0.504599
Epoch: 19 20000/60000 Training loss: 0.575508
Epoch: 19 30000/60000 Training loss: 0.587734
Epoch: 19 40000/60000 Training loss: 0.676167
Epoch: 19 50000/60000 Training loss: 0.629212
Training loss: 0.605737
Test loss: 0.045745; Test accuracy: 9891/10000 (98.9%)

[I 2022-11-03 23:52:49,710] Trial 1 finished with value: 0.0457451269030571 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.1854855090716555, 'fc1_neurons': 10, 'optimizer': 'Adam', 'learning_rate': 0.00012405720627910386}. Best is trial 0 with value: 0.022439127787947655.
params: {'num_conv1_channels': 32, 'num_conv2_channels': 32, 'conv2_drop': 0.11065850432301373, 'fc1_neurons': 200, 'optimizer': 'SGD', 'learning_rate': 2.868311954678917e-05}
Epoch: 0 0/60000 Training loss: 2.316022
Epoch: 0 10000/60000 Training loss: 2.326878
Epoch: 0 20000/60000 Training loss: 2.328143
Epoch: 0 30000/60000 Training loss: 2.321661
Epoch: 0 40000/60000 Training loss: 2.334260
Epoch: 0 50000/60000 Training loss: 2.311817
Training loss: 2.324265
Test loss: 2.317327; Test accuracy: 969/10000 (9.7%)

Epoch: 1 0/60000 Training loss: 2.316949
Epoch: 1 10000/60000 Training loss: 2.343796
Epoch: 1 20000/60000 Training loss: 2.330715
Epoch: 1 30000/60000 Training loss: 2.319714
Epoch: 1 40000/60000 Training loss: 2.319187
Epoch: 1 50000/60000 Training loss: 2.318776
Training loss: 2.319182
Test loss: 2.311946; Test accuracy: 983/10000 (9.8%)

Epoch: 2 0/60000 Training loss: 2.314158
Epoch: 2 10000/60000 Training loss: 2.316864
Epoch: 2 20000/60000 Training loss: 2.319137
Epoch: 2 30000/60000 Training loss: 2.311403
Epoch: 2 40000/60000 Training loss: 2.297829
Epoch: 2 50000/60000 Training loss: 2.335492
Training loss: 2.313116
Test loss: 2.306840; Test accuracy: 1004/10000 (10.0%)

Epoch: 3 0/60000 Training loss: 2.324328
Epoch: 3 10000/60000 Training loss: 2.309918
Epoch: 3 20000/60000 Training loss: 2.332742
Epoch: 3 30000/60000 Training loss: 2.312418
Epoch: 3 40000/60000 Training loss: 2.311555
Epoch: 3 50000/60000 Training loss: 2.294609
Training loss: 2.309598
Test loss: 2.301934; Test accuracy: 1039/10000 (10.4%)

Epoch: 4 0/60000 Training loss: 2.313977
Epoch: 4 10000/60000 Training loss: 2.304584
Epoch: 4 20000/60000 Training loss: 2.316976
Epoch: 4 30000/60000 Training loss: 2.293800
Epoch: 4 40000/60000 Training loss: 2.302346
Epoch: 4 50000/60000 Training loss: 2.295227
Training loss: 2.303758
Test loss: 2.297245; Test accuracy: 1088/10000 (10.9%)

Epoch: 5 0/60000 Training loss: 2.275366
Epoch: 5 10000/60000 Training loss: 2.263322
Epoch: 5 20000/60000 Training loss: 2.313487
Epoch: 5 30000/60000 Training loss: 2.304717
Epoch: 5 40000/60000 Training loss: 2.321052
Epoch: 5 50000/60000 Training loss: 2.299864
Training loss: 2.300086
Test loss: 2.292744; Test accuracy: 1161/10000 (11.6%)

Epoch: 6 0/60000 Training loss: 2.276592
Epoch: 6 10000/60000 Training loss: 2.314902
Epoch: 6 20000/60000 Training loss: 2.307210
Epoch: 6 30000/60000 Training loss: 2.284386
Epoch: 6 40000/60000 Training loss: 2.295269
Epoch: 6 50000/60000 Training loss: 2.308682
Training loss: 2.295720
Test loss: 2.288388; Test accuracy: 1266/10000 (12.7%)

Epoch: 7 0/60000 Training loss: 2.275468
Epoch: 7 10000/60000 Training loss: 2.290868
Epoch: 7 20000/60000 Training loss: 2.277344
Epoch: 7 30000/60000 Training loss: 2.273256
Epoch: 7 40000/60000 Training loss: 2.304675
Epoch: 7 50000/60000 Training loss: 2.286321
Training loss: 2.292016
Test loss: 2.284165; Test accuracy: 1387/10000 (13.9%)

Epoch: 8 0/60000 Training loss: 2.283508
Epoch: 8 10000/60000 Training loss: 2.301314
Epoch: 8 20000/60000 Training loss: 2.268524
Epoch: 8 30000/60000 Training loss: 2.301401
Epoch: 8 40000/60000 Training loss: 2.289156
Epoch: 8 50000/60000 Training loss: 2.283095
Training loss: 2.287457
Test loss: 2.280041; Test accuracy: 1557/10000 (15.6%)

Epoch: 9 0/60000 Training loss: 2.285371
Epoch: 9 10000/60000 Training loss: 2.281552
Epoch: 9 20000/60000 Training loss: 2.271936
Epoch: 9 30000/60000 Training loss: 2.285377
Epoch: 9 40000/60000 Training loss: 2.286359
Epoch: 9 50000/60000 Training loss: 2.293337
Training loss: 2.284395
Test loss: 2.275965; Test accuracy: 1769/10000 (17.7%)

Epoch: 10 0/60000 Training loss: 2.300703
Epoch: 10 10000/60000 Training loss: 2.318498
Epoch: 10 20000/60000 Training loss: 2.287432
Epoch: 10 30000/60000 Training loss: 2.276525
Epoch: 10 40000/60000 Training loss: 2.267420
Epoch: 10 50000/60000 Training loss: 2.278706
Training loss: 2.279841
Test loss: 2.271945; Test accuracy: 2006/10000 (20.1%)

Epoch: 11 0/60000 Training loss: 2.270644
Epoch: 11 10000/60000 Training loss: 2.270003
Epoch: 11 20000/60000 Training loss: 2.296883
Epoch: 11 30000/60000 Training loss: 2.267486
Epoch: 11 40000/60000 Training loss: 2.259628
Epoch: 11 50000/60000 Training loss: 2.294998
Training loss: 2.276735
Test loss: 2.267954; Test accuracy: 2266/10000 (22.7%)

Epoch: 12 0/60000 Training loss: 2.274367
Epoch: 12 10000/60000 Training loss: 2.266858
Epoch: 12 20000/60000 Training loss: 2.259494
Epoch: 12 30000/60000 Training loss: 2.252642
Epoch: 12 40000/60000 Training loss: 2.288945
Epoch: 12 50000/60000 Training loss: 2.263040
Training loss: 2.272866
Test loss: 2.263949; Test accuracy: 2528/10000 (25.3%)

Epoch: 13 0/60000 Training loss: 2.255995
Epoch: 13 10000/60000 Training loss: 2.274812
Epoch: 13 20000/60000 Training loss: 2.257535
Epoch: 13 30000/60000 Training loss: 2.244421
Epoch: 13 40000/60000 Training loss: 2.279181
Epoch: 13 50000/60000 Training loss: 2.277265
Training loss: 2.268783
Test loss: 2.259944; Test accuracy: 2791/10000 (27.9%)

Epoch: 14 0/60000 Training loss: 2.280586
Epoch: 14 10000/60000 Training loss: 2.265864
Epoch: 14 20000/60000 Training loss: 2.275377
Epoch: 14 30000/60000 Training loss: 2.271390
Epoch: 14 40000/60000 Training loss: 2.255132
Epoch: 14 50000/60000 Training loss: 2.262139
Training loss: 2.265626
Test loss: 2.255905; Test accuracy: 3058/10000 (30.6%)

Epoch: 15 0/60000 Training loss: 2.262444
Epoch: 15 10000/60000 Training loss: 2.286244
Epoch: 15 20000/60000 Training loss: 2.262024
Epoch: 15 30000/60000 Training loss: 2.259091
Epoch: 15 40000/60000 Training loss: 2.254514
Epoch: 15 50000/60000 Training loss: 2.270732
Training loss: 2.261515
Test loss: 2.251807; Test accuracy: 3322/10000 (33.2%)

Epoch: 16 0/60000 Training loss: 2.267328
Epoch: 16 10000/60000 Training loss: 2.249702
Epoch: 16 20000/60000 Training loss: 2.256052
Epoch: 16 30000/60000 Training loss: 2.266459
Epoch: 16 40000/60000 Training loss: 2.262277
Epoch: 16 50000/60000 Training loss: 2.263840
Training loss: 2.257096
Test loss: 2.247636; Test accuracy: 3569/10000 (35.7%)

Epoch: 17 0/60000 Training loss: 2.236172
Epoch: 17 10000/60000 Training loss: 2.254047
Epoch: 17 20000/60000 Training loss: 2.259175
Epoch: 17 30000/60000 Training loss: 2.261183
Epoch: 17 40000/60000 Training loss: 2.263011
Epoch: 17 50000/60000 Training loss: 2.259606
Training loss: 2.254035
Test loss: 2.243403; Test accuracy: 3867/10000 (38.7%)

Epoch: 18 0/60000 Training loss: 2.242782
Epoch: 18 10000/60000 Training loss: 2.252145
Epoch: 18 20000/60000 Training loss: 2.250176
Epoch: 18 30000/60000 Training loss: 2.264375
Epoch: 18 40000/60000 Training loss: 2.245149
Epoch: 18 50000/60000 Training loss: 2.235024
Training loss: 2.250015
Test loss: 2.239068; Test accuracy: 4077/10000 (40.8%)

Epoch: 19 0/60000 Training loss: 2.248079
Epoch: 19 10000/60000 Training loss: 2.271106
Epoch: 19 20000/60000 Training loss: 2.243553
Epoch: 19 30000/60000 Training loss: 2.241532
Epoch: 19 40000/60000 Training loss: 2.233986
Epoch: 19 50000/60000 Training loss: 2.245766
Training loss: 2.245757
Test loss: 2.234627; Test accuracy: 4313/10000 (43.1%)

[I 2022-11-03 23:57:33,283] Trial 2 finished with value: 2.2346270084381104 and parameters: {'num_conv1_channels': 32, 'num_conv2_channels': 32, 'conv2_drop': 0.11065850432301373, 'fc1_neurons': 200, 'optimizer': 'SGD', 'learning_rate': 2.868311954678917e-05}. Best is trial 0 with value: 0.022439127787947655.
params: {'num_conv1_channels': 48, 'num_conv2_channels': 128, 'conv2_drop': 0.09047097202476106, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00028335120878964165}
Epoch: 0 0/60000 Training loss: 2.288518
Epoch: 0 10000/60000 Training loss: 0.289600
Epoch: 0 20000/60000 Training loss: 0.177824
Epoch: 0 30000/60000 Training loss: 0.211486
Epoch: 0 40000/60000 Training loss: 0.112096
Epoch: 0 50000/60000 Training loss: 0.079294
Training loss: 0.253325
Test loss: 0.053771; Test accuracy: 9837/10000 (98.4%)

Epoch: 1 0/60000 Training loss: 0.029784
Epoch: 1 10000/60000 Training loss: 0.050309
Epoch: 1 20000/60000 Training loss: 0.068414
Epoch: 1 30000/60000 Training loss: 0.059821
Epoch: 1 40000/60000 Training loss: 0.118714
Epoch: 1 50000/60000 Training loss: 0.071892
Training loss: 0.076778
Test loss: 0.037280; Test accuracy: 9880/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.089251
Epoch: 2 10000/60000 Training loss: 0.086854
Epoch: 2 20000/60000 Training loss: 0.029457
Epoch: 2 30000/60000 Training loss: 0.058968
Epoch: 2 40000/60000 Training loss: 0.021440
Epoch: 2 50000/60000 Training loss: 0.040519
Training loss: 0.053843
Test loss: 0.029610; Test accuracy: 9902/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.016081
Epoch: 3 10000/60000 Training loss: 0.085039
Epoch: 3 20000/60000 Training loss: 0.022439
Epoch: 3 30000/60000 Training loss: 0.044449
Epoch: 3 40000/60000 Training loss: 0.059614
Epoch: 3 50000/60000 Training loss: 0.039975
Training loss: 0.043457
Test loss: 0.026965; Test accuracy: 9911/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.007127
Epoch: 4 10000/60000 Training loss: 0.038653
Epoch: 4 20000/60000 Training loss: 0.023051
Epoch: 4 30000/60000 Training loss: 0.017896
Epoch: 4 40000/60000 Training loss: 0.024419
Epoch: 4 50000/60000 Training loss: 0.065291
Training loss: 0.036607
Test loss: 0.021431; Test accuracy: 9921/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.109372
Epoch: 5 10000/60000 Training loss: 0.016396
Epoch: 5 20000/60000 Training loss: 0.029403
Epoch: 5 30000/60000 Training loss: 0.078589
Epoch: 5 40000/60000 Training loss: 0.046446
Epoch: 5 50000/60000 Training loss: 0.096632
Training loss: 0.030371
Test loss: 0.021226; Test accuracy: 9930/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.004162
Epoch: 6 10000/60000 Training loss: 0.043848
Epoch: 6 20000/60000 Training loss: 0.047976
Epoch: 6 30000/60000 Training loss: 0.051944
Epoch: 6 40000/60000 Training loss: 0.016787
Epoch: 6 50000/60000 Training loss: 0.016857
Training loss: 0.026694
Test loss: 0.021952; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.015694
Epoch: 7 10000/60000 Training loss: 0.009715
Epoch: 7 20000/60000 Training loss: 0.060261
Epoch: 7 30000/60000 Training loss: 0.013931
Epoch: 7 40000/60000 Training loss: 0.018790
Epoch: 7 50000/60000 Training loss: 0.026493
Training loss: 0.024636
Test loss: 0.021945; Test accuracy: 9926/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.028193
Epoch: 8 10000/60000 Training loss: 0.011637
Epoch: 8 20000/60000 Training loss: 0.001255
Epoch: 8 30000/60000 Training loss: 0.068996
Epoch: 8 40000/60000 Training loss: 0.009608
Epoch: 8 50000/60000 Training loss: 0.008675
Training loss: 0.019732
Test loss: 0.019603; Test accuracy: 9934/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.004480
Epoch: 9 10000/60000 Training loss: 0.025284
Epoch: 9 20000/60000 Training loss: 0.001558
Epoch: 9 30000/60000 Training loss: 0.004240
Epoch: 9 40000/60000 Training loss: 0.005108
Epoch: 9 50000/60000 Training loss: 0.020437
Training loss: 0.018799
Test loss: 0.019617; Test accuracy: 9931/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.001993
Epoch: 10 10000/60000 Training loss: 0.004264
Epoch: 10 20000/60000 Training loss: 0.013048
Epoch: 10 30000/60000 Training loss: 0.002943
Epoch: 10 40000/60000 Training loss: 0.018768
Epoch: 10 50000/60000 Training loss: 0.002132
Training loss: 0.015120
Test loss: 0.018985; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.008563
Epoch: 11 10000/60000 Training loss: 0.007289
Epoch: 11 20000/60000 Training loss: 0.047179
Epoch: 11 30000/60000 Training loss: 0.004933
Epoch: 11 40000/60000 Training loss: 0.017580
Epoch: 11 50000/60000 Training loss: 0.024486
Training loss: 0.016058
Test loss: 0.019348; Test accuracy: 9935/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.015961
Epoch: 12 10000/60000 Training loss: 0.017547
Epoch: 12 20000/60000 Training loss: 0.015419
Epoch: 12 30000/60000 Training loss: 0.007396
Epoch: 12 40000/60000 Training loss: 0.002389
Epoch: 12 50000/60000 Training loss: 0.001073
Training loss: 0.013275
Test loss: 0.022010; Test accuracy: 9934/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.001538
Epoch: 13 10000/60000 Training loss: 0.002047
Epoch: 13 20000/60000 Training loss: 0.001203
Epoch: 13 30000/60000 Training loss: 0.001115
Epoch: 13 40000/60000 Training loss: 0.004093
Epoch: 13 50000/60000 Training loss: 0.033053
Training loss: 0.012094
Test loss: 0.020368; Test accuracy: 9937/10000 (99.4%)

[I 2022-11-04 00:00:56,204] Trial 3 finished with value: 0.018984997645020485 and parameters: {'num_conv1_channels': 48, 'num_conv2_channels': 128, 'conv2_drop': 0.09047097202476106, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00028335120878964165}. Best is trial 3 with value: 0.018984997645020485.
params: {'num_conv1_channels': 16, 'num_conv2_channels': 128, 'conv2_drop': 0.11072937344014448, 'fc1_neurons': 10, 'optimizer': 'SGD', 'learning_rate': 0.00028776254721041576}
Epoch: 0 0/60000 Training loss: 2.275671
Epoch: 0 10000/60000 Training loss: 2.305089
Epoch: 0 20000/60000 Training loss: 2.280060
Epoch: 0 30000/60000 Training loss: 2.253114
Epoch: 0 40000/60000 Training loss: 2.290282
Epoch: 0 50000/60000 Training loss: 2.218223
Training loss: 2.276277
Test loss: 2.226170; Test accuracy: 1738/10000 (17.4%)

Epoch: 1 0/60000 Training loss: 2.239038
Epoch: 1 10000/60000 Training loss: 2.210882
Epoch: 1 20000/60000 Training loss: 2.224139
Epoch: 1 30000/60000 Training loss: 2.212237
Epoch: 1 40000/60000 Training loss: 2.205174
Epoch: 1 50000/60000 Training loss: 2.189376
Training loss: 2.205610
Test loss: 2.142343; Test accuracy: 2310/10000 (23.1%)

Epoch: 2 0/60000 Training loss: 2.112910
Epoch: 2 10000/60000 Training loss: 2.144379
Epoch: 2 20000/60000 Training loss: 2.162686
Epoch: 2 30000/60000 Training loss: 2.176630
Epoch: 2 40000/60000 Training loss: 2.159191
Epoch: 2 50000/60000 Training loss: 2.134983
Training loss: 2.138680
Test loss: 2.062957; Test accuracy: 3119/10000 (31.2%)

Epoch: 3 0/60000 Training loss: 2.038434
Epoch: 3 10000/60000 Training loss: 2.127344
Epoch: 3 20000/60000 Training loss: 2.059021
Epoch: 3 30000/60000 Training loss: 2.075583
Epoch: 3 40000/60000 Training loss: 2.053067
Epoch: 3 50000/60000 Training loss: 2.105490
Training loss: 2.074593
Test loss: 1.982280; Test accuracy: 3607/10000 (36.1%)

Epoch: 4 0/60000 Training loss: 2.005696
Epoch: 4 10000/60000 Training loss: 1.983097
Epoch: 4 20000/60000 Training loss: 2.064586
Epoch: 4 30000/60000 Training loss: 2.025808
Epoch: 4 40000/60000 Training loss: 2.040685
Epoch: 4 50000/60000 Training loss: 2.028935
Training loss: 2.013818
Test loss: 1.899409; Test accuracy: 4059/10000 (40.6%)

Epoch: 5 0/60000 Training loss: 2.037428
Epoch: 5 10000/60000 Training loss: 1.932165
Epoch: 5 20000/60000 Training loss: 1.916331
Epoch: 5 30000/60000 Training loss: 2.010575
Epoch: 5 40000/60000 Training loss: 1.897258
Epoch: 5 50000/60000 Training loss: 1.885415
Training loss: 1.952764
Test loss: 1.815250; Test accuracy: 4639/10000 (46.4%)

Epoch: 6 0/60000 Training loss: 1.958607
Epoch: 6 10000/60000 Training loss: 1.888413
Epoch: 6 20000/60000 Training loss: 1.858564
Epoch: 6 30000/60000 Training loss: 1.963585
Epoch: 6 40000/60000 Training loss: 1.838089
Epoch: 6 50000/60000 Training loss: 1.901586
Training loss: 1.887201
Test loss: 1.707486; Test accuracy: 5229/10000 (52.3%)

Epoch: 7 0/60000 Training loss: 1.835953
Epoch: 7 10000/60000 Training loss: 1.804981
Epoch: 7 20000/60000 Training loss: 1.816028
Epoch: 7 30000/60000 Training loss: 1.813984
Epoch: 7 40000/60000 Training loss: 1.898012
Epoch: 7 50000/60000 Training loss: 1.835415
Training loss: 1.825046
Test loss: 1.612230; Test accuracy: 6162/10000 (61.6%)

Epoch: 8 0/60000 Training loss: 1.735725
Epoch: 8 10000/60000 Training loss: 1.823343
Epoch: 8 20000/60000 Training loss: 1.964269
Epoch: 8 30000/60000 Training loss: 1.833631
Epoch: 8 40000/60000 Training loss: 1.808978
Epoch: 8 50000/60000 Training loss: 1.909237
Training loss: 1.764651
Test loss: 1.527406; Test accuracy: 6647/10000 (66.5%)

Epoch: 9 0/60000 Training loss: 1.716660
Epoch: 9 10000/60000 Training loss: 1.672713
Epoch: 9 20000/60000 Training loss: 1.703433
Epoch: 9 30000/60000 Training loss: 1.633650
Epoch: 9 40000/60000 Training loss: 1.746583
Epoch: 9 50000/60000 Training loss: 1.727706
Training loss: 1.716426
Test loss: 1.446873; Test accuracy: 6895/10000 (68.9%)

Epoch: 10 0/60000 Training loss: 1.663404
Epoch: 10 10000/60000 Training loss: 1.731121
Epoch: 10 20000/60000 Training loss: 1.625865
Epoch: 10 30000/60000 Training loss: 1.756470
Epoch: 10 40000/60000 Training loss: 1.546785
Epoch: 10 50000/60000 Training loss: 1.633691
Training loss: 1.669354
Test loss: 1.370875; Test accuracy: 7155/10000 (71.5%)

Epoch: 11 0/60000 Training loss: 1.634578
Epoch: 11 10000/60000 Training loss: 1.467098
Epoch: 11 20000/60000 Training loss: 1.729585
Epoch: 11 30000/60000 Training loss: 1.735926
Epoch: 11 40000/60000 Training loss: 1.537983
Epoch: 11 50000/60000 Training loss: 1.650245
Training loss: 1.630351
Test loss: 1.310921; Test accuracy: 7311/10000 (73.1%)

Epoch: 12 0/60000 Training loss: 1.607436
Epoch: 12 10000/60000 Training loss: 1.617491
Epoch: 12 20000/60000 Training loss: 1.479997
Epoch: 12 30000/60000 Training loss: 1.515113
Epoch: 12 40000/60000 Training loss: 1.558048
Epoch: 12 50000/60000 Training loss: 1.448273
Training loss: 1.592819
Test loss: 1.249415; Test accuracy: 7436/10000 (74.4%)

Epoch: 13 0/60000 Training loss: 1.557828
Epoch: 13 10000/60000 Training loss: 1.648729
Epoch: 13 20000/60000 Training loss: 1.491590
Epoch: 13 30000/60000 Training loss: 1.547684
Epoch: 13 40000/60000 Training loss: 1.554003
Epoch: 13 50000/60000 Training loss: 1.579016
Training loss: 1.560202
Test loss: 1.194538; Test accuracy: 7544/10000 (75.4%)

Epoch: 14 0/60000 Training loss: 1.531405
Epoch: 14 10000/60000 Training loss: 1.472718
Epoch: 14 20000/60000 Training loss: 1.592008
Epoch: 14 30000/60000 Training loss: 1.522163
Epoch: 14 40000/60000 Training loss: 1.497594
Epoch: 14 50000/60000 Training loss: 1.437611
Training loss: 1.532273
Test loss: 1.153678; Test accuracy: 7612/10000 (76.1%)

Epoch: 15 0/60000 Training loss: 1.597012
Epoch: 15 10000/60000 Training loss: 1.466853
Epoch: 15 20000/60000 Training loss: 1.475393
Epoch: 15 30000/60000 Training loss: 1.557641
Epoch: 15 40000/60000 Training loss: 1.486069
Epoch: 15 50000/60000 Training loss: 1.451321
Training loss: 1.506591
Test loss: 1.114333; Test accuracy: 7686/10000 (76.9%)

Epoch: 16 0/60000 Training loss: 1.497551
Epoch: 16 10000/60000 Training loss: 1.569105
Epoch: 16 20000/60000 Training loss: 1.394647
Epoch: 16 30000/60000 Training loss: 1.620759
Epoch: 16 40000/60000 Training loss: 1.614997
Epoch: 16 50000/60000 Training loss: 1.504637
Training loss: 1.483550
Test loss: 1.071147; Test accuracy: 7767/10000 (77.7%)

Epoch: 17 0/60000 Training loss: 1.583569
Epoch: 17 10000/60000 Training loss: 1.449415
Epoch: 17 20000/60000 Training loss: 1.683508
Epoch: 17 30000/60000 Training loss: 1.545349
Epoch: 17 40000/60000 Training loss: 1.365788
Epoch: 17 50000/60000 Training loss: 1.446136
Training loss: 1.463445
Test loss: 1.038514; Test accuracy: 7803/10000 (78.0%)

Epoch: 18 0/60000 Training loss: 1.461678
Epoch: 18 10000/60000 Training loss: 1.503193
Epoch: 18 20000/60000 Training loss: 1.335321
Epoch: 18 30000/60000 Training loss: 1.439979
Epoch: 18 40000/60000 Training loss: 1.289424
Epoch: 18 50000/60000 Training loss: 1.554064
Training loss: 1.449742
Test loss: 1.005565; Test accuracy: 7895/10000 (78.9%)

Epoch: 19 0/60000 Training loss: 1.366725
Epoch: 19 10000/60000 Training loss: 1.376203
Epoch: 19 20000/60000 Training loss: 1.307512
Epoch: 19 30000/60000 Training loss: 1.591446
Epoch: 19 40000/60000 Training loss: 1.451447
Epoch: 19 50000/60000 Training loss: 1.373862
Training loss: 1.429642
Test loss: 0.977209; Test accuracy: 7964/10000 (79.6%)

[I 2022-11-04 00:05:40,957] Trial 4 finished with value: 0.9772093296051025 and parameters: {'num_conv1_channels': 16, 'num_conv2_channels': 128, 'conv2_drop': 0.11072937344014448, 'fc1_neurons': 10, 'optimizer': 'SGD', 'learning_rate': 0.00028776254721041576}. Best is trial 3 with value: 0.018984997645020485.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 48, 'conv2_drop': 0.1973227650849031, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 2.0687627566915955e-05}
Epoch: 0 0/60000 Training loss: 2.300211
Epoch: 0 10000/60000 Training loss: 2.098075
Epoch: 0 20000/60000 Training loss: 1.662398
Epoch: 0 30000/60000 Training loss: 0.992519
Epoch: 0 40000/60000 Training loss: 0.895461
Epoch: 0 50000/60000 Training loss: 0.694888
Training loss: 1.292925
Test loss: 0.397314; Test accuracy: 9080/10000 (90.8%)

Epoch: 1 0/60000 Training loss: 0.620132
Epoch: 1 10000/60000 Training loss: 0.492324
Epoch: 1 20000/60000 Training loss: 0.401621
Epoch: 1 30000/60000 Training loss: 0.457501
Epoch: 1 40000/60000 Training loss: 0.480159
Epoch: 1 50000/60000 Training loss: 0.428394
Training loss: 0.461730
Test loss: 0.229392; Test accuracy: 9395/10000 (93.9%)

Epoch: 2 0/60000 Training loss: 0.260232
Epoch: 2 10000/60000 Training loss: 0.321492
Epoch: 2 20000/60000 Training loss: 0.352015
Epoch: 2 30000/60000 Training loss: 0.338348
Epoch: 2 40000/60000 Training loss: 0.249662
Epoch: 2 50000/60000 Training loss: 0.259324
Training loss: 0.321765
Test loss: 0.171155; Test accuracy: 9509/10000 (95.1%)

Epoch: 3 0/60000 Training loss: 0.216550
Epoch: 3 10000/60000 Training loss: 0.187461
Epoch: 3 20000/60000 Training loss: 0.312936
Epoch: 3 30000/60000 Training loss: 0.173271
Epoch: 3 40000/60000 Training loss: 0.158232
Epoch: 3 50000/60000 Training loss: 0.190859
Training loss: 0.254057
Test loss: 0.138583; Test accuracy: 9583/10000 (95.8%)

Epoch: 4 0/60000 Training loss: 0.258241
Epoch: 4 10000/60000 Training loss: 0.168070
Epoch: 4 20000/60000 Training loss: 0.168456
Epoch: 4 30000/60000 Training loss: 0.178837
Epoch: 4 40000/60000 Training loss: 0.279065
Epoch: 4 50000/60000 Training loss: 0.216855
Training loss: 0.214136
Test loss: 0.116608; Test accuracy: 9646/10000 (96.5%)

Epoch: 5 0/60000 Training loss: 0.235831
Epoch: 5 10000/60000 Training loss: 0.198724
Epoch: 5 20000/60000 Training loss: 0.145462
Epoch: 5 30000/60000 Training loss: 0.157676
Epoch: 5 40000/60000 Training loss: 0.210007
Epoch: 5 50000/60000 Training loss: 0.146847
Training loss: 0.187608
Test loss: 0.101423; Test accuracy: 9697/10000 (97.0%)

Epoch: 6 0/60000 Training loss: 0.156992
Epoch: 6 10000/60000 Training loss: 0.262169
Epoch: 6 20000/60000 Training loss: 0.219637
Epoch: 6 30000/60000 Training loss: 0.247210
Epoch: 6 40000/60000 Training loss: 0.132564
Epoch: 6 50000/60000 Training loss: 0.139869
Training loss: 0.166781
Test loss: 0.089381; Test accuracy: 9731/10000 (97.3%)

Epoch: 7 0/60000 Training loss: 0.178281
Epoch: 7 10000/60000 Training loss: 0.169747
Epoch: 7 20000/60000 Training loss: 0.115249
Epoch: 7 30000/60000 Training loss: 0.153067
Epoch: 7 40000/60000 Training loss: 0.136541
Epoch: 7 50000/60000 Training loss: 0.146320
Training loss: 0.151285
Test loss: 0.079300; Test accuracy: 9754/10000 (97.5%)

Epoch: 8 0/60000 Training loss: 0.163580
Epoch: 8 10000/60000 Training loss: 0.054824
Epoch: 8 20000/60000 Training loss: 0.204100
Epoch: 8 30000/60000 Training loss: 0.079979
Epoch: 8 40000/60000 Training loss: 0.100353
Epoch: 8 50000/60000 Training loss: 0.068103
Training loss: 0.135558
Test loss: 0.072388; Test accuracy: 9780/10000 (97.8%)

Epoch: 9 0/60000 Training loss: 0.099640
Epoch: 9 10000/60000 Training loss: 0.071171
Epoch: 9 20000/60000 Training loss: 0.224436
Epoch: 9 30000/60000 Training loss: 0.176187
Epoch: 9 40000/60000 Training loss: 0.145226
Epoch: 9 50000/60000 Training loss: 0.112321
Training loss: 0.125301
Test loss: 0.067213; Test accuracy: 9800/10000 (98.0%)

Epoch: 10 0/60000 Training loss: 0.070339
Epoch: 10 10000/60000 Training loss: 0.064998
Epoch: 10 20000/60000 Training loss: 0.104304
Epoch: 10 30000/60000 Training loss: 0.086658
Epoch: 10 40000/60000 Training loss: 0.059004
Epoch: 10 50000/60000 Training loss: 0.150797
Training loss: 0.119364
Test loss: 0.062105; Test accuracy: 9805/10000 (98.0%)

Epoch: 11 0/60000 Training loss: 0.036923
Epoch: 11 10000/60000 Training loss: 0.106843
Epoch: 11 20000/60000 Training loss: 0.124375
Epoch: 11 30000/60000 Training loss: 0.074220
Epoch: 11 40000/60000 Training loss: 0.164105
Epoch: 11 50000/60000 Training loss: 0.154558
Training loss: 0.109384
Test loss: 0.058355; Test accuracy: 9816/10000 (98.2%)

Epoch: 12 0/60000 Training loss: 0.176168
Epoch: 12 10000/60000 Training loss: 0.038829
Epoch: 12 20000/60000 Training loss: 0.051491
Epoch: 12 30000/60000 Training loss: 0.069767
Epoch: 12 40000/60000 Training loss: 0.048844
Epoch: 12 50000/60000 Training loss: 0.087009
Training loss: 0.103528
Test loss: 0.053991; Test accuracy: 9823/10000 (98.2%)

Epoch: 13 0/60000 Training loss: 0.129322
Epoch: 13 10000/60000 Training loss: 0.062402
Epoch: 13 20000/60000 Training loss: 0.037226
Epoch: 13 30000/60000 Training loss: 0.054721
Epoch: 13 40000/60000 Training loss: 0.044137
Epoch: 13 50000/60000 Training loss: 0.074985
Training loss: 0.099883
Test loss: 0.050847; Test accuracy: 9835/10000 (98.3%)

Epoch: 14 0/60000 Training loss: 0.096893
Epoch: 14 10000/60000 Training loss: 0.073236
Epoch: 14 20000/60000 Training loss: 0.168012
Epoch: 14 30000/60000 Training loss: 0.156823
Epoch: 14 40000/60000 Training loss: 0.096608
Epoch: 14 50000/60000 Training loss: 0.081135
Training loss: 0.095697
Test loss: 0.048549; Test accuracy: 9838/10000 (98.4%)

Epoch: 15 0/60000 Training loss: 0.127444
Epoch: 15 10000/60000 Training loss: 0.100408
Epoch: 15 20000/60000 Training loss: 0.142177
Epoch: 15 30000/60000 Training loss: 0.051422
Epoch: 15 40000/60000 Training loss: 0.084135
Epoch: 15 50000/60000 Training loss: 0.055154
Training loss: 0.089127
Test loss: 0.046140; Test accuracy: 9844/10000 (98.4%)

Epoch: 16 0/60000 Training loss: 0.153841
Epoch: 16 10000/60000 Training loss: 0.058724
Epoch: 16 20000/60000 Training loss: 0.070125
Epoch: 16 30000/60000 Training loss: 0.044720
Epoch: 16 40000/60000 Training loss: 0.075708
Epoch: 16 50000/60000 Training loss: 0.028658
Training loss: 0.086281
Test loss: 0.044154; Test accuracy: 9851/10000 (98.5%)

Epoch: 17 0/60000 Training loss: 0.035913
Epoch: 17 10000/60000 Training loss: 0.120154
Epoch: 17 20000/60000 Training loss: 0.099569
Epoch: 17 30000/60000 Training loss: 0.084615
Epoch: 17 40000/60000 Training loss: 0.085064
Epoch: 17 50000/60000 Training loss: 0.087632
Training loss: 0.081718
Test loss: 0.042200; Test accuracy: 9859/10000 (98.6%)

Epoch: 18 0/60000 Training loss: 0.032293
Epoch: 18 10000/60000 Training loss: 0.022344
Epoch: 18 20000/60000 Training loss: 0.072627
Epoch: 18 30000/60000 Training loss: 0.017782
Epoch: 18 40000/60000 Training loss: 0.068342
Epoch: 18 50000/60000 Training loss: 0.058067
Training loss: 0.079407
Test loss: 0.040745; Test accuracy: 9865/10000 (98.6%)

Epoch: 19 0/60000 Training loss: 0.058090
Epoch: 19 10000/60000 Training loss: 0.040660
Epoch: 19 20000/60000 Training loss: 0.018744
Epoch: 19 30000/60000 Training loss: 0.128999
Epoch: 19 40000/60000 Training loss: 0.086766
Epoch: 19 50000/60000 Training loss: 0.096678
Training loss: 0.074414
Test loss: 0.038963; Test accuracy: 9867/10000 (98.7%)

[I 2022-11-04 00:10:32,844] Trial 5 finished with value: 0.0389627180993557 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 48, 'conv2_drop': 0.1973227650849031, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 2.0687627566915955e-05}. Best is trial 3 with value: 0.018984997645020485.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.18800087591123688, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 6.71713371164459e-05}
Epoch: 0 0/60000 Training loss: 2.297967
Epoch: 0 10000/60000 Training loss: 1.300556
Epoch: 0 20000/60000 Training loss: 0.687926
Epoch: 0 30000/60000 Training loss: 0.771476
Epoch: 0 40000/60000 Training loss: 0.488125
Epoch: 0 50000/60000 Training loss: 0.328655
Training loss: 0.788049
Test loss: 0.185126; Test accuracy: 9490/10000 (94.9%)

Epoch: 1 0/60000 Training loss: 0.524991
Epoch: 1 10000/60000 Training loss: 0.213177
Epoch: 1 20000/60000 Training loss: 0.298174
Epoch: 1 30000/60000 Training loss: 0.299000
Epoch: 1 40000/60000 Training loss: 0.279411
Epoch: 1 50000/60000 Training loss: 0.268477
Training loss: 0.281017
Test loss: 0.107340; Test accuracy: 9680/10000 (96.8%)

Epoch: 2 0/60000 Training loss: 0.231986
Epoch: 2 10000/60000 Training loss: 0.181366
Epoch: 2 20000/60000 Training loss: 0.196705
Epoch: 2 30000/60000 Training loss: 0.206904
Epoch: 2 40000/60000 Training loss: 0.158355
Epoch: 2 50000/60000 Training loss: 0.221642
Training loss: 0.199081
Test loss: 0.079899; Test accuracy: 9755/10000 (97.5%)

Epoch: 3 0/60000 Training loss: 0.181676
Epoch: 3 10000/60000 Training loss: 0.197573
Epoch: 3 20000/60000 Training loss: 0.190620
Epoch: 3 30000/60000 Training loss: 0.176940
Epoch: 3 40000/60000 Training loss: 0.219279
Epoch: 3 50000/60000 Training loss: 0.092060
Training loss: 0.159175
Test loss: 0.063747; Test accuracy: 9804/10000 (98.0%)

Epoch: 4 0/60000 Training loss: 0.086431
Epoch: 4 10000/60000 Training loss: 0.125942
Epoch: 4 20000/60000 Training loss: 0.304026
Epoch: 4 30000/60000 Training loss: 0.111454
Epoch: 4 40000/60000 Training loss: 0.099492
Epoch: 4 50000/60000 Training loss: 0.136029
Training loss: 0.138019
Test loss: 0.054633; Test accuracy: 9827/10000 (98.3%)

Epoch: 5 0/60000 Training loss: 0.134824
Epoch: 5 10000/60000 Training loss: 0.147361
Epoch: 5 20000/60000 Training loss: 0.070899
Epoch: 5 30000/60000 Training loss: 0.263976
Epoch: 5 40000/60000 Training loss: 0.126981
Epoch: 5 50000/60000 Training loss: 0.138409
Training loss: 0.121055
Test loss: 0.047021; Test accuracy: 9849/10000 (98.5%)

Epoch: 6 0/60000 Training loss: 0.161530
Epoch: 6 10000/60000 Training loss: 0.082183
Epoch: 6 20000/60000 Training loss: 0.140261
Epoch: 6 30000/60000 Training loss: 0.049870
Epoch: 6 40000/60000 Training loss: 0.107657
Epoch: 6 50000/60000 Training loss: 0.151163
Training loss: 0.111588
Test loss: 0.044553; Test accuracy: 9855/10000 (98.5%)

Epoch: 7 0/60000 Training loss: 0.152625
Epoch: 7 10000/60000 Training loss: 0.073521
Epoch: 7 20000/60000 Training loss: 0.051778
Epoch: 7 30000/60000 Training loss: 0.083125
Epoch: 7 40000/60000 Training loss: 0.176168
Epoch: 7 50000/60000 Training loss: 0.101776
Training loss: 0.100686
Test loss: 0.039939; Test accuracy: 9866/10000 (98.7%)

Epoch: 8 0/60000 Training loss: 0.114685
Epoch: 8 10000/60000 Training loss: 0.124246
Epoch: 8 20000/60000 Training loss: 0.053106
Epoch: 8 30000/60000 Training loss: 0.090804
Epoch: 8 40000/60000 Training loss: 0.099968
Epoch: 8 50000/60000 Training loss: 0.076028
Training loss: 0.091937
Test loss: 0.035581; Test accuracy: 9878/10000 (98.8%)

Epoch: 9 0/60000 Training loss: 0.065846
Epoch: 9 10000/60000 Training loss: 0.117170
Epoch: 9 20000/60000 Training loss: 0.026342
Epoch: 9 30000/60000 Training loss: 0.053061
Epoch: 9 40000/60000 Training loss: 0.054442
Epoch: 9 50000/60000 Training loss: 0.061074
Training loss: 0.084402
Test loss: 0.033800; Test accuracy: 9881/10000 (98.8%)

Epoch: 10 0/60000 Training loss: 0.087209
Epoch: 10 10000/60000 Training loss: 0.078555
Epoch: 10 20000/60000 Training loss: 0.064157
Epoch: 10 30000/60000 Training loss: 0.045137
Epoch: 10 40000/60000 Training loss: 0.056056
Epoch: 10 50000/60000 Training loss: 0.066684
Training loss: 0.078284
Test loss: 0.033384; Test accuracy: 9890/10000 (98.9%)

Epoch: 11 0/60000 Training loss: 0.070596
Epoch: 11 10000/60000 Training loss: 0.055905
Epoch: 11 20000/60000 Training loss: 0.093282
Epoch: 11 30000/60000 Training loss: 0.067201
Epoch: 11 40000/60000 Training loss: 0.116086
Epoch: 11 50000/60000 Training loss: 0.065999
Training loss: 0.074008
Test loss: 0.029714; Test accuracy: 9904/10000 (99.0%)

Epoch: 12 0/60000 Training loss: 0.032784
Epoch: 12 10000/60000 Training loss: 0.059146
Epoch: 12 20000/60000 Training loss: 0.056574
Epoch: 12 30000/60000 Training loss: 0.193567
Epoch: 12 40000/60000 Training loss: 0.048269
Epoch: 12 50000/60000 Training loss: 0.071126
Training loss: 0.069487
Test loss: 0.029353; Test accuracy: 9900/10000 (99.0%)

Epoch: 13 0/60000 Training loss: 0.063990
Epoch: 13 10000/60000 Training loss: 0.115423
Epoch: 13 20000/60000 Training loss: 0.029748
Epoch: 13 30000/60000 Training loss: 0.089553
Epoch: 13 40000/60000 Training loss: 0.039058
Epoch: 13 50000/60000 Training loss: 0.075614
Training loss: 0.066175
Test loss: 0.027627; Test accuracy: 9910/10000 (99.1%)

Epoch: 14 0/60000 Training loss: 0.040536
Epoch: 14 10000/60000 Training loss: 0.049601
Epoch: 14 20000/60000 Training loss: 0.107542
Epoch: 14 30000/60000 Training loss: 0.078452
Epoch: 14 40000/60000 Training loss: 0.060330
Epoch: 14 50000/60000 Training loss: 0.016810
Training loss: 0.063907
Test loss: 0.026647; Test accuracy: 9907/10000 (99.1%)

Epoch: 15 0/60000 Training loss: 0.016649
Epoch: 15 10000/60000 Training loss: 0.015580
Epoch: 15 20000/60000 Training loss: 0.046498
Epoch: 15 30000/60000 Training loss: 0.132993
Epoch: 15 40000/60000 Training loss: 0.050785
Epoch: 15 50000/60000 Training loss: 0.077529
Training loss: 0.060889
Test loss: 0.026512; Test accuracy: 9913/10000 (99.1%)

Epoch: 16 0/60000 Training loss: 0.110262
Epoch: 16 10000/60000 Training loss: 0.017168
Epoch: 16 20000/60000 Training loss: 0.043769
Epoch: 16 30000/60000 Training loss: 0.087979
Epoch: 16 40000/60000 Training loss: 0.077420
Epoch: 16 50000/60000 Training loss: 0.023000
Training loss: 0.057729
Test loss: 0.024582; Test accuracy: 9917/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.053781
Epoch: 17 10000/60000 Training loss: 0.109767
Epoch: 17 20000/60000 Training loss: 0.034509
Epoch: 17 30000/60000 Training loss: 0.028709
Epoch: 17 40000/60000 Training loss: 0.016892
Epoch: 17 50000/60000 Training loss: 0.021048
Training loss: 0.054519
Test loss: 0.024082; Test accuracy: 9922/10000 (99.2%)

Epoch: 18 0/60000 Training loss: 0.073259
Epoch: 18 10000/60000 Training loss: 0.013802
Epoch: 18 20000/60000 Training loss: 0.015204
Epoch: 18 30000/60000 Training loss: 0.090927
Epoch: 18 40000/60000 Training loss: 0.010486
Epoch: 18 50000/60000 Training loss: 0.109444
Training loss: 0.051369
Test loss: 0.025763; Test accuracy: 9911/10000 (99.1%)

Epoch: 19 0/60000 Training loss: 0.064939
Epoch: 19 10000/60000 Training loss: 0.075862
Epoch: 19 20000/60000 Training loss: 0.021485
Epoch: 19 30000/60000 Training loss: 0.026168
Epoch: 19 40000/60000 Training loss: 0.025120
Epoch: 19 50000/60000 Training loss: 0.054490
Training loss: 0.050660
Test loss: 0.024474; Test accuracy: 9916/10000 (99.2%)

[I 2022-11-04 00:15:12,732] Trial 6 finished with value: 0.024082310497760773 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.18800087591123688, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 6.71713371164459e-05}. Best is trial 3 with value: 0.018984997645020485.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.14930225541596817, 'fc1_neurons': 70, 'optimizer': 'Adam', 'learning_rate': 0.00014698504316532513}
Epoch: 0 0/60000 Training loss: 2.312167
Epoch: 0 10000/60000 Training loss: 0.611538
Epoch: 0 20000/60000 Training loss: 0.283836
Epoch: 0 30000/60000 Training loss: 0.377315
Epoch: 0 40000/60000 Training loss: 0.309733
Epoch: 0 50000/60000 Training loss: 0.239310
Training loss: 0.459207
Test loss: 0.089521; Test accuracy: 9717/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.187481
Epoch: 1 10000/60000 Training loss: 0.132320
Epoch: 1 20000/60000 Training loss: 0.157274
Epoch: 1 30000/60000 Training loss: 0.147386
Epoch: 1 40000/60000 Training loss: 0.136405
Epoch: 1 50000/60000 Training loss: 0.114936
Training loss: 0.153660
Test loss: 0.053125; Test accuracy: 9829/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.105166
Epoch: 2 10000/60000 Training loss: 0.090053
Epoch: 2 20000/60000 Training loss: 0.128868
Epoch: 2 30000/60000 Training loss: 0.088295
Epoch: 2 40000/60000 Training loss: 0.045486
Epoch: 2 50000/60000 Training loss: 0.134931
Training loss: 0.104401
Test loss: 0.040578; Test accuracy: 9869/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.049062
Epoch: 3 10000/60000 Training loss: 0.116589
Epoch: 3 20000/60000 Training loss: 0.097431
Epoch: 3 30000/60000 Training loss: 0.078824
Epoch: 3 40000/60000 Training loss: 0.090051
Epoch: 3 50000/60000 Training loss: 0.065295
Training loss: 0.086051
Test loss: 0.033805; Test accuracy: 9885/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.084125
Epoch: 4 10000/60000 Training loss: 0.020451
Epoch: 4 20000/60000 Training loss: 0.055601
Epoch: 4 30000/60000 Training loss: 0.078538
Epoch: 4 40000/60000 Training loss: 0.067573
Epoch: 4 50000/60000 Training loss: 0.098975
Training loss: 0.073696
Test loss: 0.031003; Test accuracy: 9891/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.062926
Epoch: 5 10000/60000 Training loss: 0.124413
Epoch: 5 20000/60000 Training loss: 0.071065
Epoch: 5 30000/60000 Training loss: 0.097909
Epoch: 5 40000/60000 Training loss: 0.043006
Epoch: 5 50000/60000 Training loss: 0.062019
Training loss: 0.063523
Test loss: 0.025072; Test accuracy: 9913/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.048647
Epoch: 6 10000/60000 Training loss: 0.099138
Epoch: 6 20000/60000 Training loss: 0.058383
Epoch: 6 30000/60000 Training loss: 0.066148
Epoch: 6 40000/60000 Training loss: 0.151237
Epoch: 6 50000/60000 Training loss: 0.051462
Training loss: 0.055086
Test loss: 0.024192; Test accuracy: 9921/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.052958
Epoch: 7 10000/60000 Training loss: 0.036049
Epoch: 7 20000/60000 Training loss: 0.058466
Epoch: 7 30000/60000 Training loss: 0.037432
Epoch: 7 40000/60000 Training loss: 0.011849
Epoch: 7 50000/60000 Training loss: 0.020914
Training loss: 0.048369
Test loss: 0.023907; Test accuracy: 9925/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.060828
Epoch: 8 10000/60000 Training loss: 0.084523
Epoch: 8 20000/60000 Training loss: 0.087403
Epoch: 8 30000/60000 Training loss: 0.022212
Epoch: 8 40000/60000 Training loss: 0.060999
Epoch: 8 50000/60000 Training loss: 0.042029
Training loss: 0.045186
Test loss: 0.023273; Test accuracy: 9923/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.033167
Epoch: 9 10000/60000 Training loss: 0.152055
Epoch: 9 20000/60000 Training loss: 0.042103
Epoch: 9 30000/60000 Training loss: 0.037407
Epoch: 9 40000/60000 Training loss: 0.036629
Epoch: 9 50000/60000 Training loss: 0.022240
Training loss: 0.039692
Test loss: 0.020396; Test accuracy: 9932/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.026635
Epoch: 10 10000/60000 Training loss: 0.054780
Epoch: 10 20000/60000 Training loss: 0.018034
Epoch: 10 30000/60000 Training loss: 0.087060
Epoch: 10 40000/60000 Training loss: 0.020798
Epoch: 10 50000/60000 Training loss: 0.022145
Training loss: 0.036751
Test loss: 0.020516; Test accuracy: 9932/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.048195
Epoch: 11 10000/60000 Training loss: 0.027232
Epoch: 11 20000/60000 Training loss: 0.005668
Epoch: 11 30000/60000 Training loss: 0.045764
Epoch: 11 40000/60000 Training loss: 0.008743
Epoch: 11 50000/60000 Training loss: 0.030152
Training loss: 0.034787
Test loss: 0.019896; Test accuracy: 9937/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.096519
Epoch: 12 10000/60000 Training loss: 0.005758
Epoch: 12 20000/60000 Training loss: 0.007916
Epoch: 12 30000/60000 Training loss: 0.025034
Epoch: 12 40000/60000 Training loss: 0.050597
Epoch: 12 50000/60000 Training loss: 0.023348
Training loss: 0.032356
Test loss: 0.018618; Test accuracy: 9935/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.077736
Epoch: 13 10000/60000 Training loss: 0.007452
Epoch: 13 20000/60000 Training loss: 0.042085
Epoch: 13 30000/60000 Training loss: 0.028996
Epoch: 13 40000/60000 Training loss: 0.003033
Epoch: 13 50000/60000 Training loss: 0.012839
Training loss: 0.029221
Test loss: 0.018174; Test accuracy: 9939/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.010455
Epoch: 14 10000/60000 Training loss: 0.012672
Epoch: 14 20000/60000 Training loss: 0.022957
Epoch: 14 30000/60000 Training loss: 0.009241
Epoch: 14 40000/60000 Training loss: 0.028924
Epoch: 14 50000/60000 Training loss: 0.012994
Training loss: 0.025566
Test loss: 0.018090; Test accuracy: 9943/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.004740
Epoch: 15 10000/60000 Training loss: 0.033212
Epoch: 15 20000/60000 Training loss: 0.009592
Epoch: 15 30000/60000 Training loss: 0.005773
Epoch: 15 40000/60000 Training loss: 0.008505
Epoch: 15 50000/60000 Training loss: 0.016189
Training loss: 0.025373
Test loss: 0.021246; Test accuracy: 9935/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.083882
Epoch: 16 10000/60000 Training loss: 0.005469
Epoch: 16 20000/60000 Training loss: 0.075744
Epoch: 16 30000/60000 Training loss: 0.003122
Epoch: 16 40000/60000 Training loss: 0.026604
Epoch: 16 50000/60000 Training loss: 0.005250
Training loss: 0.024442
Test loss: 0.019878; Test accuracy: 9935/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.037691
Epoch: 17 10000/60000 Training loss: 0.022735
Epoch: 17 20000/60000 Training loss: 0.029552
Epoch: 17 30000/60000 Training loss: 0.021003
Epoch: 17 40000/60000 Training loss: 0.014945
Epoch: 17 50000/60000 Training loss: 0.008460
Training loss: 0.022042
Test loss: 0.020051; Test accuracy: 9943/10000 (99.4%)

[I 2022-11-04 00:19:24,915] Trial 7 finished with value: 0.018089881166815758 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.14930225541596817, 'fc1_neurons': 70, 'optimizer': 'Adam', 'learning_rate': 0.00014698504316532513}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.18798545423078888, 'fc1_neurons': 100, 'optimizer': 'SGD', 'learning_rate': 5.0310759954118736e-05}
Epoch: 0 0/60000 Training loss: 2.340189
Epoch: 0 10000/60000 Training loss: 2.324541
Epoch: 0 20000/60000 Training loss: 2.292783
Epoch: 0 30000/60000 Training loss: 2.308332
Epoch: 0 40000/60000 Training loss: 2.302787
Epoch: 0 50000/60000 Training loss: 2.280800
Training loss: 2.303454
Test loss: 2.286110; Test accuracy: 1008/10000 (10.1%)

Epoch: 1 0/60000 Training loss: 2.318297
Epoch: 1 10000/60000 Training loss: 2.294545
Epoch: 1 20000/60000 Training loss: 2.283139
Epoch: 1 30000/60000 Training loss: 2.272048
Epoch: 1 40000/60000 Training loss: 2.258513
Epoch: 1 50000/60000 Training loss: 2.278780
Training loss: 2.281968
Test loss: 2.264570; Test accuracy: 1087/10000 (10.9%)

Epoch: 2 0/60000 Training loss: 2.284781
Epoch: 2 10000/60000 Training loss: 2.266479
Epoch: 2 20000/60000 Training loss: 2.270115
Epoch: 2 30000/60000 Training loss: 2.279853
Epoch: 2 40000/60000 Training loss: 2.280788
Epoch: 2 50000/60000 Training loss: 2.251420
Training loss: 2.263444
Test loss: 2.243208; Test accuracy: 1695/10000 (16.9%)

Epoch: 3 0/60000 Training loss: 2.234151
Epoch: 3 10000/60000 Training loss: 2.244297
Epoch: 3 20000/60000 Training loss: 2.240737
Epoch: 3 30000/60000 Training loss: 2.250817
Epoch: 3 40000/60000 Training loss: 2.257041
Epoch: 3 50000/60000 Training loss: 2.244462
Training loss: 2.243953
Test loss: 2.221437; Test accuracy: 2943/10000 (29.4%)

Epoch: 4 0/60000 Training loss: 2.239363
Epoch: 4 10000/60000 Training loss: 2.239416
Epoch: 4 20000/60000 Training loss: 2.198588
Epoch: 4 30000/60000 Training loss: 2.202103
Epoch: 4 40000/60000 Training loss: 2.234791
Epoch: 4 50000/60000 Training loss: 2.198695
Training loss: 2.222843
Test loss: 2.198293; Test accuracy: 3650/10000 (36.5%)

Epoch: 5 0/60000 Training loss: 2.212859
Epoch: 5 10000/60000 Training loss: 2.170698
Epoch: 5 20000/60000 Training loss: 2.212186
Epoch: 5 30000/60000 Training loss: 2.213822
Epoch: 5 40000/60000 Training loss: 2.183853
Epoch: 5 50000/60000 Training loss: 2.218061
Training loss: 2.201382
Test loss: 2.173105; Test accuracy: 4005/10000 (40.0%)

Epoch: 6 0/60000 Training loss: 2.200739
Epoch: 6 10000/60000 Training loss: 2.184123
Epoch: 6 20000/60000 Training loss: 2.164609
Epoch: 6 30000/60000 Training loss: 2.184422
Epoch: 6 40000/60000 Training loss: 2.175940
Epoch: 6 50000/60000 Training loss: 2.180626
Training loss: 2.178293
Test loss: 2.145298; Test accuracy: 4305/10000 (43.0%)

Epoch: 7 0/60000 Training loss: 2.167586
Epoch: 7 10000/60000 Training loss: 2.156338
Epoch: 7 20000/60000 Training loss: 2.184507
Epoch: 7 30000/60000 Training loss: 2.166514
Epoch: 7 40000/60000 Training loss: 2.142754
Epoch: 7 50000/60000 Training loss: 2.146160
Training loss: 2.150801
Test loss: 2.114609; Test accuracy: 4724/10000 (47.2%)

Epoch: 8 0/60000 Training loss: 2.143100
Epoch: 8 10000/60000 Training loss: 2.159061
Epoch: 8 20000/60000 Training loss: 2.113657
Epoch: 8 30000/60000 Training loss: 2.111720
Epoch: 8 40000/60000 Training loss: 2.132710
Epoch: 8 50000/60000 Training loss: 2.105810
Training loss: 2.123440
Test loss: 2.081675; Test accuracy: 5197/10000 (52.0%)

Epoch: 9 0/60000 Training loss: 2.122868
Epoch: 9 10000/60000 Training loss: 2.099906
Epoch: 9 20000/60000 Training loss: 2.118113
Epoch: 9 30000/60000 Training loss: 2.130618
Epoch: 9 40000/60000 Training loss: 2.110127
Epoch: 9 50000/60000 Training loss: 2.029774
Training loss: 2.092382
Test loss: 2.045844; Test accuracy: 5574/10000 (55.7%)

Epoch: 10 0/60000 Training loss: 2.105725
Epoch: 10 10000/60000 Training loss: 2.075844
Epoch: 10 20000/60000 Training loss: 2.080905
Epoch: 10 30000/60000 Training loss: 2.085118
Epoch: 10 40000/60000 Training loss: 2.081293
Epoch: 10 50000/60000 Training loss: 2.075543
Training loss: 2.059673
Test loss: 2.006846; Test accuracy: 5911/10000 (59.1%)

Epoch: 11 0/60000 Training loss: 2.070968
Epoch: 11 10000/60000 Training loss: 2.038175
Epoch: 11 20000/60000 Training loss: 1.993886
Epoch: 11 30000/60000 Training loss: 2.007933
Epoch: 11 40000/60000 Training loss: 2.006347
Epoch: 11 50000/60000 Training loss: 1.974375
Training loss: 2.023729
Test loss: 1.964306; Test accuracy: 6205/10000 (62.0%)

Epoch: 12 0/60000 Training loss: 2.000269
Epoch: 12 10000/60000 Training loss: 2.011669
Epoch: 12 20000/60000 Training loss: 1.968065
Epoch: 12 30000/60000 Training loss: 1.980494
Epoch: 12 40000/60000 Training loss: 2.015561
Epoch: 12 50000/60000 Training loss: 1.964475
Training loss: 1.984426
Test loss: 1.917597; Test accuracy: 6450/10000 (64.5%)

Epoch: 13 0/60000 Training loss: 1.978191
Epoch: 13 10000/60000 Training loss: 1.960485
Epoch: 13 20000/60000 Training loss: 1.931482
Epoch: 13 30000/60000 Training loss: 1.913787
Epoch: 13 40000/60000 Training loss: 1.980156
Epoch: 13 50000/60000 Training loss: 1.935369
Training loss: 1.941400
Test loss: 1.866612; Test accuracy: 6677/10000 (66.8%)

Epoch: 14 0/60000 Training loss: 1.869836
Epoch: 14 10000/60000 Training loss: 1.913807
Epoch: 14 20000/60000 Training loss: 2.010558
Epoch: 14 30000/60000 Training loss: 1.790596
Epoch: 14 40000/60000 Training loss: 1.896617
Epoch: 14 50000/60000 Training loss: 1.835109
Training loss: 1.895528
Test loss: 1.811429; Test accuracy: 6861/10000 (68.6%)

Epoch: 15 0/60000 Training loss: 1.839576
Epoch: 15 10000/60000 Training loss: 1.934988
Epoch: 15 20000/60000 Training loss: 1.888380
Epoch: 15 30000/60000 Training loss: 1.802236
Epoch: 15 40000/60000 Training loss: 1.902414
Epoch: 15 50000/60000 Training loss: 1.761979
Training loss: 1.846094
Test loss: 1.752497; Test accuracy: 7017/10000 (70.2%)

Epoch: 16 0/60000 Training loss: 1.855182
Epoch: 16 10000/60000 Training loss: 1.855205
Epoch: 16 20000/60000 Training loss: 1.760151
Epoch: 16 30000/60000 Training loss: 1.757377
Epoch: 16 40000/60000 Training loss: 1.816773
Epoch: 16 50000/60000 Training loss: 1.712693
Training loss: 1.793412
Test loss: 1.690277; Test accuracy: 7115/10000 (71.2%)

Epoch: 17 0/60000 Training loss: 1.650555
Epoch: 17 10000/60000 Training loss: 1.711992
Epoch: 17 20000/60000 Training loss: 1.809055
Epoch: 17 30000/60000 Training loss: 1.712904
Epoch: 17 40000/60000 Training loss: 1.634914
Epoch: 17 50000/60000 Training loss: 1.723805
Training loss: 1.743971
Test loss: 1.626303; Test accuracy: 7246/10000 (72.5%)

Epoch: 18 0/60000 Training loss: 1.742965
Epoch: 18 10000/60000 Training loss: 1.664693
Epoch: 18 20000/60000 Training loss: 1.748027
Epoch: 18 30000/60000 Training loss: 1.760667
Epoch: 18 40000/60000 Training loss: 1.715510
Epoch: 18 50000/60000 Training loss: 1.644798
Training loss: 1.688319
Test loss: 1.560268; Test accuracy: 7380/10000 (73.8%)

Epoch: 19 0/60000 Training loss: 1.582398
Epoch: 19 10000/60000 Training loss: 1.562296
Epoch: 19 20000/60000 Training loss: 1.671387
Epoch: 19 30000/60000 Training loss: 1.584005
Epoch: 19 40000/60000 Training loss: 1.542858
Epoch: 19 50000/60000 Training loss: 1.583974
Training loss: 1.628275
Test loss: 1.492016; Test accuracy: 7547/10000 (75.5%)

[I 2022-11-04 00:24:04,253] Trial 8 finished with value: 1.4920156002044678 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.18798545423078888, 'fc1_neurons': 100, 'optimizer': 'SGD', 'learning_rate': 5.0310759954118736e-05}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 48, 'conv2_drop': 0.19629255933577472, 'fc1_neurons': 50, 'optimizer': 'SGD', 'learning_rate': 0.00011976070018847589}
Epoch: 0 0/60000 Training loss: 2.307906
Epoch: 0 10000/60000 Training loss: 2.279566
Epoch: 0 20000/60000 Training loss: 2.306909
Epoch: 0 30000/60000 Training loss: 2.299746
Epoch: 0 40000/60000 Training loss: 2.288652
Epoch: 0 50000/60000 Training loss: 2.290010
Training loss: 2.291948
Test loss: 2.259980; Test accuracy: 1738/10000 (17.4%)

Epoch: 1 0/60000 Training loss: 2.276615
Epoch: 1 10000/60000 Training loss: 2.270631
Epoch: 1 20000/60000 Training loss: 2.247022
Epoch: 1 30000/60000 Training loss: 2.243600
Epoch: 1 40000/60000 Training loss: 2.256611
Epoch: 1 50000/60000 Training loss: 2.210125
Training loss: 2.251103
Test loss: 2.211827; Test accuracy: 2646/10000 (26.5%)

Epoch: 2 0/60000 Training loss: 2.211862
Epoch: 2 10000/60000 Training loss: 2.192406
Epoch: 2 20000/60000 Training loss: 2.218593
Epoch: 2 30000/60000 Training loss: 2.195910
Epoch: 2 40000/60000 Training loss: 2.213763
Epoch: 2 50000/60000 Training loss: 2.214913
Training loss: 2.207616
Test loss: 2.157062; Test accuracy: 3920/10000 (39.2%)

Epoch: 3 0/60000 Training loss: 2.186815
Epoch: 3 10000/60000 Training loss: 2.198102
Epoch: 3 20000/60000 Training loss: 2.187395
Epoch: 3 30000/60000 Training loss: 2.117140
Epoch: 3 40000/60000 Training loss: 2.151062
Epoch: 3 50000/60000 Training loss: 2.164169
Training loss: 2.157718
Test loss: 2.092222; Test accuracy: 5456/10000 (54.6%)

Epoch: 4 0/60000 Training loss: 2.144078
Epoch: 4 10000/60000 Training loss: 2.091873
Epoch: 4 20000/60000 Training loss: 2.110192
Epoch: 4 30000/60000 Training loss: 2.067407
Epoch: 4 40000/60000 Training loss: 2.071761
Epoch: 4 50000/60000 Training loss: 2.062542
Training loss: 2.096342
Test loss: 2.013686; Test accuracy: 6708/10000 (67.1%)

Epoch: 5 0/60000 Training loss: 2.058889
Epoch: 5 10000/60000 Training loss: 2.043956
Epoch: 5 20000/60000 Training loss: 2.019874
Epoch: 5 30000/60000 Training loss: 1.992130
Epoch: 5 40000/60000 Training loss: 2.003419
Epoch: 5 50000/60000 Training loss: 1.969391
Training loss: 2.026742
Test loss: 1.919301; Test accuracy: 7173/10000 (71.7%)

Epoch: 6 0/60000 Training loss: 2.018201
Epoch: 6 10000/60000 Training loss: 2.006122
Epoch: 6 20000/60000 Training loss: 1.913081
Epoch: 6 30000/60000 Training loss: 1.974347
Epoch: 6 40000/60000 Training loss: 1.954166
Epoch: 6 50000/60000 Training loss: 1.903756
Training loss: 1.946642
Test loss: 1.810799; Test accuracy: 7408/10000 (74.1%)

Epoch: 7 0/60000 Training loss: 1.876197
Epoch: 7 10000/60000 Training loss: 1.847219
Epoch: 7 20000/60000 Training loss: 1.891077
Epoch: 7 30000/60000 Training loss: 1.831516
Epoch: 7 40000/60000 Training loss: 1.810283
Epoch: 7 50000/60000 Training loss: 1.845204
Training loss: 1.855579
Test loss: 1.690062; Test accuracy: 7539/10000 (75.4%)

Epoch: 8 0/60000 Training loss: 1.848882
Epoch: 8 10000/60000 Training loss: 1.853643
Epoch: 8 20000/60000 Training loss: 1.873993
Epoch: 8 30000/60000 Training loss: 1.832011
Epoch: 8 40000/60000 Training loss: 1.734338
Epoch: 8 50000/60000 Training loss: 1.739297
Training loss: 1.756780
Test loss: 1.562483; Test accuracy: 7743/10000 (77.4%)

Epoch: 9 0/60000 Training loss: 1.751328
Epoch: 9 10000/60000 Training loss: 1.650940
Epoch: 9 20000/60000 Training loss: 1.705027
Epoch: 9 30000/60000 Training loss: 1.622537
Epoch: 9 40000/60000 Training loss: 1.738592
Epoch: 9 50000/60000 Training loss: 1.571709
Training loss: 1.660608
Test loss: 1.436994; Test accuracy: 7803/10000 (78.0%)

Epoch: 10 0/60000 Training loss: 1.509506
Epoch: 10 10000/60000 Training loss: 1.555342
Epoch: 10 20000/60000 Training loss: 1.639929
Epoch: 10 30000/60000 Training loss: 1.555415
Epoch: 10 40000/60000 Training loss: 1.527366
Epoch: 10 50000/60000 Training loss: 1.587984
Training loss: 1.563375
Test loss: 1.316381; Test accuracy: 7969/10000 (79.7%)

Epoch: 11 0/60000 Training loss: 1.498578
Epoch: 11 10000/60000 Training loss: 1.498431
Epoch: 11 20000/60000 Training loss: 1.582169
Epoch: 11 30000/60000 Training loss: 1.598207
Epoch: 11 40000/60000 Training loss: 1.510049
Epoch: 11 50000/60000 Training loss: 1.374209
Training loss: 1.472863
Test loss: 1.204175; Test accuracy: 8058/10000 (80.6%)

Epoch: 12 0/60000 Training loss: 1.459695
Epoch: 12 10000/60000 Training loss: 1.446050
Epoch: 12 20000/60000 Training loss: 1.441304
Epoch: 12 30000/60000 Training loss: 1.293424
Epoch: 12 40000/60000 Training loss: 1.402433
Epoch: 12 50000/60000 Training loss: 1.325599
Training loss: 1.391421
Test loss: 1.103834; Test accuracy: 8170/10000 (81.7%)

Epoch: 13 0/60000 Training loss: 1.357627
Epoch: 13 10000/60000 Training loss: 1.385567
Epoch: 13 20000/60000 Training loss: 1.354433
Epoch: 13 30000/60000 Training loss: 1.416774
Epoch: 13 40000/60000 Training loss: 1.342279
Epoch: 13 50000/60000 Training loss: 1.270001
Training loss: 1.320962
Test loss: 1.018865; Test accuracy: 8277/10000 (82.8%)

Epoch: 14 0/60000 Training loss: 1.204650
Epoch: 14 10000/60000 Training loss: 1.039721
Epoch: 14 20000/60000 Training loss: 1.390230
Epoch: 14 30000/60000 Training loss: 1.186812
Epoch: 14 40000/60000 Training loss: 1.225939
Epoch: 14 50000/60000 Training loss: 1.221934
Training loss: 1.249038
Test loss: 0.940523; Test accuracy: 8357/10000 (83.6%)

Epoch: 15 0/60000 Training loss: 1.320168
Epoch: 15 10000/60000 Training loss: 1.254838
Epoch: 15 20000/60000 Training loss: 1.151229
Epoch: 15 30000/60000 Training loss: 1.095940
Epoch: 15 40000/60000 Training loss: 1.321370
Epoch: 15 50000/60000 Training loss: 1.166335
Training loss: 1.190253
Test loss: 0.873783; Test accuracy: 8400/10000 (84.0%)

Epoch: 16 0/60000 Training loss: 1.112894
Epoch: 16 10000/60000 Training loss: 1.075587
Epoch: 16 20000/60000 Training loss: 1.119693
Epoch: 16 30000/60000 Training loss: 1.103818
Epoch: 16 40000/60000 Training loss: 1.152210
Epoch: 16 50000/60000 Training loss: 0.996972
Training loss: 1.134730
Test loss: 0.817098; Test accuracy: 8448/10000 (84.5%)

Epoch: 17 0/60000 Training loss: 1.066613
Epoch: 17 10000/60000 Training loss: 1.092113
Epoch: 17 20000/60000 Training loss: 1.090465
Epoch: 17 30000/60000 Training loss: 1.128335
Epoch: 17 40000/60000 Training loss: 0.946639
Epoch: 17 50000/60000 Training loss: 1.171024
Training loss: 1.092482
Test loss: 0.767251; Test accuracy: 8515/10000 (85.2%)

Epoch: 18 0/60000 Training loss: 0.988486
Epoch: 18 10000/60000 Training loss: 1.024008
Epoch: 18 20000/60000 Training loss: 1.083793
Epoch: 18 30000/60000 Training loss: 1.023456
Epoch: 18 40000/60000 Training loss: 0.931913
Epoch: 18 50000/60000 Training loss: 0.944728
Training loss: 1.045759
Test loss: 0.723836; Test accuracy: 8572/10000 (85.7%)

Epoch: 19 0/60000 Training loss: 1.289617
Epoch: 19 10000/60000 Training loss: 0.912568
Epoch: 19 20000/60000 Training loss: 0.935890
Epoch: 19 30000/60000 Training loss: 1.083381
Epoch: 19 40000/60000 Training loss: 0.849168
Epoch: 19 50000/60000 Training loss: 1.022212
Training loss: 1.012211
Test loss: 0.687204; Test accuracy: 8616/10000 (86.2%)

[I 2022-11-04 00:28:42,853] Trial 9 finished with value: 0.6872042417526245 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 48, 'conv2_drop': 0.19629255933577472, 'fc1_neurons': 50, 'optimizer': 'SGD', 'learning_rate': 0.00011976070018847589}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.05098173136253968, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.0009104572081189141}
C:\Users\Ahmad\Desktop\fourth_year\SYDE599\SYDE599-Assignment2\optuna_optimizer.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
Epoch: 0 0/60000 Training loss: 2.342723
Epoch: 0 10000/60000 Training loss: 0.171860
Epoch: 0 20000/60000 Training loss: 0.197354
Epoch: 0 30000/60000 Training loss: 0.096277
Epoch: 0 40000/60000 Training loss: 0.102097
Epoch: 0 50000/60000 Training loss: 0.038617
Training loss: 0.195326
Test loss: 0.036252; Test accuracy: 9888/10000 (98.9%)

Epoch: 1 0/60000 Training loss: 0.160376
Epoch: 1 10000/60000 Training loss: 0.131386
Epoch: 1 20000/60000 Training loss: 0.078333
Epoch: 1 30000/60000 Training loss: 0.080993
Epoch: 1 40000/60000 Training loss: 0.020768
Epoch: 1 50000/60000 Training loss: 0.012770
Training loss: 0.066732
Test loss: 0.034984; Test accuracy: 9878/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.055335
Epoch: 2 10000/60000 Training loss: 0.058596
Epoch: 2 20000/60000 Training loss: 0.055826
Epoch: 2 30000/60000 Training loss: 0.068253
Epoch: 2 40000/60000 Training loss: 0.045922
Epoch: 2 50000/60000 Training loss: 0.021063
Training loss: 0.051229
Test loss: 0.028190; Test accuracy: 9905/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.111802
Epoch: 3 10000/60000 Training loss: 0.027133
Epoch: 3 20000/60000 Training loss: 0.015680
Epoch: 3 30000/60000 Training loss: 0.056682
Epoch: 3 40000/60000 Training loss: 0.035034
Epoch: 3 50000/60000 Training loss: 0.014319
Training loss: 0.041914
Test loss: 0.024383; Test accuracy: 9925/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.003536
Epoch: 4 10000/60000 Training loss: 0.073129
Epoch: 4 20000/60000 Training loss: 0.056944
Epoch: 4 30000/60000 Training loss: 0.006867
Epoch: 4 40000/60000 Training loss: 0.011719
Epoch: 4 50000/60000 Training loss: 0.001551
Training loss: 0.035417
Test loss: 0.022965; Test accuracy: 9920/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.099214
Epoch: 5 10000/60000 Training loss: 0.064492
Epoch: 5 20000/60000 Training loss: 0.010964
Epoch: 5 30000/60000 Training loss: 0.027198
Epoch: 5 40000/60000 Training loss: 0.006032
Epoch: 5 50000/60000 Training loss: 0.055968
Training loss: 0.028825
Test loss: 0.021979; Test accuracy: 9931/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.002986
Epoch: 6 10000/60000 Training loss: 0.046183
Epoch: 6 20000/60000 Training loss: 0.043340
Epoch: 6 30000/60000 Training loss: 0.045000
Epoch: 6 40000/60000 Training loss: 0.013155
Epoch: 6 50000/60000 Training loss: 0.004212
Training loss: 0.024604
Test loss: 0.024703; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.062585
Epoch: 7 10000/60000 Training loss: 0.001307
Epoch: 7 20000/60000 Training loss: 0.006388
Epoch: 7 30000/60000 Training loss: 0.020766
Epoch: 7 40000/60000 Training loss: 0.065739
Epoch: 7 50000/60000 Training loss: 0.010629
Training loss: 0.023530
Test loss: 0.022735; Test accuracy: 9931/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.003018
Epoch: 8 10000/60000 Training loss: 0.012984
Epoch: 8 20000/60000 Training loss: 0.008138
Epoch: 8 30000/60000 Training loss: 0.175803
Epoch: 8 40000/60000 Training loss: 0.018261
Epoch: 8 50000/60000 Training loss: 0.024482
Training loss: 0.021141
Test loss: 0.024858; Test accuracy: 9928/10000 (99.3%)

[I 2022-11-04 00:30:49,423] Trial 10 finished with value: 0.02197927050292492 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.05098173136253968, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.0009104572081189141}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 48, 'num_conv2_channels': 96, 'conv2_drop': 0.07690048345974439, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.00032462254004259094}
Epoch: 0 0/60000 Training loss: 2.338010
Epoch: 0 10000/60000 Training loss: 0.437448
Epoch: 0 20000/60000 Training loss: 0.319725
Epoch: 0 30000/60000 Training loss: 0.119628
Epoch: 0 40000/60000 Training loss: 0.183569
Epoch: 0 50000/60000 Training loss: 0.084018
Training loss: 0.318347
Test loss: 0.061507; Test accuracy: 9819/10000 (98.2%)

Epoch: 1 0/60000 Training loss: 0.120100
Epoch: 1 10000/60000 Training loss: 0.058607
Epoch: 1 20000/60000 Training loss: 0.072693
Epoch: 1 30000/60000 Training loss: 0.079716
Epoch: 1 40000/60000 Training loss: 0.055187
Epoch: 1 50000/60000 Training loss: 0.097996
Training loss: 0.097352
Test loss: 0.037378; Test accuracy: 9881/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.038783
Epoch: 2 10000/60000 Training loss: 0.093151
Epoch: 2 20000/60000 Training loss: 0.158588
Epoch: 2 30000/60000 Training loss: 0.047907
Epoch: 2 40000/60000 Training loss: 0.092086
Epoch: 2 50000/60000 Training loss: 0.020396
Training loss: 0.068832
Test loss: 0.029710; Test accuracy: 9899/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.021354
Epoch: 3 10000/60000 Training loss: 0.018688
Epoch: 3 20000/60000 Training loss: 0.050053
Epoch: 3 30000/60000 Training loss: 0.055728
Epoch: 3 40000/60000 Training loss: 0.029670
Epoch: 3 50000/60000 Training loss: 0.019873
Training loss: 0.056528
Test loss: 0.026519; Test accuracy: 9923/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.016697
Epoch: 4 10000/60000 Training loss: 0.040631
Epoch: 4 20000/60000 Training loss: 0.054943
Epoch: 4 30000/60000 Training loss: 0.035614
Epoch: 4 40000/60000 Training loss: 0.021838
Epoch: 4 50000/60000 Training loss: 0.123707
Training loss: 0.046668
Test loss: 0.025230; Test accuracy: 9912/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.045080
Epoch: 5 10000/60000 Training loss: 0.011188
Epoch: 5 20000/60000 Training loss: 0.044516
Epoch: 5 30000/60000 Training loss: 0.030810
Epoch: 5 40000/60000 Training loss: 0.085439
Epoch: 5 50000/60000 Training loss: 0.039122
Training loss: 0.040731
Test loss: 0.023848; Test accuracy: 9927/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.044975
Epoch: 6 10000/60000 Training loss: 0.030426
Epoch: 6 20000/60000 Training loss: 0.036862
Epoch: 6 30000/60000 Training loss: 0.018066
Epoch: 6 40000/60000 Training loss: 0.077047
Epoch: 6 50000/60000 Training loss: 0.016103
Training loss: 0.033319
Test loss: 0.023669; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.100638
Epoch: 7 10000/60000 Training loss: 0.015791
Epoch: 7 20000/60000 Training loss: 0.016754
Epoch: 7 30000/60000 Training loss: 0.003131
Epoch: 7 40000/60000 Training loss: 0.109892
Epoch: 7 50000/60000 Training loss: 0.014547
Training loss: 0.029989
Test loss: 0.019725; Test accuracy: 9934/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.012207
Epoch: 8 10000/60000 Training loss: 0.028691
Epoch: 8 20000/60000 Training loss: 0.029622
Epoch: 8 30000/60000 Training loss: 0.008162
Epoch: 8 40000/60000 Training loss: 0.026865
Epoch: 8 50000/60000 Training loss: 0.006861
Training loss: 0.026387
Test loss: 0.021424; Test accuracy: 9931/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.027285
Epoch: 9 10000/60000 Training loss: 0.010189
Epoch: 9 20000/60000 Training loss: 0.022374
Epoch: 9 30000/60000 Training loss: 0.009477
Epoch: 9 40000/60000 Training loss: 0.026003
Epoch: 9 50000/60000 Training loss: 0.001787
Training loss: 0.024710
Test loss: 0.021021; Test accuracy: 9940/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.001537
Epoch: 10 10000/60000 Training loss: 0.047386
Epoch: 10 20000/60000 Training loss: 0.009137
Epoch: 10 30000/60000 Training loss: 0.018863
Epoch: 10 40000/60000 Training loss: 0.004273
Epoch: 10 50000/60000 Training loss: 0.036494
Training loss: 0.023660
Test loss: 0.020567; Test accuracy: 9937/10000 (99.4%)

[I 2022-11-04 00:33:23,083] Trial 11 finished with value: 0.019725089892745018 and parameters: {'num_conv1_channels': 48, 'num_conv2_channels': 96, 'conv2_drop': 0.07690048345974439, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.00032462254004259094}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.1475598579632401, 'fc1_neurons': 70, 'optimizer': 'Adam', 'learning_rate': 0.00029736529670787367}
Epoch: 0 0/60000 Training loss: 2.326854
Epoch: 0 10000/60000 Training loss: 0.546314
Epoch: 0 20000/60000 Training loss: 0.420657
Epoch: 0 30000/60000 Training loss: 0.162157
Epoch: 0 40000/60000 Training loss: 0.130722
Epoch: 0 50000/60000 Training loss: 0.211051
Training loss: 0.351637
Test loss: 0.058886; Test accuracy: 9810/10000 (98.1%)

Epoch: 1 0/60000 Training loss: 0.135684
Epoch: 1 10000/60000 Training loss: 0.056612
Epoch: 1 20000/60000 Training loss: 0.164005
Epoch: 1 30000/60000 Training loss: 0.180016
Epoch: 1 40000/60000 Training loss: 0.134268
Epoch: 1 50000/60000 Training loss: 0.263601
Training loss: 0.118578
Test loss: 0.040530; Test accuracy: 9866/10000 (98.7%)

Epoch: 2 0/60000 Training loss: 0.134016
Epoch: 2 10000/60000 Training loss: 0.060818
Epoch: 2 20000/60000 Training loss: 0.080540
Epoch: 2 30000/60000 Training loss: 0.097762
Epoch: 2 40000/60000 Training loss: 0.098827
Epoch: 2 50000/60000 Training loss: 0.048235
Training loss: 0.085735
Test loss: 0.035738; Test accuracy: 9878/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.049050
Epoch: 3 10000/60000 Training loss: 0.068425
Epoch: 3 20000/60000 Training loss: 0.128779
Epoch: 3 30000/60000 Training loss: 0.086997
Epoch: 3 40000/60000 Training loss: 0.070104
Epoch: 3 50000/60000 Training loss: 0.029017
Training loss: 0.067562
Test loss: 0.028847; Test accuracy: 9906/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.046942
Epoch: 4 10000/60000 Training loss: 0.033715
Epoch: 4 20000/60000 Training loss: 0.017914
Epoch: 4 30000/60000 Training loss: 0.029336
Epoch: 4 40000/60000 Training loss: 0.054950
Epoch: 4 50000/60000 Training loss: 0.161802
Training loss: 0.056480
Test loss: 0.022728; Test accuracy: 9930/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.023541
Epoch: 5 10000/60000 Training loss: 0.017530
Epoch: 5 20000/60000 Training loss: 0.045054
Epoch: 5 30000/60000 Training loss: 0.005684
Epoch: 5 40000/60000 Training loss: 0.020471
Epoch: 5 50000/60000 Training loss: 0.035136
Training loss: 0.048729
Test loss: 0.022237; Test accuracy: 9932/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.070263
Epoch: 6 10000/60000 Training loss: 0.047267
Epoch: 6 20000/60000 Training loss: 0.048699
Epoch: 6 30000/60000 Training loss: 0.059475
Epoch: 6 40000/60000 Training loss: 0.010931
Epoch: 6 50000/60000 Training loss: 0.099213
Training loss: 0.043751
Test loss: 0.022289; Test accuracy: 9926/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.018105
Epoch: 7 10000/60000 Training loss: 0.035061
Epoch: 7 20000/60000 Training loss: 0.010544
Epoch: 7 30000/60000 Training loss: 0.084925
Epoch: 7 40000/60000 Training loss: 0.015439
Epoch: 7 50000/60000 Training loss: 0.029686
Training loss: 0.037290
Test loss: 0.018501; Test accuracy: 9934/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.016760
Epoch: 8 10000/60000 Training loss: 0.020186
Epoch: 8 20000/60000 Training loss: 0.040903
Epoch: 8 30000/60000 Training loss: 0.012715
Epoch: 8 40000/60000 Training loss: 0.014161
Epoch: 8 50000/60000 Training loss: 0.011996
Training loss: 0.034166
Test loss: 0.019259; Test accuracy: 9940/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.029453
Epoch: 9 10000/60000 Training loss: 0.016587
Epoch: 9 20000/60000 Training loss: 0.051142
Epoch: 9 30000/60000 Training loss: 0.014456
Epoch: 9 40000/60000 Training loss: 0.037165
Epoch: 9 50000/60000 Training loss: 0.013935
Training loss: 0.030855
Test loss: 0.020721; Test accuracy: 9931/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.018268
Epoch: 10 10000/60000 Training loss: 0.008058
Epoch: 10 20000/60000 Training loss: 0.017993
Epoch: 10 30000/60000 Training loss: 0.037261
Epoch: 10 40000/60000 Training loss: 0.018845
Epoch: 10 50000/60000 Training loss: 0.001104
Training loss: 0.027582
Test loss: 0.019132; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 00:35:57,745] Trial 12 finished with value: 0.01850122958421707 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.1475598579632401, 'fc1_neurons': 70, 'optimizer': 'Adam', 'learning_rate': 0.00029736529670787367}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.1498803294100577, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 0.000642122329299245}
Epoch: 0 0/60000 Training loss: 2.310053
Epoch: 0 10000/60000 Training loss: 0.384520
Epoch: 0 20000/60000 Training loss: 0.203223
Epoch: 0 30000/60000 Training loss: 0.246545
Epoch: 0 40000/60000 Training loss: 0.178767
Epoch: 0 50000/60000 Training loss: 0.155505
Training loss: 0.296954
Test loss: 0.048603; Test accuracy: 9844/10000 (98.4%)

Epoch: 1 0/60000 Training loss: 0.086537
Epoch: 1 10000/60000 Training loss: 0.162717
Epoch: 1 20000/60000 Training loss: 0.034308
Epoch: 1 30000/60000 Training loss: 0.077495
Epoch: 1 40000/60000 Training loss: 0.069751
Epoch: 1 50000/60000 Training loss: 0.106454
Training loss: 0.101503
Test loss: 0.037464; Test accuracy: 9882/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.051933
Epoch: 2 10000/60000 Training loss: 0.123989
Epoch: 2 20000/60000 Training loss: 0.074786
Epoch: 2 30000/60000 Training loss: 0.055969
Epoch: 2 40000/60000 Training loss: 0.034481
Epoch: 2 50000/60000 Training loss: 0.049890
Training loss: 0.073395
Test loss: 0.034038; Test accuracy: 9893/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.030481
Epoch: 3 10000/60000 Training loss: 0.186119
Epoch: 3 20000/60000 Training loss: 0.140471
Epoch: 3 30000/60000 Training loss: 0.230593
Epoch: 3 40000/60000 Training loss: 0.059086
Epoch: 3 50000/60000 Training loss: 0.057459
Training loss: 0.060125
Test loss: 0.026728; Test accuracy: 9919/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.047193
Epoch: 4 10000/60000 Training loss: 0.012283
Epoch: 4 20000/60000 Training loss: 0.076222
Epoch: 4 30000/60000 Training loss: 0.026296
Epoch: 4 40000/60000 Training loss: 0.033053
Epoch: 4 50000/60000 Training loss: 0.024766
Training loss: 0.050729
Test loss: 0.025319; Test accuracy: 9917/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.051690
Epoch: 5 10000/60000 Training loss: 0.028283
Epoch: 5 20000/60000 Training loss: 0.018263
Epoch: 5 30000/60000 Training loss: 0.036706
Epoch: 5 40000/60000 Training loss: 0.102378
Epoch: 5 50000/60000 Training loss: 0.058546
Training loss: 0.045585
Test loss: 0.022412; Test accuracy: 9925/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.026887
Epoch: 6 10000/60000 Training loss: 0.112395
Epoch: 6 20000/60000 Training loss: 0.009395
Epoch: 6 30000/60000 Training loss: 0.186088
Epoch: 6 40000/60000 Training loss: 0.044716
Epoch: 6 50000/60000 Training loss: 0.044247
Training loss: 0.042282
Test loss: 0.029630; Test accuracy: 9906/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.019414
Epoch: 7 10000/60000 Training loss: 0.027772
Epoch: 7 20000/60000 Training loss: 0.024216
Epoch: 7 30000/60000 Training loss: 0.053438
Epoch: 7 40000/60000 Training loss: 0.020679
Epoch: 7 50000/60000 Training loss: 0.008323
Training loss: 0.037025
Test loss: 0.027653; Test accuracy: 9915/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.029550
Epoch: 8 10000/60000 Training loss: 0.024914
Epoch: 8 20000/60000 Training loss: 0.146472
Epoch: 8 30000/60000 Training loss: 0.006030
Epoch: 8 40000/60000 Training loss: 0.034493
Epoch: 8 50000/60000 Training loss: 0.018268
Training loss: 0.034790
Test loss: 0.022827; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 00:38:04,212] Trial 13 finished with value: 0.022412462159991264 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.1498803294100577, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 0.000642122329299245}. Best is trial 7 with value: 0.018089881166815758.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16309149290927577, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 0.00018501940576309242}
Epoch: 0 0/60000 Training loss: 2.290019
Epoch: 0 10000/60000 Training loss: 0.476033
Epoch: 0 20000/60000 Training loss: 0.275898
Epoch: 0 30000/60000 Training loss: 0.217396
Epoch: 0 40000/60000 Training loss: 0.337677
Epoch: 0 50000/60000 Training loss: 0.103943
Training loss: 0.399374
Test loss: 0.071321; Test accuracy: 9771/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.115663
Epoch: 1 10000/60000 Training loss: 0.067693
Epoch: 1 20000/60000 Training loss: 0.160378
Epoch: 1 30000/60000 Training loss: 0.128578
Epoch: 1 40000/60000 Training loss: 0.096217
Epoch: 1 50000/60000 Training loss: 0.096037
Training loss: 0.124705
Test loss: 0.045194; Test accuracy: 9854/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.080668
Epoch: 2 10000/60000 Training loss: 0.028910
Epoch: 2 20000/60000 Training loss: 0.083082
Epoch: 2 30000/60000 Training loss: 0.114100
Epoch: 2 40000/60000 Training loss: 0.117699
Epoch: 2 50000/60000 Training loss: 0.079174
Training loss: 0.089278
Test loss: 0.035285; Test accuracy: 9882/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.075787
Epoch: 3 10000/60000 Training loss: 0.117057
Epoch: 3 20000/60000 Training loss: 0.026770
Epoch: 3 30000/60000 Training loss: 0.027598
Epoch: 3 40000/60000 Training loss: 0.028572
Epoch: 3 50000/60000 Training loss: 0.034978
Training loss: 0.073011
Test loss: 0.028116; Test accuracy: 9906/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.078483
Epoch: 4 10000/60000 Training loss: 0.035852
Epoch: 4 20000/60000 Training loss: 0.179064
Epoch: 4 30000/60000 Training loss: 0.080557
Epoch: 4 40000/60000 Training loss: 0.013398
Epoch: 4 50000/60000 Training loss: 0.072652
Training loss: 0.062549
Test loss: 0.026387; Test accuracy: 9915/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.045515
Epoch: 5 10000/60000 Training loss: 0.168015
Epoch: 5 20000/60000 Training loss: 0.021893
Epoch: 5 30000/60000 Training loss: 0.016996
Epoch: 5 40000/60000 Training loss: 0.057981
Epoch: 5 50000/60000 Training loss: 0.039932
Training loss: 0.053823
Test loss: 0.024784; Test accuracy: 9919/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.016019
Epoch: 6 10000/60000 Training loss: 0.027757
Epoch: 6 20000/60000 Training loss: 0.023201
Epoch: 6 30000/60000 Training loss: 0.047166
Epoch: 6 40000/60000 Training loss: 0.030866
Epoch: 6 50000/60000 Training loss: 0.021640
Training loss: 0.046083
Test loss: 0.021366; Test accuracy: 9927/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.030088
Epoch: 7 10000/60000 Training loss: 0.043098
Epoch: 7 20000/60000 Training loss: 0.025860
Epoch: 7 30000/60000 Training loss: 0.028821
Epoch: 7 40000/60000 Training loss: 0.034330
Epoch: 7 50000/60000 Training loss: 0.023868
Training loss: 0.041702
Test loss: 0.022987; Test accuracy: 9919/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.019885
Epoch: 8 10000/60000 Training loss: 0.007879
Epoch: 8 20000/60000 Training loss: 0.024950
Epoch: 8 30000/60000 Training loss: 0.075267
Epoch: 8 40000/60000 Training loss: 0.013567
Epoch: 8 50000/60000 Training loss: 0.040367
Training loss: 0.037277
Test loss: 0.020387; Test accuracy: 9932/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.007528
Epoch: 9 10000/60000 Training loss: 0.021955
Epoch: 9 20000/60000 Training loss: 0.018596
Epoch: 9 30000/60000 Training loss: 0.010467
Epoch: 9 40000/60000 Training loss: 0.024160
Epoch: 9 50000/60000 Training loss: 0.054065
Training loss: 0.035362
Test loss: 0.020543; Test accuracy: 9929/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.041119
Epoch: 10 10000/60000 Training loss: 0.004922
Epoch: 10 20000/60000 Training loss: 0.019659
Epoch: 10 30000/60000 Training loss: 0.040778
Epoch: 10 40000/60000 Training loss: 0.020134
Epoch: 10 50000/60000 Training loss: 0.020551
Training loss: 0.030694
Test loss: 0.020801; Test accuracy: 9928/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.006533
Epoch: 11 10000/60000 Training loss: 0.023500
Epoch: 11 20000/60000 Training loss: 0.036147
Epoch: 11 30000/60000 Training loss: 0.023944
Epoch: 11 40000/60000 Training loss: 0.005356
Epoch: 11 50000/60000 Training loss: 0.049904
Training loss: 0.029610
Test loss: 0.017991; Test accuracy: 9945/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.050333
Epoch: 12 10000/60000 Training loss: 0.029021
Epoch: 12 20000/60000 Training loss: 0.008081
Epoch: 12 30000/60000 Training loss: 0.006343
Epoch: 12 40000/60000 Training loss: 0.003053
Epoch: 12 50000/60000 Training loss: 0.032409
Training loss: 0.026642
Test loss: 0.018203; Test accuracy: 9946/10000 (99.5%)

Epoch: 13 0/60000 Training loss: 0.024151
Epoch: 13 10000/60000 Training loss: 0.040894
Epoch: 13 20000/60000 Training loss: 0.020285
Epoch: 13 30000/60000 Training loss: 0.015108
Epoch: 13 40000/60000 Training loss: 0.022660
Epoch: 13 50000/60000 Training loss: 0.003807
Training loss: 0.024496
Test loss: 0.019150; Test accuracy: 9942/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.040890
Epoch: 14 10000/60000 Training loss: 0.028247
Epoch: 14 20000/60000 Training loss: 0.030297
Epoch: 14 30000/60000 Training loss: 0.019220
Epoch: 14 40000/60000 Training loss: 0.008087
Epoch: 14 50000/60000 Training loss: 0.002603
Training loss: 0.021327
Test loss: 0.019337; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 00:41:35,144] Trial 14 finished with value: 0.01799141988158226 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16309149290927577, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 0.00018501940576309242}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.16571947732627867, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00016896519866248979}
Epoch: 0 0/60000 Training loss: 2.335775
Epoch: 0 10000/60000 Training loss: 0.501956
Epoch: 0 20000/60000 Training loss: 0.222122
Epoch: 0 30000/60000 Training loss: 0.170659
Epoch: 0 40000/60000 Training loss: 0.240407
Epoch: 0 50000/60000 Training loss: 0.156350
Training loss: 0.361052
Test loss: 0.069248; Test accuracy: 9791/10000 (97.9%)

Epoch: 1 0/60000 Training loss: 0.084701
Epoch: 1 10000/60000 Training loss: 0.096603
Epoch: 1 20000/60000 Training loss: 0.068536
Epoch: 1 30000/60000 Training loss: 0.188303
Epoch: 1 40000/60000 Training loss: 0.100522
Epoch: 1 50000/60000 Training loss: 0.110571
Training loss: 0.111416
Test loss: 0.044740; Test accuracy: 9859/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.057352
Epoch: 2 10000/60000 Training loss: 0.077240
Epoch: 2 20000/60000 Training loss: 0.030962
Epoch: 2 30000/60000 Training loss: 0.058908
Epoch: 2 40000/60000 Training loss: 0.159992
Epoch: 2 50000/60000 Training loss: 0.065910
Training loss: 0.078119
Test loss: 0.034745; Test accuracy: 9884/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.095966
Epoch: 3 10000/60000 Training loss: 0.145333
Epoch: 3 20000/60000 Training loss: 0.035393
Epoch: 3 30000/60000 Training loss: 0.029203
Epoch: 3 40000/60000 Training loss: 0.107505
Epoch: 3 50000/60000 Training loss: 0.105089
Training loss: 0.064019
Test loss: 0.029282; Test accuracy: 9898/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.039754
Epoch: 4 10000/60000 Training loss: 0.041615
Epoch: 4 20000/60000 Training loss: 0.021915
Epoch: 4 30000/60000 Training loss: 0.035759
Epoch: 4 40000/60000 Training loss: 0.049426
Epoch: 4 50000/60000 Training loss: 0.083313
Training loss: 0.053949
Test loss: 0.027698; Test accuracy: 9903/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.095403
Epoch: 5 10000/60000 Training loss: 0.049080
Epoch: 5 20000/60000 Training loss: 0.034574
Epoch: 5 30000/60000 Training loss: 0.046865
Epoch: 5 40000/60000 Training loss: 0.027714
Epoch: 5 50000/60000 Training loss: 0.073082
Training loss: 0.047001
Test loss: 0.024801; Test accuracy: 9919/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.049210
Epoch: 6 10000/60000 Training loss: 0.026014
Epoch: 6 20000/60000 Training loss: 0.032819
Epoch: 6 30000/60000 Training loss: 0.016075
Epoch: 6 40000/60000 Training loss: 0.020121
Epoch: 6 50000/60000 Training loss: 0.022533
Training loss: 0.041141
Test loss: 0.023495; Test accuracy: 9920/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.048445
Epoch: 7 10000/60000 Training loss: 0.012408
Epoch: 7 20000/60000 Training loss: 0.010013
Epoch: 7 30000/60000 Training loss: 0.011450
Epoch: 7 40000/60000 Training loss: 0.057370
Epoch: 7 50000/60000 Training loss: 0.072439
Training loss: 0.036941
Test loss: 0.022836; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.015652
Epoch: 8 10000/60000 Training loss: 0.050902
Epoch: 8 20000/60000 Training loss: 0.047895
Epoch: 8 30000/60000 Training loss: 0.068119
Epoch: 8 40000/60000 Training loss: 0.050125
Epoch: 8 50000/60000 Training loss: 0.003064
Training loss: 0.032249
Test loss: 0.022041; Test accuracy: 9925/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.057141
Epoch: 9 10000/60000 Training loss: 0.059353
Epoch: 9 20000/60000 Training loss: 0.034039
Epoch: 9 30000/60000 Training loss: 0.017184
Epoch: 9 40000/60000 Training loss: 0.005035
Epoch: 9 50000/60000 Training loss: 0.065705
Training loss: 0.029880
Test loss: 0.020732; Test accuracy: 9937/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.020685
Epoch: 10 10000/60000 Training loss: 0.042638
Epoch: 10 20000/60000 Training loss: 0.094842
Epoch: 10 30000/60000 Training loss: 0.031741
Epoch: 10 40000/60000 Training loss: 0.007328
Epoch: 10 50000/60000 Training loss: 0.012591
Training loss: 0.027267
Test loss: 0.019803; Test accuracy: 9940/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.020581
Epoch: 11 10000/60000 Training loss: 0.022682
Epoch: 11 20000/60000 Training loss: 0.003709
Epoch: 11 30000/60000 Training loss: 0.044105
Epoch: 11 40000/60000 Training loss: 0.028493
Epoch: 11 50000/60000 Training loss: 0.001878
Training loss: 0.026383
Test loss: 0.022887; Test accuracy: 9927/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.027528
Epoch: 12 10000/60000 Training loss: 0.028738
Epoch: 12 20000/60000 Training loss: 0.018294
Epoch: 12 30000/60000 Training loss: 0.008097
Epoch: 12 40000/60000 Training loss: 0.009010
Epoch: 12 50000/60000 Training loss: 0.009502
Training loss: 0.024336
Test loss: 0.021255; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.008586
Epoch: 13 10000/60000 Training loss: 0.023985
Epoch: 13 20000/60000 Training loss: 0.004821
Epoch: 13 30000/60000 Training loss: 0.034199
Epoch: 13 40000/60000 Training loss: 0.022981
Epoch: 13 50000/60000 Training loss: 0.002245
Training loss: 0.021683
Test loss: 0.018853; Test accuracy: 9939/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.041414
Epoch: 14 10000/60000 Training loss: 0.002169
Epoch: 14 20000/60000 Training loss: 0.012154
Epoch: 14 30000/60000 Training loss: 0.022767
Epoch: 14 40000/60000 Training loss: 0.029757
Epoch: 14 50000/60000 Training loss: 0.059729
Training loss: 0.019676
Test loss: 0.019116; Test accuracy: 9939/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.028161
Epoch: 15 10000/60000 Training loss: 0.007662
Epoch: 15 20000/60000 Training loss: 0.003055
Epoch: 15 30000/60000 Training loss: 0.005448
Epoch: 15 40000/60000 Training loss: 0.015370
Epoch: 15 50000/60000 Training loss: 0.032009
Training loss: 0.019022
Test loss: 0.018640; Test accuracy: 9942/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.019107
Epoch: 16 10000/60000 Training loss: 0.007841
Epoch: 16 20000/60000 Training loss: 0.015922
Epoch: 16 30000/60000 Training loss: 0.002933
Epoch: 16 40000/60000 Training loss: 0.003515
Epoch: 16 50000/60000 Training loss: 0.055062
Training loss: 0.017116
Test loss: 0.019273; Test accuracy: 9934/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.032529
Epoch: 17 10000/60000 Training loss: 0.004623
Epoch: 17 20000/60000 Training loss: 0.001272
Epoch: 17 30000/60000 Training loss: 0.015551
Epoch: 17 40000/60000 Training loss: 0.033593
Epoch: 17 50000/60000 Training loss: 0.040240
Training loss: 0.014664
Test loss: 0.018636; Test accuracy: 9946/10000 (99.5%)

Epoch: 18 0/60000 Training loss: 0.001338
Epoch: 18 10000/60000 Training loss: 0.005967
Epoch: 18 20000/60000 Training loss: 0.001905
Epoch: 18 30000/60000 Training loss: 0.013961
Epoch: 18 40000/60000 Training loss: 0.047710
Epoch: 18 50000/60000 Training loss: 0.002628
Training loss: 0.015043
Test loss: 0.018032; Test accuracy: 9946/10000 (99.5%)

Epoch: 19 0/60000 Training loss: 0.033596
Epoch: 19 10000/60000 Training loss: 0.008538
Epoch: 19 20000/60000 Training loss: 0.001173
Epoch: 19 30000/60000 Training loss: 0.006660
Epoch: 19 40000/60000 Training loss: 0.003828
Epoch: 19 50000/60000 Training loss: 0.001605
Training loss: 0.014225
Test loss: 0.018329; Test accuracy: 9945/10000 (99.4%)

[I 2022-11-04 00:46:16,426] Trial 15 finished with value: 0.018031585961580276 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.16571947732627867, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00016896519866248979}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 16, 'conv2_drop': 0.16755576978397985, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 1.1225466743209401e-05}
Epoch: 0 0/60000 Training loss: 2.305890
Epoch: 0 10000/60000 Training loss: 2.235957
Epoch: 0 20000/60000 Training loss: 2.141888
Epoch: 0 30000/60000 Training loss: 2.053633
Epoch: 0 40000/60000 Training loss: 1.792325
Epoch: 0 50000/60000 Training loss: 1.631209
Training loss: 1.959335
Test loss: 1.219714; Test accuracy: 7818/10000 (78.2%)

Epoch: 1 0/60000 Training loss: 1.494544
Epoch: 1 10000/60000 Training loss: 1.328034
Epoch: 1 20000/60000 Training loss: 1.149972
Epoch: 1 30000/60000 Training loss: 0.989773
Epoch: 1 40000/60000 Training loss: 0.823447
Epoch: 1 50000/60000 Training loss: 0.883443
Training loss: 1.093319
Test loss: 0.572397; Test accuracy: 8791/10000 (87.9%)

Epoch: 2 0/60000 Training loss: 0.839155
Epoch: 2 10000/60000 Training loss: 0.979634
Epoch: 2 20000/60000 Training loss: 0.823308
Epoch: 2 30000/60000 Training loss: 0.707485
Epoch: 2 40000/60000 Training loss: 0.712135
Epoch: 2 50000/60000 Training loss: 0.512047
Training loss: 0.750306
Test loss: 0.390191; Test accuracy: 9053/10000 (90.5%)

Epoch: 3 0/60000 Training loss: 0.749155
Epoch: 3 10000/60000 Training loss: 0.709666
Epoch: 3 20000/60000 Training loss: 0.575401
Epoch: 3 30000/60000 Training loss: 0.572075
Epoch: 3 40000/60000 Training loss: 0.491688
Epoch: 3 50000/60000 Training loss: 0.504098
Training loss: 0.596447
Test loss: 0.306452; Test accuracy: 9213/10000 (92.1%)

Epoch: 4 0/60000 Training loss: 0.420120
Epoch: 4 10000/60000 Training loss: 0.580302
Epoch: 4 20000/60000 Training loss: 0.604463
Epoch: 4 30000/60000 Training loss: 0.563487
Epoch: 4 40000/60000 Training loss: 0.548860
Epoch: 4 50000/60000 Training loss: 0.459472
Training loss: 0.504640
Test loss: 0.255044; Test accuracy: 9327/10000 (93.3%)

Epoch: 5 0/60000 Training loss: 0.576790
Epoch: 5 10000/60000 Training loss: 0.397068
Epoch: 5 20000/60000 Training loss: 0.320138
Epoch: 5 30000/60000 Training loss: 0.482564
Epoch: 5 40000/60000 Training loss: 0.756393
Epoch: 5 50000/60000 Training loss: 0.446026
Training loss: 0.438726
Test loss: 0.220060; Test accuracy: 9407/10000 (94.1%)

Epoch: 6 0/60000 Training loss: 0.372653
Epoch: 6 10000/60000 Training loss: 0.267976
Epoch: 6 20000/60000 Training loss: 0.420953
Epoch: 6 30000/60000 Training loss: 0.400816
Epoch: 6 40000/60000 Training loss: 0.397018
Epoch: 6 50000/60000 Training loss: 0.316672
Training loss: 0.390616
Test loss: 0.194377; Test accuracy: 9463/10000 (94.6%)

Epoch: 7 0/60000 Training loss: 0.367981
Epoch: 7 10000/60000 Training loss: 0.362807
Epoch: 7 20000/60000 Training loss: 0.352033
Epoch: 7 30000/60000 Training loss: 0.427434
Epoch: 7 40000/60000 Training loss: 0.323492
Epoch: 7 50000/60000 Training loss: 0.212031
Training loss: 0.354756
Test loss: 0.175491; Test accuracy: 9506/10000 (95.1%)

Epoch: 8 0/60000 Training loss: 0.252384
Epoch: 8 10000/60000 Training loss: 0.282311
Epoch: 8 20000/60000 Training loss: 0.307563
Epoch: 8 30000/60000 Training loss: 0.320409
Epoch: 8 40000/60000 Training loss: 0.380364
Epoch: 8 50000/60000 Training loss: 0.167447
Training loss: 0.323790
Test loss: 0.159893; Test accuracy: 9550/10000 (95.5%)

Epoch: 9 0/60000 Training loss: 0.414299
Epoch: 9 10000/60000 Training loss: 0.287263
Epoch: 9 20000/60000 Training loss: 0.380368
Epoch: 9 30000/60000 Training loss: 0.314778
Epoch: 9 40000/60000 Training loss: 0.203922
Epoch: 9 50000/60000 Training loss: 0.259937
Training loss: 0.299038
Test loss: 0.147266; Test accuracy: 9579/10000 (95.8%)

Epoch: 10 0/60000 Training loss: 0.311797
Epoch: 10 10000/60000 Training loss: 0.274601
Epoch: 10 20000/60000 Training loss: 0.308724
Epoch: 10 30000/60000 Training loss: 0.357653
Epoch: 10 40000/60000 Training loss: 0.274900
Epoch: 10 50000/60000 Training loss: 0.181307
Training loss: 0.282574
Test loss: 0.136880; Test accuracy: 9599/10000 (96.0%)

Epoch: 11 0/60000 Training loss: 0.210648
Epoch: 11 10000/60000 Training loss: 0.189829
Epoch: 11 20000/60000 Training loss: 0.249261
Epoch: 11 30000/60000 Training loss: 0.230574
Epoch: 11 40000/60000 Training loss: 0.178343
Epoch: 11 50000/60000 Training loss: 0.232775
Training loss: 0.265306
Test loss: 0.129167; Test accuracy: 9620/10000 (96.2%)

Epoch: 12 0/60000 Training loss: 0.276854
Epoch: 12 10000/60000 Training loss: 0.206636
Epoch: 12 20000/60000 Training loss: 0.333215
Epoch: 12 30000/60000 Training loss: 0.237700
Epoch: 12 40000/60000 Training loss: 0.322220
Epoch: 12 50000/60000 Training loss: 0.193694
Training loss: 0.245236
Test loss: 0.121461; Test accuracy: 9641/10000 (96.4%)

Epoch: 13 0/60000 Training loss: 0.259722
Epoch: 13 10000/60000 Training loss: 0.245731
Epoch: 13 20000/60000 Training loss: 0.247551
Epoch: 13 30000/60000 Training loss: 0.176395
Epoch: 13 40000/60000 Training loss: 0.280185
Epoch: 13 50000/60000 Training loss: 0.231818
Training loss: 0.236636
Test loss: 0.114955; Test accuracy: 9659/10000 (96.6%)

Epoch: 14 0/60000 Training loss: 0.163931
Epoch: 14 10000/60000 Training loss: 0.168938
Epoch: 14 20000/60000 Training loss: 0.166177
Epoch: 14 30000/60000 Training loss: 0.331247
Epoch: 14 40000/60000 Training loss: 0.217490
Epoch: 14 50000/60000 Training loss: 0.257139
Training loss: 0.220388
Test loss: 0.108439; Test accuracy: 9677/10000 (96.8%)

Epoch: 15 0/60000 Training loss: 0.246466
Epoch: 15 10000/60000 Training loss: 0.267284
Epoch: 15 20000/60000 Training loss: 0.201053
Epoch: 15 30000/60000 Training loss: 0.319663
Epoch: 15 40000/60000 Training loss: 0.324947
Epoch: 15 50000/60000 Training loss: 0.209491
Training loss: 0.213774
Test loss: 0.103285; Test accuracy: 9683/10000 (96.8%)

Epoch: 16 0/60000 Training loss: 0.176308
Epoch: 16 10000/60000 Training loss: 0.138114
Epoch: 16 20000/60000 Training loss: 0.294992
Epoch: 16 30000/60000 Training loss: 0.299469
Epoch: 16 40000/60000 Training loss: 0.115535
Epoch: 16 50000/60000 Training loss: 0.239369
Training loss: 0.204248
Test loss: 0.097978; Test accuracy: 9691/10000 (96.9%)

Epoch: 17 0/60000 Training loss: 0.414155
Epoch: 17 10000/60000 Training loss: 0.155430
Epoch: 17 20000/60000 Training loss: 0.210136
Epoch: 17 30000/60000 Training loss: 0.319893
Epoch: 17 40000/60000 Training loss: 0.114286
Epoch: 17 50000/60000 Training loss: 0.125362
Training loss: 0.195623
Test loss: 0.094018; Test accuracy: 9704/10000 (97.0%)

Epoch: 18 0/60000 Training loss: 0.197438
Epoch: 18 10000/60000 Training loss: 0.197135
Epoch: 18 20000/60000 Training loss: 0.158986
Epoch: 18 30000/60000 Training loss: 0.185604
Epoch: 18 40000/60000 Training loss: 0.094756
Epoch: 18 50000/60000 Training loss: 0.157073
Training loss: 0.190339
Test loss: 0.090708; Test accuracy: 9713/10000 (97.1%)

Epoch: 19 0/60000 Training loss: 0.186956
Epoch: 19 10000/60000 Training loss: 0.216422
Epoch: 19 20000/60000 Training loss: 0.322141
Epoch: 19 30000/60000 Training loss: 0.163544
Epoch: 19 40000/60000 Training loss: 0.225059
Epoch: 19 50000/60000 Training loss: 0.151791
Training loss: 0.179257
Test loss: 0.086704; Test accuracy: 9727/10000 (97.3%)

[I 2022-11-04 00:50:56,295] Trial 16 finished with value: 0.08670416474342346 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 16, 'conv2_drop': 0.16755576978397985, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 1.1225466743209401e-05}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.17043372578606336, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00018768545507960813}
Epoch: 0 0/60000 Training loss: 2.294258
Epoch: 0 10000/60000 Training loss: 0.550405
Epoch: 0 20000/60000 Training loss: 0.326023
Epoch: 0 30000/60000 Training loss: 0.268552
Epoch: 0 40000/60000 Training loss: 0.118510
Epoch: 0 50000/60000 Training loss: 0.160022
Training loss: 0.382584
Test loss: 0.084422; Test accuracy: 9742/10000 (97.4%)

Epoch: 1 0/60000 Training loss: 0.114583
Epoch: 1 10000/60000 Training loss: 0.100293
Epoch: 1 20000/60000 Training loss: 0.057262
Epoch: 1 30000/60000 Training loss: 0.136058
Epoch: 1 40000/60000 Training loss: 0.094177
Epoch: 1 50000/60000 Training loss: 0.142635
Training loss: 0.118788
Test loss: 0.047652; Test accuracy: 9850/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.041723
Epoch: 2 10000/60000 Training loss: 0.064342
Epoch: 2 20000/60000 Training loss: 0.050498
Epoch: 2 30000/60000 Training loss: 0.070601
Epoch: 2 40000/60000 Training loss: 0.028927
Epoch: 2 50000/60000 Training loss: 0.105806
Training loss: 0.084130
Test loss: 0.035555; Test accuracy: 9889/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.095731
Epoch: 3 10000/60000 Training loss: 0.047253
Epoch: 3 20000/60000 Training loss: 0.039400
Epoch: 3 30000/60000 Training loss: 0.084401
Epoch: 3 40000/60000 Training loss: 0.042413
Epoch: 3 50000/60000 Training loss: 0.109668
Training loss: 0.067507
Test loss: 0.031722; Test accuracy: 9898/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.044205
Epoch: 4 10000/60000 Training loss: 0.020502
Epoch: 4 20000/60000 Training loss: 0.090924
Epoch: 4 30000/60000 Training loss: 0.021460
Epoch: 4 40000/60000 Training loss: 0.123098
Epoch: 4 50000/60000 Training loss: 0.056858
Training loss: 0.055453
Test loss: 0.030323; Test accuracy: 9897/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.095214
Epoch: 5 10000/60000 Training loss: 0.030340
Epoch: 5 20000/60000 Training loss: 0.049187
Epoch: 5 30000/60000 Training loss: 0.151334
Epoch: 5 40000/60000 Training loss: 0.092459
Epoch: 5 50000/60000 Training loss: 0.059556
Training loss: 0.050097
Test loss: 0.026997; Test accuracy: 9907/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.085014
Epoch: 6 10000/60000 Training loss: 0.061412
Epoch: 6 20000/60000 Training loss: 0.068748
Epoch: 6 30000/60000 Training loss: 0.008288
Epoch: 6 40000/60000 Training loss: 0.040215
Epoch: 6 50000/60000 Training loss: 0.054470
Training loss: 0.043350
Test loss: 0.022940; Test accuracy: 9923/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.054201
Epoch: 7 10000/60000 Training loss: 0.016216
Epoch: 7 20000/60000 Training loss: 0.038208
Epoch: 7 30000/60000 Training loss: 0.070835
Epoch: 7 40000/60000 Training loss: 0.019197
Epoch: 7 50000/60000 Training loss: 0.010127
Training loss: 0.038061
Test loss: 0.023541; Test accuracy: 9917/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.061531
Epoch: 8 10000/60000 Training loss: 0.005298
Epoch: 8 20000/60000 Training loss: 0.040754
Epoch: 8 30000/60000 Training loss: 0.055935
Epoch: 8 40000/60000 Training loss: 0.045505
Epoch: 8 50000/60000 Training loss: 0.061663
Training loss: 0.035900
Test loss: 0.022398; Test accuracy: 9929/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.017807
Epoch: 9 10000/60000 Training loss: 0.037567
Epoch: 9 20000/60000 Training loss: 0.027322
Epoch: 9 30000/60000 Training loss: 0.043556
Epoch: 9 40000/60000 Training loss: 0.035984
Epoch: 9 50000/60000 Training loss: 0.011662
Training loss: 0.032303
Test loss: 0.021982; Test accuracy: 9932/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.011498
Epoch: 10 10000/60000 Training loss: 0.064215
Epoch: 10 20000/60000 Training loss: 0.002910
Epoch: 10 30000/60000 Training loss: 0.003626
Epoch: 10 40000/60000 Training loss: 0.007814
Epoch: 10 50000/60000 Training loss: 0.004728
Training loss: 0.028274
Test loss: 0.020293; Test accuracy: 9935/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.046367
Epoch: 11 10000/60000 Training loss: 0.039068
Epoch: 11 20000/60000 Training loss: 0.029681
Epoch: 11 30000/60000 Training loss: 0.002558
Epoch: 11 40000/60000 Training loss: 0.006405
Epoch: 11 50000/60000 Training loss: 0.039856
Training loss: 0.026624
Test loss: 0.019553; Test accuracy: 9938/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.002607
Epoch: 12 10000/60000 Training loss: 0.014265
Epoch: 12 20000/60000 Training loss: 0.004005
Epoch: 12 30000/60000 Training loss: 0.037952
Epoch: 12 40000/60000 Training loss: 0.011686
Epoch: 12 50000/60000 Training loss: 0.010314
Training loss: 0.023527
Test loss: 0.019114; Test accuracy: 9942/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.019416
Epoch: 13 10000/60000 Training loss: 0.012389
Epoch: 13 20000/60000 Training loss: 0.011480
Epoch: 13 30000/60000 Training loss: 0.025348
Epoch: 13 40000/60000 Training loss: 0.003115
Epoch: 13 50000/60000 Training loss: 0.005109
Training loss: 0.022356
Test loss: 0.018034; Test accuracy: 9941/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.001526
Epoch: 14 10000/60000 Training loss: 0.029728
Epoch: 14 20000/60000 Training loss: 0.051992
Epoch: 14 30000/60000 Training loss: 0.064654
Epoch: 14 40000/60000 Training loss: 0.011542
Epoch: 14 50000/60000 Training loss: 0.016461
Training loss: 0.021976
Test loss: 0.018037; Test accuracy: 9934/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.002322
Epoch: 15 10000/60000 Training loss: 0.007272
Epoch: 15 20000/60000 Training loss: 0.022540
Epoch: 15 30000/60000 Training loss: 0.005699
Epoch: 15 40000/60000 Training loss: 0.067796
Epoch: 15 50000/60000 Training loss: 0.001825
Training loss: 0.018558
Test loss: 0.019757; Test accuracy: 9934/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.020150
Epoch: 16 10000/60000 Training loss: 0.011217
Epoch: 16 20000/60000 Training loss: 0.052196
Epoch: 16 30000/60000 Training loss: 0.012457
Epoch: 16 40000/60000 Training loss: 0.001679
Epoch: 16 50000/60000 Training loss: 0.014600
Training loss: 0.018945
Test loss: 0.018888; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 00:54:53,949] Trial 17 finished with value: 0.018034111708402634 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.17043372578606336, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00018768545507960813}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.13036293489222217, 'fc1_neurons': 160, 'optimizer': 'SGD', 'learning_rate': 0.0005236326501703913}
Epoch: 0 0/60000 Training loss: 2.320046
Epoch: 0 10000/60000 Training loss: 2.245804
Epoch: 0 20000/60000 Training loss: 2.232490
Epoch: 0 30000/60000 Training loss: 2.178228
Epoch: 0 40000/60000 Training loss: 2.097087
Epoch: 0 50000/60000 Training loss: 2.042065
Training loss: 2.170664
Test loss: 1.955166; Test accuracy: 6584/10000 (65.8%)

Epoch: 1 0/60000 Training loss: 1.993522
Epoch: 1 10000/60000 Training loss: 1.936351
Epoch: 1 20000/60000 Training loss: 1.802170
Epoch: 1 30000/60000 Training loss: 1.728032
Epoch: 1 40000/60000 Training loss: 1.642869
Epoch: 1 50000/60000 Training loss: 1.440787
Training loss: 1.717024
Test loss: 1.265052; Test accuracy: 7807/10000 (78.1%)

Epoch: 2 0/60000 Training loss: 1.308472
Epoch: 2 10000/60000 Training loss: 1.320838
Epoch: 2 20000/60000 Training loss: 1.246784
Epoch: 2 30000/60000 Training loss: 1.134499
Epoch: 2 40000/60000 Training loss: 1.237795
Epoch: 2 50000/60000 Training loss: 1.008475
Training loss: 1.160794
Test loss: 0.738908; Test accuracy: 8727/10000 (87.3%)

Epoch: 3 0/60000 Training loss: 1.039107
Epoch: 3 10000/60000 Training loss: 1.089392
Epoch: 3 20000/60000 Training loss: 1.051710
Epoch: 3 30000/60000 Training loss: 0.821217
Epoch: 3 40000/60000 Training loss: 0.770942
Epoch: 3 50000/60000 Training loss: 0.811077
Training loss: 0.824124
Test loss: 0.511288; Test accuracy: 8952/10000 (89.5%)

Epoch: 4 0/60000 Training loss: 0.693234
Epoch: 4 10000/60000 Training loss: 0.606310
Epoch: 4 20000/60000 Training loss: 0.674476
Epoch: 4 30000/60000 Training loss: 0.523091
Epoch: 4 40000/60000 Training loss: 0.556206
Epoch: 4 50000/60000 Training loss: 0.586332
Training loss: 0.659637
Test loss: 0.406738; Test accuracy: 9074/10000 (90.7%)

Epoch: 5 0/60000 Training loss: 0.684691
Epoch: 5 10000/60000 Training loss: 0.568350
Epoch: 5 20000/60000 Training loss: 0.506546
Epoch: 5 30000/60000 Training loss: 0.554636
Epoch: 5 40000/60000 Training loss: 0.644182
Epoch: 5 50000/60000 Training loss: 0.477868
Training loss: 0.561469
Test loss: 0.346719; Test accuracy: 9147/10000 (91.5%)

Epoch: 6 0/60000 Training loss: 0.558986
Epoch: 6 10000/60000 Training loss: 0.411417
Epoch: 6 20000/60000 Training loss: 0.451465
Epoch: 6 30000/60000 Training loss: 0.535802
Epoch: 6 40000/60000 Training loss: 0.568509
Epoch: 6 50000/60000 Training loss: 0.397699
Training loss: 0.498935
Test loss: 0.307782; Test accuracy: 9215/10000 (92.1%)

Epoch: 7 0/60000 Training loss: 0.483885
Epoch: 7 10000/60000 Training loss: 0.508968
Epoch: 7 20000/60000 Training loss: 0.422349
Epoch: 7 30000/60000 Training loss: 0.517690
Epoch: 7 40000/60000 Training loss: 0.362048
Epoch: 7 50000/60000 Training loss: 0.507414
Training loss: 0.452670
Test loss: 0.279802; Test accuracy: 9265/10000 (92.6%)

Epoch: 8 0/60000 Training loss: 0.638746
Epoch: 8 10000/60000 Training loss: 0.524055
Epoch: 8 20000/60000 Training loss: 0.480310
Epoch: 8 30000/60000 Training loss: 0.467396
Epoch: 8 40000/60000 Training loss: 0.291664
Epoch: 8 50000/60000 Training loss: 0.388434
Training loss: 0.412597
Test loss: 0.258465; Test accuracy: 9306/10000 (93.1%)

Epoch: 9 0/60000 Training loss: 0.349002
Epoch: 9 10000/60000 Training loss: 0.334539
Epoch: 9 20000/60000 Training loss: 0.280303
Epoch: 9 30000/60000 Training loss: 0.484551
Epoch: 9 40000/60000 Training loss: 0.321893
Epoch: 9 50000/60000 Training loss: 0.483892
Training loss: 0.390912
Test loss: 0.241739; Test accuracy: 9351/10000 (93.5%)

Epoch: 10 0/60000 Training loss: 0.304573
Epoch: 10 10000/60000 Training loss: 0.479196
Epoch: 10 20000/60000 Training loss: 0.358702
Epoch: 10 30000/60000 Training loss: 0.334300
Epoch: 10 40000/60000 Training loss: 0.335812
Epoch: 10 50000/60000 Training loss: 0.376246
Training loss: 0.368692
Test loss: 0.227173; Test accuracy: 9377/10000 (93.8%)

Epoch: 11 0/60000 Training loss: 0.387404
Epoch: 11 10000/60000 Training loss: 0.313235
Epoch: 11 20000/60000 Training loss: 0.238034
Epoch: 11 30000/60000 Training loss: 0.316045
Epoch: 11 40000/60000 Training loss: 0.207829
Epoch: 11 50000/60000 Training loss: 0.250226
Training loss: 0.350940
Test loss: 0.215039; Test accuracy: 9411/10000 (94.1%)

Epoch: 12 0/60000 Training loss: 0.368824
Epoch: 12 10000/60000 Training loss: 0.344859
Epoch: 12 20000/60000 Training loss: 0.274099
Epoch: 12 30000/60000 Training loss: 0.272920
Epoch: 12 40000/60000 Training loss: 0.349296
Epoch: 12 50000/60000 Training loss: 0.387373
Training loss: 0.330038
Test loss: 0.205285; Test accuracy: 9421/10000 (94.2%)

Epoch: 13 0/60000 Training loss: 0.386229
Epoch: 13 10000/60000 Training loss: 0.251163
Epoch: 13 20000/60000 Training loss: 0.442162
Epoch: 13 30000/60000 Training loss: 0.205594
Epoch: 13 40000/60000 Training loss: 0.332903
Epoch: 13 50000/60000 Training loss: 0.263966
Training loss: 0.316629
Test loss: 0.195467; Test accuracy: 9439/10000 (94.4%)

Epoch: 14 0/60000 Training loss: 0.324653
Epoch: 14 10000/60000 Training loss: 0.317206
Epoch: 14 20000/60000 Training loss: 0.335266
Epoch: 14 30000/60000 Training loss: 0.369772
Epoch: 14 40000/60000 Training loss: 0.363142
Epoch: 14 50000/60000 Training loss: 0.338223
Training loss: 0.304693
Test loss: 0.187836; Test accuracy: 9457/10000 (94.6%)

Epoch: 15 0/60000 Training loss: 0.225729
Epoch: 15 10000/60000 Training loss: 0.375427
Epoch: 15 20000/60000 Training loss: 0.280826
Epoch: 15 30000/60000 Training loss: 0.415689
Epoch: 15 40000/60000 Training loss: 0.303541
Epoch: 15 50000/60000 Training loss: 0.272047
Training loss: 0.294443
Test loss: 0.180786; Test accuracy: 9469/10000 (94.7%)

Epoch: 16 0/60000 Training loss: 0.244690
Epoch: 16 10000/60000 Training loss: 0.242518
Epoch: 16 20000/60000 Training loss: 0.324923
Epoch: 16 30000/60000 Training loss: 0.300374
Epoch: 16 40000/60000 Training loss: 0.397604
Epoch: 16 50000/60000 Training loss: 0.263889
Training loss: 0.283144
Test loss: 0.173483; Test accuracy: 9484/10000 (94.8%)

Epoch: 17 0/60000 Training loss: 0.310055
Epoch: 17 10000/60000 Training loss: 0.207860
Epoch: 17 20000/60000 Training loss: 0.191284
Epoch: 17 30000/60000 Training loss: 0.221928
Epoch: 17 40000/60000 Training loss: 0.286142
Epoch: 17 50000/60000 Training loss: 0.386406
Training loss: 0.275313
Test loss: 0.167999; Test accuracy: 9499/10000 (95.0%)

Epoch: 18 0/60000 Training loss: 0.303597
Epoch: 18 10000/60000 Training loss: 0.326899
Epoch: 18 20000/60000 Training loss: 0.265743
Epoch: 18 30000/60000 Training loss: 0.363589
Epoch: 18 40000/60000 Training loss: 0.343811
Epoch: 18 50000/60000 Training loss: 0.215360
Training loss: 0.261565
Test loss: 0.161915; Test accuracy: 9508/10000 (95.1%)

Epoch: 19 0/60000 Training loss: 0.443651
Epoch: 19 10000/60000 Training loss: 0.389069
Epoch: 19 20000/60000 Training loss: 0.382348
Epoch: 19 30000/60000 Training loss: 0.280015
Epoch: 19 40000/60000 Training loss: 0.208665
Epoch: 19 50000/60000 Training loss: 0.194862
Training loss: 0.256565
Test loss: 0.157158; Test accuracy: 9528/10000 (95.3%)

[I 2022-11-04 00:59:33,281] Trial 18 finished with value: 0.1571577489376068 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.13036293489222217, 'fc1_neurons': 160, 'optimizer': 'SGD', 'learning_rate': 0.0005236326501703913}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 112, 'conv2_drop': 0.16701415910588943, 'fc1_neurons': 90, 'optimizer': 'Adam', 'learning_rate': 4.5600751496084203e-05}
Epoch: 0 0/60000 Training loss: 2.333527
Epoch: 0 10000/60000 Training loss: 1.245878
Epoch: 0 20000/60000 Training loss: 0.807914
Epoch: 0 30000/60000 Training loss: 0.364053
Epoch: 0 40000/60000 Training loss: 0.534867
Epoch: 0 50000/60000 Training loss: 0.515782
Training loss: 0.768480
Test loss: 0.174156; Test accuracy: 9503/10000 (95.0%)

Epoch: 1 0/60000 Training loss: 0.240540
Epoch: 1 10000/60000 Training loss: 0.308366
Epoch: 1 20000/60000 Training loss: 0.435051
Epoch: 1 30000/60000 Training loss: 0.246468
Epoch: 1 40000/60000 Training loss: 0.218335
Epoch: 1 50000/60000 Training loss: 0.336844
Training loss: 0.252266
Test loss: 0.099643; Test accuracy: 9700/10000 (97.0%)

Epoch: 2 0/60000 Training loss: 0.189598
Epoch: 2 10000/60000 Training loss: 0.188280
Epoch: 2 20000/60000 Training loss: 0.169518
Epoch: 2 30000/60000 Training loss: 0.070672
Epoch: 2 40000/60000 Training loss: 0.121715
Epoch: 2 50000/60000 Training loss: 0.171893
Training loss: 0.176561
Test loss: 0.076109; Test accuracy: 9764/10000 (97.6%)

Epoch: 3 0/60000 Training loss: 0.195164
Epoch: 3 10000/60000 Training loss: 0.150616
Epoch: 3 20000/60000 Training loss: 0.138333
Epoch: 3 30000/60000 Training loss: 0.258437
Epoch: 3 40000/60000 Training loss: 0.077340
Epoch: 3 50000/60000 Training loss: 0.121901
Training loss: 0.140730
Test loss: 0.060640; Test accuracy: 9817/10000 (98.2%)

Epoch: 4 0/60000 Training loss: 0.120658
Epoch: 4 10000/60000 Training loss: 0.099288
Epoch: 4 20000/60000 Training loss: 0.093736
Epoch: 4 30000/60000 Training loss: 0.115299
Epoch: 4 40000/60000 Training loss: 0.108804
Epoch: 4 50000/60000 Training loss: 0.096684
Training loss: 0.119150
Test loss: 0.050769; Test accuracy: 9836/10000 (98.4%)

Epoch: 5 0/60000 Training loss: 0.112632
Epoch: 5 10000/60000 Training loss: 0.121522
Epoch: 5 20000/60000 Training loss: 0.043454
Epoch: 5 30000/60000 Training loss: 0.057578
Epoch: 5 40000/60000 Training loss: 0.068283
Epoch: 5 50000/60000 Training loss: 0.060748
Training loss: 0.106377
Test loss: 0.044368; Test accuracy: 9856/10000 (98.6%)

Epoch: 6 0/60000 Training loss: 0.068253
Epoch: 6 10000/60000 Training loss: 0.100854
Epoch: 6 20000/60000 Training loss: 0.070496
Epoch: 6 30000/60000 Training loss: 0.135926
Epoch: 6 40000/60000 Training loss: 0.047665
Epoch: 6 50000/60000 Training loss: 0.144159
Training loss: 0.093719
Test loss: 0.040020; Test accuracy: 9862/10000 (98.6%)

Epoch: 7 0/60000 Training loss: 0.059110
Epoch: 7 10000/60000 Training loss: 0.080441
Epoch: 7 20000/60000 Training loss: 0.057873
Epoch: 7 30000/60000 Training loss: 0.099520
Epoch: 7 40000/60000 Training loss: 0.075040
Epoch: 7 50000/60000 Training loss: 0.108492
Training loss: 0.085291
Test loss: 0.036874; Test accuracy: 9875/10000 (98.8%)

Epoch: 8 0/60000 Training loss: 0.057036
Epoch: 8 10000/60000 Training loss: 0.039792
Epoch: 8 20000/60000 Training loss: 0.163157
Epoch: 8 30000/60000 Training loss: 0.015523
Epoch: 8 40000/60000 Training loss: 0.045189
Epoch: 8 50000/60000 Training loss: 0.052255
Training loss: 0.079028
Test loss: 0.033317; Test accuracy: 9885/10000 (98.8%)

Epoch: 9 0/60000 Training loss: 0.079207
Epoch: 9 10000/60000 Training loss: 0.044892
Epoch: 9 20000/60000 Training loss: 0.094648
Epoch: 9 30000/60000 Training loss: 0.027751
Epoch: 9 40000/60000 Training loss: 0.067320
Epoch: 9 50000/60000 Training loss: 0.061278
Training loss: 0.071802
Test loss: 0.031017; Test accuracy: 9899/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.032730
Epoch: 10 10000/60000 Training loss: 0.038733
Epoch: 10 20000/60000 Training loss: 0.017924
Epoch: 10 30000/60000 Training loss: 0.058212
Epoch: 10 40000/60000 Training loss: 0.037572
Epoch: 10 50000/60000 Training loss: 0.072083
Training loss: 0.066519
Test loss: 0.030117; Test accuracy: 9902/10000 (99.0%)

Epoch: 11 0/60000 Training loss: 0.101400
Epoch: 11 10000/60000 Training loss: 0.027461
Epoch: 11 20000/60000 Training loss: 0.020141
Epoch: 11 30000/60000 Training loss: 0.025081
Epoch: 11 40000/60000 Training loss: 0.016980
Epoch: 11 50000/60000 Training loss: 0.036401
Training loss: 0.064376
Test loss: 0.029087; Test accuracy: 9894/10000 (98.9%)

Epoch: 12 0/60000 Training loss: 0.056321
Epoch: 12 10000/60000 Training loss: 0.064402
Epoch: 12 20000/60000 Training loss: 0.080462
Epoch: 12 30000/60000 Training loss: 0.058920
Epoch: 12 40000/60000 Training loss: 0.050045
Epoch: 12 50000/60000 Training loss: 0.053672
Training loss: 0.057916
Test loss: 0.027171; Test accuracy: 9915/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.010386
Epoch: 13 10000/60000 Training loss: 0.052712
Epoch: 13 20000/60000 Training loss: 0.042098
Epoch: 13 30000/60000 Training loss: 0.035739
Epoch: 13 40000/60000 Training loss: 0.048771
Epoch: 13 50000/60000 Training loss: 0.027696
Training loss: 0.055167
Test loss: 0.025740; Test accuracy: 9920/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.053137
Epoch: 14 10000/60000 Training loss: 0.041255
Epoch: 14 20000/60000 Training loss: 0.029340
Epoch: 14 30000/60000 Training loss: 0.030247
Epoch: 14 40000/60000 Training loss: 0.031294
Epoch: 14 50000/60000 Training loss: 0.045788
Training loss: 0.052180
Test loss: 0.024379; Test accuracy: 9922/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.033537
Epoch: 15 10000/60000 Training loss: 0.064792
Epoch: 15 20000/60000 Training loss: 0.019159
Epoch: 15 30000/60000 Training loss: 0.014645
Epoch: 15 40000/60000 Training loss: 0.081977
Epoch: 15 50000/60000 Training loss: 0.042815
Training loss: 0.048477
Test loss: 0.024389; Test accuracy: 9917/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.018356
Epoch: 16 10000/60000 Training loss: 0.036089
Epoch: 16 20000/60000 Training loss: 0.015358
Epoch: 16 30000/60000 Training loss: 0.016884
Epoch: 16 40000/60000 Training loss: 0.053142
Epoch: 16 50000/60000 Training loss: 0.080296
Training loss: 0.048013
Test loss: 0.024252; Test accuracy: 9919/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.069428
Epoch: 17 10000/60000 Training loss: 0.061946
Epoch: 17 20000/60000 Training loss: 0.040883
Epoch: 17 30000/60000 Training loss: 0.049621
Epoch: 17 40000/60000 Training loss: 0.022429
Epoch: 17 50000/60000 Training loss: 0.040327
Training loss: 0.044998
Test loss: 0.023318; Test accuracy: 9919/10000 (99.2%)

Epoch: 18 0/60000 Training loss: 0.045809
Epoch: 18 10000/60000 Training loss: 0.016945
Epoch: 18 20000/60000 Training loss: 0.043210
Epoch: 18 30000/60000 Training loss: 0.021397
Epoch: 18 40000/60000 Training loss: 0.028062
Epoch: 18 50000/60000 Training loss: 0.024719
Training loss: 0.043617
Test loss: 0.021974; Test accuracy: 9924/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.020629
Epoch: 19 10000/60000 Training loss: 0.012698
Epoch: 19 20000/60000 Training loss: 0.046407
Epoch: 19 30000/60000 Training loss: 0.128384
Epoch: 19 40000/60000 Training loss: 0.010114
Epoch: 19 50000/60000 Training loss: 0.014656
Training loss: 0.040933
Test loss: 0.021732; Test accuracy: 9930/10000 (99.3%)

[I 2022-11-04 01:04:12,595] Trial 19 finished with value: 0.021732468158006668 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 112, 'conv2_drop': 0.16701415910588943, 'fc1_neurons': 90, 'optimizer': 'Adam', 'learning_rate': 4.5600751496084203e-05}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.12596422701343368, 'fc1_neurons': 40, 'optimizer': 'Adam', 'learning_rate': 0.00017806086773389392}
Epoch: 0 0/60000 Training loss: 2.304497
Epoch: 0 10000/60000 Training loss: 0.794990
Epoch: 0 20000/60000 Training loss: 0.580308
Epoch: 0 30000/60000 Training loss: 0.339740
Epoch: 0 40000/60000 Training loss: 0.312703
Epoch: 0 50000/60000 Training loss: 0.219841
Training loss: 0.601390
Test loss: 0.096551; Test accuracy: 9709/10000 (97.1%)

Epoch: 1 0/60000 Training loss: 0.267555
Epoch: 1 10000/60000 Training loss: 0.386961
Epoch: 1 20000/60000 Training loss: 0.220770
Epoch: 1 30000/60000 Training loss: 0.330868
Epoch: 1 40000/60000 Training loss: 0.140671
Epoch: 1 50000/60000 Training loss: 0.171575
Training loss: 0.229301
Test loss: 0.065228; Test accuracy: 9813/10000 (98.1%)

Epoch: 2 0/60000 Training loss: 0.127001
Epoch: 2 10000/60000 Training loss: 0.163805
Epoch: 2 20000/60000 Training loss: 0.100444
Epoch: 2 30000/60000 Training loss: 0.219575
Epoch: 2 40000/60000 Training loss: 0.297571
Epoch: 2 50000/60000 Training loss: 0.131104
Training loss: 0.169570
Test loss: 0.048610; Test accuracy: 9851/10000 (98.5%)

Epoch: 3 0/60000 Training loss: 0.073590
Epoch: 3 10000/60000 Training loss: 0.115060
Epoch: 3 20000/60000 Training loss: 0.096951
Epoch: 3 30000/60000 Training loss: 0.272005
Epoch: 3 40000/60000 Training loss: 0.111705
Epoch: 3 50000/60000 Training loss: 0.172143
Training loss: 0.136920
Test loss: 0.039985; Test accuracy: 9861/10000 (98.6%)

Epoch: 4 0/60000 Training loss: 0.029387
Epoch: 4 10000/60000 Training loss: 0.109669
Epoch: 4 20000/60000 Training loss: 0.108527
Epoch: 4 30000/60000 Training loss: 0.132643
Epoch: 4 40000/60000 Training loss: 0.191038
Epoch: 4 50000/60000 Training loss: 0.092555
Training loss: 0.115648
Test loss: 0.033946; Test accuracy: 9886/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.124012
Epoch: 5 10000/60000 Training loss: 0.194311
Epoch: 5 20000/60000 Training loss: 0.097888
Epoch: 5 30000/60000 Training loss: 0.089342
Epoch: 5 40000/60000 Training loss: 0.107633
Epoch: 5 50000/60000 Training loss: 0.182024
Training loss: 0.102400
Test loss: 0.031731; Test accuracy: 9883/10000 (98.8%)

Epoch: 6 0/60000 Training loss: 0.068437
Epoch: 6 10000/60000 Training loss: 0.094222
Epoch: 6 20000/60000 Training loss: 0.058423
Epoch: 6 30000/60000 Training loss: 0.174208
Epoch: 6 40000/60000 Training loss: 0.069430
Epoch: 6 50000/60000 Training loss: 0.112514
Training loss: 0.093269
Test loss: 0.028737; Test accuracy: 9904/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.037784
Epoch: 7 10000/60000 Training loss: 0.130675
Epoch: 7 20000/60000 Training loss: 0.104759
Epoch: 7 30000/60000 Training loss: 0.077112
Epoch: 7 40000/60000 Training loss: 0.060054
Epoch: 7 50000/60000 Training loss: 0.078472
Training loss: 0.084734
Test loss: 0.030607; Test accuracy: 9898/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.189365
Epoch: 8 10000/60000 Training loss: 0.039689
Epoch: 8 20000/60000 Training loss: 0.091643
Epoch: 8 30000/60000 Training loss: 0.147903
Epoch: 8 40000/60000 Training loss: 0.069631
Epoch: 8 50000/60000 Training loss: 0.036939
Training loss: 0.078432
Test loss: 0.030127; Test accuracy: 9909/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.153189
Epoch: 9 10000/60000 Training loss: 0.058615
Epoch: 9 20000/60000 Training loss: 0.091528
Epoch: 9 30000/60000 Training loss: 0.081259
Epoch: 9 40000/60000 Training loss: 0.058316
Epoch: 9 50000/60000 Training loss: 0.049910
Training loss: 0.072172
Test loss: 0.026026; Test accuracy: 9917/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.090956
Epoch: 10 10000/60000 Training loss: 0.078369
Epoch: 10 20000/60000 Training loss: 0.123931
Epoch: 10 30000/60000 Training loss: 0.029567
Epoch: 10 40000/60000 Training loss: 0.061669
Epoch: 10 50000/60000 Training loss: 0.020283
Training loss: 0.069417
Test loss: 0.025098; Test accuracy: 9912/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.032710
Epoch: 11 10000/60000 Training loss: 0.050909
Epoch: 11 20000/60000 Training loss: 0.094997
Epoch: 11 30000/60000 Training loss: 0.022546
Epoch: 11 40000/60000 Training loss: 0.073290
Epoch: 11 50000/60000 Training loss: 0.042296
Training loss: 0.062529
Test loss: 0.023776; Test accuracy: 9923/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.035673
Epoch: 12 10000/60000 Training loss: 0.153864
Epoch: 12 20000/60000 Training loss: 0.081247
Epoch: 12 30000/60000 Training loss: 0.048747
Epoch: 12 40000/60000 Training loss: 0.107274
Epoch: 12 50000/60000 Training loss: 0.025876
Training loss: 0.060899
Test loss: 0.021829; Test accuracy: 9925/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.156407
Epoch: 13 10000/60000 Training loss: 0.101331
Epoch: 13 20000/60000 Training loss: 0.071630
Epoch: 13 30000/60000 Training loss: 0.056149
Epoch: 13 40000/60000 Training loss: 0.095258
Epoch: 13 50000/60000 Training loss: 0.056664
Training loss: 0.056160
Test loss: 0.022341; Test accuracy: 9927/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.057730
Epoch: 14 10000/60000 Training loss: 0.110594
Epoch: 14 20000/60000 Training loss: 0.060859
Epoch: 14 30000/60000 Training loss: 0.042698
Epoch: 14 40000/60000 Training loss: 0.039400
Epoch: 14 50000/60000 Training loss: 0.027345
Training loss: 0.053294
Test loss: 0.024268; Test accuracy: 9924/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.030129
Epoch: 15 10000/60000 Training loss: 0.040503
Epoch: 15 20000/60000 Training loss: 0.112049
Epoch: 15 30000/60000 Training loss: 0.060179
Epoch: 15 40000/60000 Training loss: 0.010666
Epoch: 15 50000/60000 Training loss: 0.010388
Training loss: 0.052124
Test loss: 0.021493; Test accuracy: 9930/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.181053
Epoch: 16 10000/60000 Training loss: 0.086682
Epoch: 16 20000/60000 Training loss: 0.009321
Epoch: 16 30000/60000 Training loss: 0.014123
Epoch: 16 40000/60000 Training loss: 0.013312
Epoch: 16 50000/60000 Training loss: 0.007075
Training loss: 0.050702
Test loss: 0.023587; Test accuracy: 9930/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.131176
Epoch: 17 10000/60000 Training loss: 0.041578
Epoch: 17 20000/60000 Training loss: 0.030890
Epoch: 17 30000/60000 Training loss: 0.029217
Epoch: 17 40000/60000 Training loss: 0.020570
Epoch: 17 50000/60000 Training loss: 0.067735
Training loss: 0.046184
Test loss: 0.022260; Test accuracy: 9930/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.035285
Epoch: 18 10000/60000 Training loss: 0.083491
Epoch: 18 20000/60000 Training loss: 0.047612
Epoch: 18 30000/60000 Training loss: 0.073647
Epoch: 18 40000/60000 Training loss: 0.131938
Epoch: 18 50000/60000 Training loss: 0.026839
Training loss: 0.047342
Test loss: 0.023523; Test accuracy: 9933/10000 (99.3%)

[I 2022-11-04 01:08:38,689] Trial 20 finished with value: 0.021492643281817436 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.12596422701343368, 'fc1_neurons': 40, 'optimizer': 'Adam', 'learning_rate': 0.00017806086773389392}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 64, 'conv2_drop': 0.1700053852320349, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00018367435844522344}
Epoch: 0 0/60000 Training loss: 2.322570
Epoch: 0 10000/60000 Training loss: 0.565375
Epoch: 0 20000/60000 Training loss: 0.338535
Epoch: 0 30000/60000 Training loss: 0.193181
Epoch: 0 40000/60000 Training loss: 0.165627
Epoch: 0 50000/60000 Training loss: 0.207627
Training loss: 0.425016
Test loss: 0.081680; Test accuracy: 9751/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.140767
Epoch: 1 10000/60000 Training loss: 0.172564
Epoch: 1 20000/60000 Training loss: 0.154826
Epoch: 1 30000/60000 Training loss: 0.106952
Epoch: 1 40000/60000 Training loss: 0.137057
Epoch: 1 50000/60000 Training loss: 0.040139
Training loss: 0.125172
Test loss: 0.051526; Test accuracy: 9833/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.085154
Epoch: 2 10000/60000 Training loss: 0.081601
Epoch: 2 20000/60000 Training loss: 0.084111
Epoch: 2 30000/60000 Training loss: 0.029466
Epoch: 2 40000/60000 Training loss: 0.050211
Epoch: 2 50000/60000 Training loss: 0.081545
Training loss: 0.091226
Test loss: 0.040025; Test accuracy: 9874/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.068276
Epoch: 3 10000/60000 Training loss: 0.059484
Epoch: 3 20000/60000 Training loss: 0.028700
Epoch: 3 30000/60000 Training loss: 0.130168
Epoch: 3 40000/60000 Training loss: 0.025679
Epoch: 3 50000/60000 Training loss: 0.128136
Training loss: 0.073524
Test loss: 0.033260; Test accuracy: 9888/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.057891
Epoch: 4 10000/60000 Training loss: 0.038849
Epoch: 4 20000/60000 Training loss: 0.041488
Epoch: 4 30000/60000 Training loss: 0.017017
Epoch: 4 40000/60000 Training loss: 0.086047
Epoch: 4 50000/60000 Training loss: 0.051976
Training loss: 0.060944
Test loss: 0.027525; Test accuracy: 9901/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.017017
Epoch: 5 10000/60000 Training loss: 0.054107
Epoch: 5 20000/60000 Training loss: 0.082065
Epoch: 5 30000/60000 Training loss: 0.045357
Epoch: 5 40000/60000 Training loss: 0.007489
Epoch: 5 50000/60000 Training loss: 0.040644
Training loss: 0.053131
Test loss: 0.026377; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.016031
Epoch: 6 10000/60000 Training loss: 0.054097
Epoch: 6 20000/60000 Training loss: 0.017916
Epoch: 6 30000/60000 Training loss: 0.009400
Epoch: 6 40000/60000 Training loss: 0.012814
Epoch: 6 50000/60000 Training loss: 0.098373
Training loss: 0.047106
Test loss: 0.025324; Test accuracy: 9915/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.016431
Epoch: 7 10000/60000 Training loss: 0.023085
Epoch: 7 20000/60000 Training loss: 0.024375
Epoch: 7 30000/60000 Training loss: 0.027683
Epoch: 7 40000/60000 Training loss: 0.018319
Epoch: 7 50000/60000 Training loss: 0.073474
Training loss: 0.042129
Test loss: 0.025411; Test accuracy: 9911/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.023017
Epoch: 8 10000/60000 Training loss: 0.030446
Epoch: 8 20000/60000 Training loss: 0.014929
Epoch: 8 30000/60000 Training loss: 0.072877
Epoch: 8 40000/60000 Training loss: 0.015148
Epoch: 8 50000/60000 Training loss: 0.022432
Training loss: 0.039660
Test loss: 0.023259; Test accuracy: 9928/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.021730
Epoch: 9 10000/60000 Training loss: 0.006687
Epoch: 9 20000/60000 Training loss: 0.064461
Epoch: 9 30000/60000 Training loss: 0.010518
Epoch: 9 40000/60000 Training loss: 0.023235
Epoch: 9 50000/60000 Training loss: 0.045121
Training loss: 0.035693
Test loss: 0.020686; Test accuracy: 9933/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.019298
Epoch: 10 10000/60000 Training loss: 0.016115
Epoch: 10 20000/60000 Training loss: 0.049615
Epoch: 10 30000/60000 Training loss: 0.022751
Epoch: 10 40000/60000 Training loss: 0.006492
Epoch: 10 50000/60000 Training loss: 0.009163
Training loss: 0.032701
Test loss: 0.020867; Test accuracy: 9930/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.084920
Epoch: 11 10000/60000 Training loss: 0.006139
Epoch: 11 20000/60000 Training loss: 0.010004
Epoch: 11 30000/60000 Training loss: 0.018846
Epoch: 11 40000/60000 Training loss: 0.008116
Epoch: 11 50000/60000 Training loss: 0.006048
Training loss: 0.029968
Test loss: 0.020603; Test accuracy: 9927/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.052940
Epoch: 12 10000/60000 Training loss: 0.030564
Epoch: 12 20000/60000 Training loss: 0.048396
Epoch: 12 30000/60000 Training loss: 0.014916
Epoch: 12 40000/60000 Training loss: 0.021548
Epoch: 12 50000/60000 Training loss: 0.022597
Training loss: 0.028192
Test loss: 0.020140; Test accuracy: 9934/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.011931
Epoch: 13 10000/60000 Training loss: 0.009575
Epoch: 13 20000/60000 Training loss: 0.013263
Epoch: 13 30000/60000 Training loss: 0.040708
Epoch: 13 40000/60000 Training loss: 0.040521
Epoch: 13 50000/60000 Training loss: 0.076385
Training loss: 0.026767
Test loss: 0.020989; Test accuracy: 9930/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.002429
Epoch: 14 10000/60000 Training loss: 0.030070
Epoch: 14 20000/60000 Training loss: 0.004877
Epoch: 14 30000/60000 Training loss: 0.006619
Epoch: 14 40000/60000 Training loss: 0.085778
Epoch: 14 50000/60000 Training loss: 0.054993
Training loss: 0.024936
Test loss: 0.018584; Test accuracy: 9934/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.009291
Epoch: 15 10000/60000 Training loss: 0.012246
Epoch: 15 20000/60000 Training loss: 0.003822
Epoch: 15 30000/60000 Training loss: 0.043584
Epoch: 15 40000/60000 Training loss: 0.001145
Epoch: 15 50000/60000 Training loss: 0.013020
Training loss: 0.022763
Test loss: 0.020508; Test accuracy: 9930/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.019185
Epoch: 16 10000/60000 Training loss: 0.008375
Epoch: 16 20000/60000 Training loss: 0.041086
Epoch: 16 30000/60000 Training loss: 0.002418
Epoch: 16 40000/60000 Training loss: 0.009103
Epoch: 16 50000/60000 Training loss: 0.024369
Training loss: 0.022119
Test loss: 0.018834; Test accuracy: 9934/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.016304
Epoch: 17 10000/60000 Training loss: 0.036397
Epoch: 17 20000/60000 Training loss: 0.005174
Epoch: 17 30000/60000 Training loss: 0.020166
Epoch: 17 40000/60000 Training loss: 0.019727
Epoch: 17 50000/60000 Training loss: 0.013669
Training loss: 0.020562
Test loss: 0.019060; Test accuracy: 9943/10000 (99.4%)

[I 2022-11-04 01:12:50,568] Trial 21 finished with value: 0.0185841154307127 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 64, 'conv2_drop': 0.1700053852320349, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.00018367435844522344}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.17236807213809546, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 0.00020818564670309955}
Epoch: 0 0/60000 Training loss: 2.341404
Epoch: 0 10000/60000 Training loss: 0.515124
Epoch: 0 20000/60000 Training loss: 0.337704
Epoch: 0 30000/60000 Training loss: 0.260084
Epoch: 0 40000/60000 Training loss: 0.118994
Epoch: 0 50000/60000 Training loss: 0.119062
Training loss: 0.362585
Test loss: 0.073837; Test accuracy: 9773/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.100410
Epoch: 1 10000/60000 Training loss: 0.035109
Epoch: 1 20000/60000 Training loss: 0.082053
Epoch: 1 30000/60000 Training loss: 0.172432
Epoch: 1 40000/60000 Training loss: 0.117675
Epoch: 1 50000/60000 Training loss: 0.067306
Training loss: 0.110329
Test loss: 0.044618; Test accuracy: 9857/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.077812
Epoch: 2 10000/60000 Training loss: 0.173081
Epoch: 2 20000/60000 Training loss: 0.181960
Epoch: 2 30000/60000 Training loss: 0.030424
Epoch: 2 40000/60000 Training loss: 0.016498
Epoch: 2 50000/60000 Training loss: 0.071643
Training loss: 0.079832
Test loss: 0.034907; Test accuracy: 9882/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.163108
Epoch: 3 10000/60000 Training loss: 0.085558
Epoch: 3 20000/60000 Training loss: 0.076520
Epoch: 3 30000/60000 Training loss: 0.117341
Epoch: 3 40000/60000 Training loss: 0.083735
Epoch: 3 50000/60000 Training loss: 0.086616
Training loss: 0.061746
Test loss: 0.030943; Test accuracy: 9902/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.076041
Epoch: 4 10000/60000 Training loss: 0.040871
Epoch: 4 20000/60000 Training loss: 0.035470
Epoch: 4 30000/60000 Training loss: 0.046960
Epoch: 4 40000/60000 Training loss: 0.021949
Epoch: 4 50000/60000 Training loss: 0.071828
Training loss: 0.053391
Test loss: 0.031856; Test accuracy: 9899/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.092740
Epoch: 5 10000/60000 Training loss: 0.124467
Epoch: 5 20000/60000 Training loss: 0.005597
Epoch: 5 30000/60000 Training loss: 0.071133
Epoch: 5 40000/60000 Training loss: 0.017367
Epoch: 5 50000/60000 Training loss: 0.025958
Training loss: 0.048705
Test loss: 0.024267; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.034856
Epoch: 6 10000/60000 Training loss: 0.010170
Epoch: 6 20000/60000 Training loss: 0.029753
Epoch: 6 30000/60000 Training loss: 0.036538
Epoch: 6 40000/60000 Training loss: 0.050465
Epoch: 6 50000/60000 Training loss: 0.051243
Training loss: 0.040886
Test loss: 0.025169; Test accuracy: 9910/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.040079
Epoch: 7 10000/60000 Training loss: 0.021594
Epoch: 7 20000/60000 Training loss: 0.022647
Epoch: 7 30000/60000 Training loss: 0.015407
Epoch: 7 40000/60000 Training loss: 0.017371
Epoch: 7 50000/60000 Training loss: 0.013245
Training loss: 0.037860
Test loss: 0.022737; Test accuracy: 9925/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.021619
Epoch: 8 10000/60000 Training loss: 0.050583
Epoch: 8 20000/60000 Training loss: 0.016591
Epoch: 8 30000/60000 Training loss: 0.015548
Epoch: 8 40000/60000 Training loss: 0.012532
Epoch: 8 50000/60000 Training loss: 0.020719
Training loss: 0.032447
Test loss: 0.020247; Test accuracy: 9927/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.027245
Epoch: 9 10000/60000 Training loss: 0.024723
Epoch: 9 20000/60000 Training loss: 0.032958
Epoch: 9 30000/60000 Training loss: 0.012380
Epoch: 9 40000/60000 Training loss: 0.042815
Epoch: 9 50000/60000 Training loss: 0.026469
Training loss: 0.029414
Test loss: 0.024336; Test accuracy: 9923/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.013490
Epoch: 10 10000/60000 Training loss: 0.014885
Epoch: 10 20000/60000 Training loss: 0.012073
Epoch: 10 30000/60000 Training loss: 0.088198
Epoch: 10 40000/60000 Training loss: 0.044031
Epoch: 10 50000/60000 Training loss: 0.048504
Training loss: 0.027504
Test loss: 0.020526; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.005900
Epoch: 11 10000/60000 Training loss: 0.001385
Epoch: 11 20000/60000 Training loss: 0.006167
Epoch: 11 30000/60000 Training loss: 0.041583
Epoch: 11 40000/60000 Training loss: 0.058669
Epoch: 11 50000/60000 Training loss: 0.026255
Training loss: 0.025434
Test loss: 0.021832; Test accuracy: 9928/10000 (99.3%)

[I 2022-11-04 01:15:39,229] Trial 22 finished with value: 0.020247317850589752 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.17236807213809546, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 0.00020818564670309955}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 48, 'num_conv2_channels': 96, 'conv2_drop': 0.157445276922286, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 8.418962649428344e-05}
Epoch: 0 0/60000 Training loss: 2.299982
Epoch: 0 10000/60000 Training loss: 0.786227
Epoch: 0 20000/60000 Training loss: 0.421382
Epoch: 0 30000/60000 Training loss: 0.347689
Epoch: 0 40000/60000 Training loss: 0.228526
Epoch: 0 50000/60000 Training loss: 0.310716
Training loss: 0.556211
Test loss: 0.127554; Test accuracy: 9618/10000 (96.2%)

Epoch: 1 0/60000 Training loss: 0.149085
Epoch: 1 10000/60000 Training loss: 0.278603
Epoch: 1 20000/60000 Training loss: 0.216242
Epoch: 1 30000/60000 Training loss: 0.159849
Epoch: 1 40000/60000 Training loss: 0.102680
Epoch: 1 50000/60000 Training loss: 0.084813
Training loss: 0.161538
Test loss: 0.074661; Test accuracy: 9777/10000 (97.8%)

Epoch: 2 0/60000 Training loss: 0.076803
Epoch: 2 10000/60000 Training loss: 0.103730
Epoch: 2 20000/60000 Training loss: 0.130523
Epoch: 2 30000/60000 Training loss: 0.162650
Epoch: 2 40000/60000 Training loss: 0.176882
Epoch: 2 50000/60000 Training loss: 0.150238
Training loss: 0.111868
Test loss: 0.056578; Test accuracy: 9822/10000 (98.2%)

Epoch: 3 0/60000 Training loss: 0.151986
Epoch: 3 10000/60000 Training loss: 0.044293
Epoch: 3 20000/60000 Training loss: 0.081300
Epoch: 3 30000/60000 Training loss: 0.108668
Epoch: 3 40000/60000 Training loss: 0.067052
Epoch: 3 50000/60000 Training loss: 0.071755
Training loss: 0.090478
Test loss: 0.044369; Test accuracy: 9853/10000 (98.5%)

Epoch: 4 0/60000 Training loss: 0.072232
Epoch: 4 10000/60000 Training loss: 0.062108
Epoch: 4 20000/60000 Training loss: 0.093135
Epoch: 4 30000/60000 Training loss: 0.059058
Epoch: 4 40000/60000 Training loss: 0.043213
Epoch: 4 50000/60000 Training loss: 0.046490
Training loss: 0.074629
Test loss: 0.037590; Test accuracy: 9884/10000 (98.8%)

Epoch: 5 0/60000 Training loss: 0.145430
Epoch: 5 10000/60000 Training loss: 0.103012
Epoch: 5 20000/60000 Training loss: 0.059300
Epoch: 5 30000/60000 Training loss: 0.031472
Epoch: 5 40000/60000 Training loss: 0.098553
Epoch: 5 50000/60000 Training loss: 0.018778
Training loss: 0.065215
Test loss: 0.033802; Test accuracy: 9882/10000 (98.8%)

Epoch: 6 0/60000 Training loss: 0.062688
Epoch: 6 10000/60000 Training loss: 0.058950
Epoch: 6 20000/60000 Training loss: 0.112772
Epoch: 6 30000/60000 Training loss: 0.048575
Epoch: 6 40000/60000 Training loss: 0.084312
Epoch: 6 50000/60000 Training loss: 0.089259
Training loss: 0.059490
Test loss: 0.032833; Test accuracy: 9893/10000 (98.9%)

Epoch: 7 0/60000 Training loss: 0.069341
Epoch: 7 10000/60000 Training loss: 0.037772
Epoch: 7 20000/60000 Training loss: 0.101181
Epoch: 7 30000/60000 Training loss: 0.048809
Epoch: 7 40000/60000 Training loss: 0.024074
Epoch: 7 50000/60000 Training loss: 0.017821
Training loss: 0.052148
Test loss: 0.027478; Test accuracy: 9913/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.076847
Epoch: 8 10000/60000 Training loss: 0.024047
Epoch: 8 20000/60000 Training loss: 0.040597
Epoch: 8 30000/60000 Training loss: 0.038600
Epoch: 8 40000/60000 Training loss: 0.086846
Epoch: 8 50000/60000 Training loss: 0.055093
Training loss: 0.047241
Test loss: 0.026522; Test accuracy: 9916/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.031286
Epoch: 9 10000/60000 Training loss: 0.039210
Epoch: 9 20000/60000 Training loss: 0.018507
Epoch: 9 30000/60000 Training loss: 0.021823
Epoch: 9 40000/60000 Training loss: 0.019092
Epoch: 9 50000/60000 Training loss: 0.076307
Training loss: 0.044569
Test loss: 0.025803; Test accuracy: 9911/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.091623
Epoch: 10 10000/60000 Training loss: 0.076703
Epoch: 10 20000/60000 Training loss: 0.035379
Epoch: 10 30000/60000 Training loss: 0.023281
Epoch: 10 40000/60000 Training loss: 0.074777
Epoch: 10 50000/60000 Training loss: 0.020377
Training loss: 0.042007
Test loss: 0.024110; Test accuracy: 9914/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.028041
Epoch: 11 10000/60000 Training loss: 0.014338
Epoch: 11 20000/60000 Training loss: 0.068035
Epoch: 11 30000/60000 Training loss: 0.041290
Epoch: 11 40000/60000 Training loss: 0.009107
Epoch: 11 50000/60000 Training loss: 0.050129
Training loss: 0.038873
Test loss: 0.023833; Test accuracy: 9917/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.013051
Epoch: 12 10000/60000 Training loss: 0.030055
Epoch: 12 20000/60000 Training loss: 0.042777
Epoch: 12 30000/60000 Training loss: 0.016633
Epoch: 12 40000/60000 Training loss: 0.018301
Epoch: 12 50000/60000 Training loss: 0.082108
Training loss: 0.034965
Test loss: 0.021545; Test accuracy: 9927/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.011628
Epoch: 13 10000/60000 Training loss: 0.040658
Epoch: 13 20000/60000 Training loss: 0.004973
Epoch: 13 30000/60000 Training loss: 0.038034
Epoch: 13 40000/60000 Training loss: 0.028655
Epoch: 13 50000/60000 Training loss: 0.067992
Training loss: 0.032468
Test loss: 0.021287; Test accuracy: 9925/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.005238
Epoch: 14 10000/60000 Training loss: 0.049483
Epoch: 14 20000/60000 Training loss: 0.007843
Epoch: 14 30000/60000 Training loss: 0.089486
Epoch: 14 40000/60000 Training loss: 0.023222
Epoch: 14 50000/60000 Training loss: 0.082233
Training loss: 0.032250
Test loss: 0.020130; Test accuracy: 9935/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.002512
Epoch: 15 10000/60000 Training loss: 0.032129
Epoch: 15 20000/60000 Training loss: 0.066697
Epoch: 15 30000/60000 Training loss: 0.052614
Epoch: 15 40000/60000 Training loss: 0.087236
Epoch: 15 50000/60000 Training loss: 0.042908
Training loss: 0.028861
Test loss: 0.020600; Test accuracy: 9930/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.038673
Epoch: 16 10000/60000 Training loss: 0.016587
Epoch: 16 20000/60000 Training loss: 0.010825
Epoch: 16 30000/60000 Training loss: 0.084574
Epoch: 16 40000/60000 Training loss: 0.011217
Epoch: 16 50000/60000 Training loss: 0.011212
Training loss: 0.027016
Test loss: 0.021023; Test accuracy: 9932/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.030452
Epoch: 17 10000/60000 Training loss: 0.009228
Epoch: 17 20000/60000 Training loss: 0.021646
Epoch: 17 30000/60000 Training loss: 0.048415
Epoch: 17 40000/60000 Training loss: 0.004597
Epoch: 17 50000/60000 Training loss: 0.006950
Training loss: 0.025287
Test loss: 0.020720; Test accuracy: 9930/10000 (99.3%)

[I 2022-11-04 01:19:50,387] Trial 23 finished with value: 0.02013036608695984 and parameters: {'num_conv1_channels': 48, 'num_conv2_channels': 96, 'conv2_drop': 0.157445276922286, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 8.418962649428344e-05}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 48, 'conv2_drop': 0.1780845837190835, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00039450937922041427}
Epoch: 0 0/60000 Training loss: 2.313096
Epoch: 0 10000/60000 Training loss: 0.449795
Epoch: 0 20000/60000 Training loss: 0.180955
Epoch: 0 30000/60000 Training loss: 0.148065
Epoch: 0 40000/60000 Training loss: 0.121416
Epoch: 0 50000/60000 Training loss: 0.153905
Training loss: 0.329282
Test loss: 0.059561; Test accuracy: 9800/10000 (98.0%)

Epoch: 1 0/60000 Training loss: 0.105386
Epoch: 1 10000/60000 Training loss: 0.088724
Epoch: 1 20000/60000 Training loss: 0.243801
Epoch: 1 30000/60000 Training loss: 0.042859
Epoch: 1 40000/60000 Training loss: 0.064776
Epoch: 1 50000/60000 Training loss: 0.114335
Training loss: 0.102314
Test loss: 0.043044; Test accuracy: 9865/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.103934
Epoch: 2 10000/60000 Training loss: 0.089308
Epoch: 2 20000/60000 Training loss: 0.063439
Epoch: 2 30000/60000 Training loss: 0.098631
Epoch: 2 40000/60000 Training loss: 0.084952
Epoch: 2 50000/60000 Training loss: 0.012951
Training loss: 0.073958
Test loss: 0.031364; Test accuracy: 9899/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.033277
Epoch: 3 10000/60000 Training loss: 0.064163
Epoch: 3 20000/60000 Training loss: 0.129957
Epoch: 3 30000/60000 Training loss: 0.038119
Epoch: 3 40000/60000 Training loss: 0.066226
Epoch: 3 50000/60000 Training loss: 0.035596
Training loss: 0.060649
Test loss: 0.028107; Test accuracy: 9907/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.073452
Epoch: 4 10000/60000 Training loss: 0.091351
Epoch: 4 20000/60000 Training loss: 0.035110
Epoch: 4 30000/60000 Training loss: 0.086796
Epoch: 4 40000/60000 Training loss: 0.039309
Epoch: 4 50000/60000 Training loss: 0.199410
Training loss: 0.053162
Test loss: 0.028260; Test accuracy: 9908/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.020356
Epoch: 5 10000/60000 Training loss: 0.031702
Epoch: 5 20000/60000 Training loss: 0.044732
Epoch: 5 30000/60000 Training loss: 0.029669
Epoch: 5 40000/60000 Training loss: 0.020418
Epoch: 5 50000/60000 Training loss: 0.138607
Training loss: 0.045567
Test loss: 0.024889; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.022999
Epoch: 6 10000/60000 Training loss: 0.077020
Epoch: 6 20000/60000 Training loss: 0.006931
Epoch: 6 30000/60000 Training loss: 0.090266
Epoch: 6 40000/60000 Training loss: 0.040503
Epoch: 6 50000/60000 Training loss: 0.073301
Training loss: 0.042019
Test loss: 0.024497; Test accuracy: 9920/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.031880
Epoch: 7 10000/60000 Training loss: 0.093087
Epoch: 7 20000/60000 Training loss: 0.008592
Epoch: 7 30000/60000 Training loss: 0.011248
Epoch: 7 40000/60000 Training loss: 0.013348
Epoch: 7 50000/60000 Training loss: 0.054810
Training loss: 0.036726
Test loss: 0.022552; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.007646
Epoch: 8 10000/60000 Training loss: 0.015555
Epoch: 8 20000/60000 Training loss: 0.024958
Epoch: 8 30000/60000 Training loss: 0.030993
Epoch: 8 40000/60000 Training loss: 0.028311
Epoch: 8 50000/60000 Training loss: 0.010557
Training loss: 0.032340
Test loss: 0.021900; Test accuracy: 9937/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.020612
Epoch: 9 10000/60000 Training loss: 0.070662
Epoch: 9 20000/60000 Training loss: 0.143874
Epoch: 9 30000/60000 Training loss: 0.007388
Epoch: 9 40000/60000 Training loss: 0.067966
Epoch: 9 50000/60000 Training loss: 0.017719
Training loss: 0.029614
Test loss: 0.022666; Test accuracy: 9929/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.015420
Epoch: 10 10000/60000 Training loss: 0.002688
Epoch: 10 20000/60000 Training loss: 0.002876
Epoch: 10 30000/60000 Training loss: 0.005176
Epoch: 10 40000/60000 Training loss: 0.005332
Epoch: 10 50000/60000 Training loss: 0.056812
Training loss: 0.029210
Test loss: 0.022139; Test accuracy: 9934/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.007105
Epoch: 11 10000/60000 Training loss: 0.005614
Epoch: 11 20000/60000 Training loss: 0.065351
Epoch: 11 30000/60000 Training loss: 0.009602
Epoch: 11 40000/60000 Training loss: 0.055084
Epoch: 11 50000/60000 Training loss: 0.010416
Training loss: 0.026191
Test loss: 0.022241; Test accuracy: 9934/10000 (99.3%)

[I 2022-11-04 01:22:38,233] Trial 24 finished with value: 0.021899744868278503 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 48, 'conv2_drop': 0.1780845837190835, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00039450937922041427}. Best is trial 14 with value: 0.01799141988158226.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.158451845708855, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00019454816172831765}
Epoch: 0 0/60000 Training loss: 2.288438
Epoch: 0 10000/60000 Training loss: 0.628951
Epoch: 0 20000/60000 Training loss: 0.104423
Epoch: 0 30000/60000 Training loss: 0.167088
Epoch: 0 40000/60000 Training loss: 0.130429
Epoch: 0 50000/60000 Training loss: 0.180957
Training loss: 0.333897
Test loss: 0.064550; Test accuracy: 9808/10000 (98.1%)

Epoch: 1 0/60000 Training loss: 0.135106
Epoch: 1 10000/60000 Training loss: 0.229209
Epoch: 1 20000/60000 Training loss: 0.087873
Epoch: 1 30000/60000 Training loss: 0.174974
Epoch: 1 40000/60000 Training loss: 0.116643
Epoch: 1 50000/60000 Training loss: 0.090210
Training loss: 0.099663
Test loss: 0.041687; Test accuracy: 9864/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.058890
Epoch: 2 10000/60000 Training loss: 0.096484
Epoch: 2 20000/60000 Training loss: 0.019350
Epoch: 2 30000/60000 Training loss: 0.154272
Epoch: 2 40000/60000 Training loss: 0.054590
Epoch: 2 50000/60000 Training loss: 0.017754
Training loss: 0.071376
Test loss: 0.031512; Test accuracy: 9902/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.049296
Epoch: 3 10000/60000 Training loss: 0.106777
Epoch: 3 20000/60000 Training loss: 0.081674
Epoch: 3 30000/60000 Training loss: 0.056876
Epoch: 3 40000/60000 Training loss: 0.076981
Epoch: 3 50000/60000 Training loss: 0.102837
Training loss: 0.056949
Test loss: 0.030767; Test accuracy: 9899/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.075056
Epoch: 4 10000/60000 Training loss: 0.029236
Epoch: 4 20000/60000 Training loss: 0.020410
Epoch: 4 30000/60000 Training loss: 0.045672
Epoch: 4 40000/60000 Training loss: 0.011592
Epoch: 4 50000/60000 Training loss: 0.044060
Training loss: 0.048132
Test loss: 0.029115; Test accuracy: 9905/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.031004
Epoch: 5 10000/60000 Training loss: 0.036447
Epoch: 5 20000/60000 Training loss: 0.033672
Epoch: 5 30000/60000 Training loss: 0.050382
Epoch: 5 40000/60000 Training loss: 0.053867
Epoch: 5 50000/60000 Training loss: 0.015507
Training loss: 0.041137
Test loss: 0.021130; Test accuracy: 9927/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.048929
Epoch: 6 10000/60000 Training loss: 0.019457
Epoch: 6 20000/60000 Training loss: 0.004591
Epoch: 6 30000/60000 Training loss: 0.034501
Epoch: 6 40000/60000 Training loss: 0.044831
Epoch: 6 50000/60000 Training loss: 0.093502
Training loss: 0.034948
Test loss: 0.022144; Test accuracy: 9931/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.040759
Epoch: 7 10000/60000 Training loss: 0.017065
Epoch: 7 20000/60000 Training loss: 0.001501
Epoch: 7 30000/60000 Training loss: 0.014261
Epoch: 7 40000/60000 Training loss: 0.041977
Epoch: 7 50000/60000 Training loss: 0.012220
Training loss: 0.031644
Test loss: 0.021537; Test accuracy: 9923/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.024405
Epoch: 8 10000/60000 Training loss: 0.003546
Epoch: 8 20000/60000 Training loss: 0.004839
Epoch: 8 30000/60000 Training loss: 0.022292
Epoch: 8 40000/60000 Training loss: 0.047331
Epoch: 8 50000/60000 Training loss: 0.013120
Training loss: 0.029349
Test loss: 0.020053; Test accuracy: 9931/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.004538
Epoch: 9 10000/60000 Training loss: 0.010466
Epoch: 9 20000/60000 Training loss: 0.003198
Epoch: 9 30000/60000 Training loss: 0.010808
Epoch: 9 40000/60000 Training loss: 0.014644
Epoch: 9 50000/60000 Training loss: 0.012156
Training loss: 0.024049
Test loss: 0.023329; Test accuracy: 9923/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.110365
Epoch: 10 10000/60000 Training loss: 0.008083
Epoch: 10 20000/60000 Training loss: 0.047682
Epoch: 10 30000/60000 Training loss: 0.045766
Epoch: 10 40000/60000 Training loss: 0.028645
Epoch: 10 50000/60000 Training loss: 0.007967
Training loss: 0.025043
Test loss: 0.018978; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.006602
Epoch: 11 10000/60000 Training loss: 0.021250
Epoch: 11 20000/60000 Training loss: 0.010537
Epoch: 11 30000/60000 Training loss: 0.006452
Epoch: 11 40000/60000 Training loss: 0.039619
Epoch: 11 50000/60000 Training loss: 0.003601
Training loss: 0.021585
Test loss: 0.018980; Test accuracy: 9939/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.002918
Epoch: 12 10000/60000 Training loss: 0.004087
Epoch: 12 20000/60000 Training loss: 0.003152
Epoch: 12 30000/60000 Training loss: 0.008592
Epoch: 12 40000/60000 Training loss: 0.002527
Epoch: 12 50000/60000 Training loss: 0.025490
Training loss: 0.019976
Test loss: 0.018382; Test accuracy: 9940/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.029166
Epoch: 13 10000/60000 Training loss: 0.007574
Epoch: 13 20000/60000 Training loss: 0.013046
Epoch: 13 30000/60000 Training loss: 0.009057
Epoch: 13 40000/60000 Training loss: 0.026700
Epoch: 13 50000/60000 Training loss: 0.002849
Training loss: 0.017502
Test loss: 0.020192; Test accuracy: 9940/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.014407
Epoch: 14 10000/60000 Training loss: 0.027257
Epoch: 14 20000/60000 Training loss: 0.005645
Epoch: 14 30000/60000 Training loss: 0.002868
Epoch: 14 40000/60000 Training loss: 0.002111
Epoch: 14 50000/60000 Training loss: 0.003622
Training loss: 0.016099
Test loss: 0.018836; Test accuracy: 9936/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.001782
Epoch: 15 10000/60000 Training loss: 0.021758
Epoch: 15 20000/60000 Training loss: 0.073432
Epoch: 15 30000/60000 Training loss: 0.007880
Epoch: 15 40000/60000 Training loss: 0.004658
Epoch: 15 50000/60000 Training loss: 0.009591
Training loss: 0.016353
Test loss: 0.016268; Test accuracy: 9950/10000 (99.5%)

Epoch: 16 0/60000 Training loss: 0.001527
Epoch: 16 10000/60000 Training loss: 0.017569
Epoch: 16 20000/60000 Training loss: 0.003103
Epoch: 16 30000/60000 Training loss: 0.017871
Epoch: 16 40000/60000 Training loss: 0.010898
Epoch: 16 50000/60000 Training loss: 0.005337
Training loss: 0.015119
Test loss: 0.018178; Test accuracy: 9941/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.007360
Epoch: 17 10000/60000 Training loss: 0.008441
Epoch: 17 20000/60000 Training loss: 0.001780
Epoch: 17 30000/60000 Training loss: 0.035915
Epoch: 17 40000/60000 Training loss: 0.005382
Epoch: 17 50000/60000 Training loss: 0.000981
Training loss: 0.014204
Test loss: 0.018969; Test accuracy: 9946/10000 (99.5%)

Epoch: 18 0/60000 Training loss: 0.010793
Epoch: 18 10000/60000 Training loss: 0.001497
Epoch: 18 20000/60000 Training loss: 0.003345
Epoch: 18 30000/60000 Training loss: 0.018180
Epoch: 18 40000/60000 Training loss: 0.025312
Epoch: 18 50000/60000 Training loss: 0.027643
Training loss: 0.012841
Test loss: 0.017326; Test accuracy: 9948/10000 (99.5%)

[I 2022-11-04 01:27:03,764] Trial 25 finished with value: 0.01626817137002945 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.158451845708855, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00019454816172831765}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.1569994135014055, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.0004836598806835083}
Epoch: 0 0/60000 Training loss: 2.324538
Epoch: 0 10000/60000 Training loss: 0.253567
Epoch: 0 20000/60000 Training loss: 0.133767
Epoch: 0 30000/60000 Training loss: 0.118967
Epoch: 0 40000/60000 Training loss: 0.040697
Epoch: 0 50000/60000 Training loss: 0.114569
Training loss: 0.221789
Test loss: 0.043848; Test accuracy: 9862/10000 (98.6%)

Epoch: 1 0/60000 Training loss: 0.062943
Epoch: 1 10000/60000 Training loss: 0.042497
Epoch: 1 20000/60000 Training loss: 0.052782
Epoch: 1 30000/60000 Training loss: 0.013027
Epoch: 1 40000/60000 Training loss: 0.121997
Epoch: 1 50000/60000 Training loss: 0.069386
Training loss: 0.071603
Test loss: 0.028631; Test accuracy: 9909/10000 (99.1%)

Epoch: 2 0/60000 Training loss: 0.013828
Epoch: 2 10000/60000 Training loss: 0.076359
Epoch: 2 20000/60000 Training loss: 0.002599
Epoch: 2 30000/60000 Training loss: 0.018916
Epoch: 2 40000/60000 Training loss: 0.057629
Epoch: 2 50000/60000 Training loss: 0.011886
Training loss: 0.050407
Test loss: 0.025475; Test accuracy: 9915/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.036617
Epoch: 3 10000/60000 Training loss: 0.014071
Epoch: 3 20000/60000 Training loss: 0.006775
Epoch: 3 30000/60000 Training loss: 0.099198
Epoch: 3 40000/60000 Training loss: 0.019407
Epoch: 3 50000/60000 Training loss: 0.042832
Training loss: 0.043115
Test loss: 0.024392; Test accuracy: 9926/10000 (99.3%)

Epoch: 4 0/60000 Training loss: 0.053930
Epoch: 4 10000/60000 Training loss: 0.012984
Epoch: 4 20000/60000 Training loss: 0.024788
Epoch: 4 30000/60000 Training loss: 0.083000
Epoch: 4 40000/60000 Training loss: 0.020084
Epoch: 4 50000/60000 Training loss: 0.040401
Training loss: 0.035893
Test loss: 0.022430; Test accuracy: 9920/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.012131
Epoch: 5 10000/60000 Training loss: 0.004304
Epoch: 5 20000/60000 Training loss: 0.019163
Epoch: 5 30000/60000 Training loss: 0.085243
Epoch: 5 40000/60000 Training loss: 0.048806
Epoch: 5 50000/60000 Training loss: 0.040525
Training loss: 0.029505
Test loss: 0.018646; Test accuracy: 9944/10000 (99.4%)

Epoch: 6 0/60000 Training loss: 0.010852
Epoch: 6 10000/60000 Training loss: 0.052770
Epoch: 6 20000/60000 Training loss: 0.002376
Epoch: 6 30000/60000 Training loss: 0.015320
Epoch: 6 40000/60000 Training loss: 0.042034
Epoch: 6 50000/60000 Training loss: 0.093081
Training loss: 0.028004
Test loss: 0.019434; Test accuracy: 9940/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.031854
Epoch: 7 10000/60000 Training loss: 0.004816
Epoch: 7 20000/60000 Training loss: 0.010326
Epoch: 7 30000/60000 Training loss: 0.003457
Epoch: 7 40000/60000 Training loss: 0.001626
Epoch: 7 50000/60000 Training loss: 0.009810
Training loss: 0.023519
Test loss: 0.022909; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.044116
Epoch: 8 10000/60000 Training loss: 0.050477
Epoch: 8 20000/60000 Training loss: 0.042606
Epoch: 8 30000/60000 Training loss: 0.016384
Epoch: 8 40000/60000 Training loss: 0.027018
Epoch: 8 50000/60000 Training loss: 0.019651
Training loss: 0.023798
Test loss: 0.020118; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 01:29:13,091] Trial 26 finished with value: 0.01864561438560486 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.1569994135014055, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.0004836598806835083}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 96, 'conv2_drop': 0.11394778247202358, 'fc1_neurons': 90, 'optimizer': 'SGD', 'learning_rate': 0.00023505738261564308}
Epoch: 0 0/60000 Training loss: 2.331416
Epoch: 0 10000/60000 Training loss: 2.295742
Epoch: 0 20000/60000 Training loss: 2.277042
Epoch: 0 30000/60000 Training loss: 2.252717
Epoch: 0 40000/60000 Training loss: 2.255157
Epoch: 0 50000/60000 Training loss: 2.219561
Training loss: 2.259933
Test loss: 2.199662; Test accuracy: 4133/10000 (41.3%)

Epoch: 1 0/60000 Training loss: 2.209834
Epoch: 1 10000/60000 Training loss: 2.210812
Epoch: 1 20000/60000 Training loss: 2.164618
Epoch: 1 30000/60000 Training loss: 2.154322
Epoch: 1 40000/60000 Training loss: 2.107958
Epoch: 1 50000/60000 Training loss: 2.068489
Training loss: 2.149278
Test loss: 2.046212; Test accuracy: 6723/10000 (67.2%)

Epoch: 2 0/60000 Training loss: 2.080173
Epoch: 2 10000/60000 Training loss: 2.039892
Epoch: 2 20000/60000 Training loss: 2.014259
Epoch: 2 30000/60000 Training loss: 1.949231
Epoch: 2 40000/60000 Training loss: 1.936638
Epoch: 2 50000/60000 Training loss: 1.932275
Training loss: 1.977517
Test loss: 1.800584; Test accuracy: 7882/10000 (78.8%)

Epoch: 3 0/60000 Training loss: 1.865220
Epoch: 3 10000/60000 Training loss: 1.835911
Epoch: 3 20000/60000 Training loss: 1.704293
Epoch: 3 30000/60000 Training loss: 1.726128
Epoch: 3 40000/60000 Training loss: 1.648884
Epoch: 3 50000/60000 Training loss: 1.646552
Training loss: 1.731690
Test loss: 1.473733; Test accuracy: 8238/10000 (82.4%)

Epoch: 4 0/60000 Training loss: 1.540331
Epoch: 4 10000/60000 Training loss: 1.568720
Epoch: 4 20000/60000 Training loss: 1.567437
Epoch: 4 30000/60000 Training loss: 1.487303
Epoch: 4 40000/60000 Training loss: 1.319722
Epoch: 4 50000/60000 Training loss: 1.393021
Training loss: 1.458299
Test loss: 1.155920; Test accuracy: 8391/10000 (83.9%)

Epoch: 5 0/60000 Training loss: 1.190365
Epoch: 5 10000/60000 Training loss: 1.332513
Epoch: 5 20000/60000 Training loss: 1.179302
Epoch: 5 30000/60000 Training loss: 1.245468
Epoch: 5 40000/60000 Training loss: 1.239711
Epoch: 5 50000/60000 Training loss: 1.223786
Training loss: 1.227278
Test loss: 0.917441; Test accuracy: 8562/10000 (85.6%)

Epoch: 6 0/60000 Training loss: 1.051659
Epoch: 6 10000/60000 Training loss: 1.125032
Epoch: 6 20000/60000 Training loss: 1.101936
Epoch: 6 30000/60000 Training loss: 1.011056
Epoch: 6 40000/60000 Training loss: 1.190356
Epoch: 6 50000/60000 Training loss: 1.080426
Training loss: 1.050118
Test loss: 0.749248; Test accuracy: 8682/10000 (86.8%)

Epoch: 7 0/60000 Training loss: 0.856195
Epoch: 7 10000/60000 Training loss: 0.887443
Epoch: 7 20000/60000 Training loss: 0.920514
Epoch: 7 30000/60000 Training loss: 0.991860
Epoch: 7 40000/60000 Training loss: 0.780748
Epoch: 7 50000/60000 Training loss: 0.867712
Training loss: 0.921503
Test loss: 0.632225; Test accuracy: 8778/10000 (87.8%)

Epoch: 8 0/60000 Training loss: 0.905806
Epoch: 8 10000/60000 Training loss: 0.808989
Epoch: 8 20000/60000 Training loss: 0.716160
Epoch: 8 30000/60000 Training loss: 0.675297
Epoch: 8 40000/60000 Training loss: 0.799025
Epoch: 8 50000/60000 Training loss: 0.746590
Training loss: 0.833223
Test loss: 0.554755; Test accuracy: 8857/10000 (88.6%)

Epoch: 9 0/60000 Training loss: 0.652805
Epoch: 9 10000/60000 Training loss: 0.644816
Epoch: 9 20000/60000 Training loss: 0.867019
Epoch: 9 30000/60000 Training loss: 0.739179
Epoch: 9 40000/60000 Training loss: 0.749315
Epoch: 9 50000/60000 Training loss: 0.728504
Training loss: 0.754641
Test loss: 0.493524; Test accuracy: 8940/10000 (89.4%)

Epoch: 10 0/60000 Training loss: 0.780991
Epoch: 10 10000/60000 Training loss: 0.720485
Epoch: 10 20000/60000 Training loss: 0.725861
Epoch: 10 30000/60000 Training loss: 0.619558
Epoch: 10 40000/60000 Training loss: 0.626276
Epoch: 10 50000/60000 Training loss: 0.606513
Training loss: 0.701491
Test loss: 0.450187; Test accuracy: 8985/10000 (89.8%)

Epoch: 11 0/60000 Training loss: 0.643789
Epoch: 11 10000/60000 Training loss: 0.757620
Epoch: 11 20000/60000 Training loss: 0.595541
Epoch: 11 30000/60000 Training loss: 0.630210
Epoch: 11 40000/60000 Training loss: 0.618523
Epoch: 11 50000/60000 Training loss: 0.580149
Training loss: 0.655298
Test loss: 0.414535; Test accuracy: 9029/10000 (90.3%)

Epoch: 12 0/60000 Training loss: 0.578765
Epoch: 12 10000/60000 Training loss: 0.691842
Epoch: 12 20000/60000 Training loss: 0.585366
Epoch: 12 30000/60000 Training loss: 0.589858
Epoch: 12 40000/60000 Training loss: 0.593327
Epoch: 12 50000/60000 Training loss: 0.587173
Training loss: 0.617332
Test loss: 0.385486; Test accuracy: 9088/10000 (90.9%)

Epoch: 13 0/60000 Training loss: 0.522516
Epoch: 13 10000/60000 Training loss: 0.669158
Epoch: 13 20000/60000 Training loss: 0.502619
Epoch: 13 30000/60000 Training loss: 0.560792
Epoch: 13 40000/60000 Training loss: 0.537902
Epoch: 13 50000/60000 Training loss: 0.646824
Training loss: 0.583584
Test loss: 0.361765; Test accuracy: 9118/10000 (91.2%)

Epoch: 14 0/60000 Training loss: 0.708441
Epoch: 14 10000/60000 Training loss: 0.478758
Epoch: 14 20000/60000 Training loss: 0.533305
Epoch: 14 30000/60000 Training loss: 0.486893
Epoch: 14 40000/60000 Training loss: 0.538499
Epoch: 14 50000/60000 Training loss: 0.754218
Training loss: 0.554998
Test loss: 0.342171; Test accuracy: 9147/10000 (91.5%)

Epoch: 15 0/60000 Training loss: 0.470202
Epoch: 15 10000/60000 Training loss: 0.517351
Epoch: 15 20000/60000 Training loss: 0.523056
Epoch: 15 30000/60000 Training loss: 0.413436
Epoch: 15 40000/60000 Training loss: 0.618922
Epoch: 15 50000/60000 Training loss: 0.492240
Training loss: 0.532426
Test loss: 0.324512; Test accuracy: 9175/10000 (91.8%)

Epoch: 16 0/60000 Training loss: 0.668977
Epoch: 16 10000/60000 Training loss: 0.657003
Epoch: 16 20000/60000 Training loss: 0.638264
Epoch: 16 30000/60000 Training loss: 0.481197
Epoch: 16 40000/60000 Training loss: 0.502907
Epoch: 16 50000/60000 Training loss: 0.410841
Training loss: 0.510566
Test loss: 0.310177; Test accuracy: 9204/10000 (92.0%)

Epoch: 17 0/60000 Training loss: 0.449702
Epoch: 17 10000/60000 Training loss: 0.451117
Epoch: 17 20000/60000 Training loss: 0.674664
Epoch: 17 30000/60000 Training loss: 0.515325
Epoch: 17 40000/60000 Training loss: 0.502793
Epoch: 17 50000/60000 Training loss: 0.539670
Training loss: 0.492316
Test loss: 0.296224; Test accuracy: 9242/10000 (92.4%)

Epoch: 18 0/60000 Training loss: 0.476058
Epoch: 18 10000/60000 Training loss: 0.516108
Epoch: 18 20000/60000 Training loss: 0.671069
Epoch: 18 30000/60000 Training loss: 0.407104
Epoch: 18 40000/60000 Training loss: 0.411473
Epoch: 18 50000/60000 Training loss: 0.458315
Training loss: 0.472716
Test loss: 0.284781; Test accuracy: 9263/10000 (92.6%)

Epoch: 19 0/60000 Training loss: 0.491836
Epoch: 19 10000/60000 Training loss: 0.487051
Epoch: 19 20000/60000 Training loss: 0.492737
Epoch: 19 30000/60000 Training loss: 0.415757
Epoch: 19 40000/60000 Training loss: 0.584348
Epoch: 19 50000/60000 Training loss: 0.455759
Training loss: 0.458063
Test loss: 0.274625; Test accuracy: 9291/10000 (92.9%)

[I 2022-11-04 01:33:52,533] Trial 27 finished with value: 0.2746249735355377 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 96, 'conv2_drop': 0.11394778247202358, 'fc1_neurons': 90, 'optimizer': 'SGD', 'learning_rate': 0.00023505738261564308}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.13698917163004398, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 6.19402573555088e-05}
Epoch: 0 0/60000 Training loss: 2.313040
Epoch: 0 10000/60000 Training loss: 0.989241
Epoch: 0 20000/60000 Training loss: 0.463883
Epoch: 0 30000/60000 Training loss: 0.413379
Epoch: 0 40000/60000 Training loss: 0.280460
Epoch: 0 50000/60000 Training loss: 0.250650
Training loss: 0.587772
Test loss: 0.145330; Test accuracy: 9577/10000 (95.8%)

Epoch: 1 0/60000 Training loss: 0.207788
Epoch: 1 10000/60000 Training loss: 0.144999
Epoch: 1 20000/60000 Training loss: 0.234253
Epoch: 1 30000/60000 Training loss: 0.108923
Epoch: 1 40000/60000 Training loss: 0.209091
Epoch: 1 50000/60000 Training loss: 0.346656
Training loss: 0.186201
Test loss: 0.085937; Test accuracy: 9742/10000 (97.4%)

Epoch: 2 0/60000 Training loss: 0.208541
Epoch: 2 10000/60000 Training loss: 0.095533
Epoch: 2 20000/60000 Training loss: 0.151886
Epoch: 2 30000/60000 Training loss: 0.128931
Epoch: 2 40000/60000 Training loss: 0.144022
Epoch: 2 50000/60000 Training loss: 0.096277
Training loss: 0.129089
Test loss: 0.065389; Test accuracy: 9791/10000 (97.9%)

Epoch: 3 0/60000 Training loss: 0.241750
Epoch: 3 10000/60000 Training loss: 0.035369
Epoch: 3 20000/60000 Training loss: 0.142596
Epoch: 3 30000/60000 Training loss: 0.196880
Epoch: 3 40000/60000 Training loss: 0.095444
Epoch: 3 50000/60000 Training loss: 0.045442
Training loss: 0.102528
Test loss: 0.052587; Test accuracy: 9829/10000 (98.3%)

Epoch: 4 0/60000 Training loss: 0.052306
Epoch: 4 10000/60000 Training loss: 0.066109
Epoch: 4 20000/60000 Training loss: 0.026114
Epoch: 4 30000/60000 Training loss: 0.093019
Epoch: 4 40000/60000 Training loss: 0.041750
Epoch: 4 50000/60000 Training loss: 0.162163
Training loss: 0.083923
Test loss: 0.043870; Test accuracy: 9852/10000 (98.5%)

Epoch: 5 0/60000 Training loss: 0.079048
Epoch: 5 10000/60000 Training loss: 0.054071
Epoch: 5 20000/60000 Training loss: 0.058181
Epoch: 5 30000/60000 Training loss: 0.074904
Epoch: 5 40000/60000 Training loss: 0.056484
Epoch: 5 50000/60000 Training loss: 0.016732
Training loss: 0.076288
Test loss: 0.040339; Test accuracy: 9871/10000 (98.7%)

Epoch: 6 0/60000 Training loss: 0.071180
Epoch: 6 10000/60000 Training loss: 0.113268
Epoch: 6 20000/60000 Training loss: 0.029371
Epoch: 6 30000/60000 Training loss: 0.038074
Epoch: 6 40000/60000 Training loss: 0.059872
Epoch: 6 50000/60000 Training loss: 0.092116
Training loss: 0.067265
Test loss: 0.032648; Test accuracy: 9890/10000 (98.9%)

Epoch: 7 0/60000 Training loss: 0.024233
Epoch: 7 10000/60000 Training loss: 0.036306
Epoch: 7 20000/60000 Training loss: 0.085749
Epoch: 7 30000/60000 Training loss: 0.044323
Epoch: 7 40000/60000 Training loss: 0.060410
Epoch: 7 50000/60000 Training loss: 0.079143
Training loss: 0.059153
Test loss: 0.031888; Test accuracy: 9902/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.051768
Epoch: 8 10000/60000 Training loss: 0.060563
Epoch: 8 20000/60000 Training loss: 0.027371
Epoch: 8 30000/60000 Training loss: 0.072702
Epoch: 8 40000/60000 Training loss: 0.071906
Epoch: 8 50000/60000 Training loss: 0.103665
Training loss: 0.054046
Test loss: 0.029483; Test accuracy: 9901/10000 (99.0%)

Epoch: 9 0/60000 Training loss: 0.010362
Epoch: 9 10000/60000 Training loss: 0.052477
Epoch: 9 20000/60000 Training loss: 0.054703
Epoch: 9 30000/60000 Training loss: 0.040827
Epoch: 9 40000/60000 Training loss: 0.061800
Epoch: 9 50000/60000 Training loss: 0.075894
Training loss: 0.049670
Test loss: 0.026233; Test accuracy: 9912/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.121764
Epoch: 10 10000/60000 Training loss: 0.012725
Epoch: 10 20000/60000 Training loss: 0.046475
Epoch: 10 30000/60000 Training loss: 0.106138
Epoch: 10 40000/60000 Training loss: 0.060563
Epoch: 10 50000/60000 Training loss: 0.085566
Training loss: 0.046638
Test loss: 0.028156; Test accuracy: 9909/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.069429
Epoch: 11 10000/60000 Training loss: 0.024715
Epoch: 11 20000/60000 Training loss: 0.019574
Epoch: 11 30000/60000 Training loss: 0.043220
Epoch: 11 40000/60000 Training loss: 0.009776
Epoch: 11 50000/60000 Training loss: 0.034580
Training loss: 0.043236
Test loss: 0.025017; Test accuracy: 9911/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.026871
Epoch: 12 10000/60000 Training loss: 0.058963
Epoch: 12 20000/60000 Training loss: 0.016254
Epoch: 12 30000/60000 Training loss: 0.017656
Epoch: 12 40000/60000 Training loss: 0.041734
Epoch: 12 50000/60000 Training loss: 0.034935
Training loss: 0.039470
Test loss: 0.025103; Test accuracy: 9920/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.024093
Epoch: 13 10000/60000 Training loss: 0.041521
Epoch: 13 20000/60000 Training loss: 0.022469
Epoch: 13 30000/60000 Training loss: 0.062385
Epoch: 13 40000/60000 Training loss: 0.006524
Epoch: 13 50000/60000 Training loss: 0.033951
Training loss: 0.037736
Test loss: 0.023561; Test accuracy: 9916/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.018605
Epoch: 14 10000/60000 Training loss: 0.019756
Epoch: 14 20000/60000 Training loss: 0.112287
Epoch: 14 30000/60000 Training loss: 0.023525
Epoch: 14 40000/60000 Training loss: 0.036580
Epoch: 14 50000/60000 Training loss: 0.021836
Training loss: 0.034920
Test loss: 0.022613; Test accuracy: 9927/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.008694
Epoch: 15 10000/60000 Training loss: 0.039797
Epoch: 15 20000/60000 Training loss: 0.026962
Epoch: 15 30000/60000 Training loss: 0.035670
Epoch: 15 40000/60000 Training loss: 0.080085
Epoch: 15 50000/60000 Training loss: 0.021065
Training loss: 0.034375
Test loss: 0.023025; Test accuracy: 9922/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.043087
Epoch: 16 10000/60000 Training loss: 0.044226
Epoch: 16 20000/60000 Training loss: 0.036033
Epoch: 16 30000/60000 Training loss: 0.005163
Epoch: 16 40000/60000 Training loss: 0.017811
Epoch: 16 50000/60000 Training loss: 0.003285
Training loss: 0.030682
Test loss: 0.022672; Test accuracy: 9923/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.036245
Epoch: 17 10000/60000 Training loss: 0.023938
Epoch: 17 20000/60000 Training loss: 0.021340
Epoch: 17 30000/60000 Training loss: 0.110240
Epoch: 17 40000/60000 Training loss: 0.048845
Epoch: 17 50000/60000 Training loss: 0.013874
Training loss: 0.029868
Test loss: 0.021349; Test accuracy: 9923/10000 (99.2%)

Epoch: 18 0/60000 Training loss: 0.044817
Epoch: 18 10000/60000 Training loss: 0.025363
Epoch: 18 20000/60000 Training loss: 0.008975
Epoch: 18 30000/60000 Training loss: 0.022692
Epoch: 18 40000/60000 Training loss: 0.039754
Epoch: 18 50000/60000 Training loss: 0.015624
Training loss: 0.028189
Test loss: 0.021384; Test accuracy: 9922/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.004005
Epoch: 19 10000/60000 Training loss: 0.057009
Epoch: 19 20000/60000 Training loss: 0.006695
Epoch: 19 30000/60000 Training loss: 0.099356
Epoch: 19 40000/60000 Training loss: 0.028849
Epoch: 19 50000/60000 Training loss: 0.083754
Training loss: 0.026625
Test loss: 0.020717; Test accuracy: 9925/10000 (99.2%)

[I 2022-11-04 01:38:32,607] Trial 28 finished with value: 0.020716998726129532 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.13698917163004398, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 6.19402573555088e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.13946772038468797, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 9.353139721007898e-05}
Epoch: 0 0/60000 Training loss: 2.297215
Epoch: 0 10000/60000 Training loss: 0.625186
Epoch: 0 20000/60000 Training loss: 0.385341
Epoch: 0 30000/60000 Training loss: 0.236341
Epoch: 0 40000/60000 Training loss: 0.228617
Epoch: 0 50000/60000 Training loss: 0.101354
Training loss: 0.433553
Test loss: 0.096191; Test accuracy: 9703/10000 (97.0%)

Epoch: 1 0/60000 Training loss: 0.132638
Epoch: 1 10000/60000 Training loss: 0.169036
Epoch: 1 20000/60000 Training loss: 0.143638
Epoch: 1 30000/60000 Training loss: 0.107659
Epoch: 1 40000/60000 Training loss: 0.124989
Epoch: 1 50000/60000 Training loss: 0.150645
Training loss: 0.127929
Test loss: 0.057800; Test accuracy: 9806/10000 (98.1%)

Epoch: 2 0/60000 Training loss: 0.044810
Epoch: 2 10000/60000 Training loss: 0.136736
Epoch: 2 20000/60000 Training loss: 0.159546
Epoch: 2 30000/60000 Training loss: 0.247279
Epoch: 2 40000/60000 Training loss: 0.038601
Epoch: 2 50000/60000 Training loss: 0.126259
Training loss: 0.089196
Test loss: 0.042637; Test accuracy: 9856/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.088011
Epoch: 3 10000/60000 Training loss: 0.093297
Epoch: 3 20000/60000 Training loss: 0.098987
Epoch: 3 30000/60000 Training loss: 0.028023
Epoch: 3 40000/60000 Training loss: 0.027484
Epoch: 3 50000/60000 Training loss: 0.017247
Training loss: 0.072013
Test loss: 0.036003; Test accuracy: 9879/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.130056
Epoch: 4 10000/60000 Training loss: 0.059550
Epoch: 4 20000/60000 Training loss: 0.033793
Epoch: 4 30000/60000 Training loss: 0.066493
Epoch: 4 40000/60000 Training loss: 0.021174
Epoch: 4 50000/60000 Training loss: 0.105899
Training loss: 0.060462
Test loss: 0.031546; Test accuracy: 9901/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.079191
Epoch: 5 10000/60000 Training loss: 0.163532
Epoch: 5 20000/60000 Training loss: 0.012224
Epoch: 5 30000/60000 Training loss: 0.068198
Epoch: 5 40000/60000 Training loss: 0.043209
Epoch: 5 50000/60000 Training loss: 0.110034
Training loss: 0.052761
Test loss: 0.027138; Test accuracy: 9900/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.025929
Epoch: 6 10000/60000 Training loss: 0.079749
Epoch: 6 20000/60000 Training loss: 0.040017
Epoch: 6 30000/60000 Training loss: 0.037623
Epoch: 6 40000/60000 Training loss: 0.063338
Epoch: 6 50000/60000 Training loss: 0.016680
Training loss: 0.046924
Test loss: 0.026710; Test accuracy: 9906/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.024668
Epoch: 7 10000/60000 Training loss: 0.043254
Epoch: 7 20000/60000 Training loss: 0.029846
Epoch: 7 30000/60000 Training loss: 0.059806
Epoch: 7 40000/60000 Training loss: 0.018563
Epoch: 7 50000/60000 Training loss: 0.008835
Training loss: 0.041709
Test loss: 0.023803; Test accuracy: 9921/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.019331
Epoch: 8 10000/60000 Training loss: 0.029603
Epoch: 8 20000/60000 Training loss: 0.024528
Epoch: 8 30000/60000 Training loss: 0.024431
Epoch: 8 40000/60000 Training loss: 0.029650
Epoch: 8 50000/60000 Training loss: 0.017460
Training loss: 0.036568
Test loss: 0.024146; Test accuracy: 9912/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.042772
Epoch: 9 10000/60000 Training loss: 0.067388
Epoch: 9 20000/60000 Training loss: 0.056928
Epoch: 9 30000/60000 Training loss: 0.013090
Epoch: 9 40000/60000 Training loss: 0.099541
Epoch: 9 50000/60000 Training loss: 0.012798
Training loss: 0.033632
Test loss: 0.024167; Test accuracy: 9919/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.011138
Epoch: 10 10000/60000 Training loss: 0.012197
Epoch: 10 20000/60000 Training loss: 0.034566
Epoch: 10 30000/60000 Training loss: 0.010157
Epoch: 10 40000/60000 Training loss: 0.088309
Epoch: 10 50000/60000 Training loss: 0.016408
Training loss: 0.032463
Test loss: 0.020114; Test accuracy: 9934/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.013441
Epoch: 11 10000/60000 Training loss: 0.021955
Epoch: 11 20000/60000 Training loss: 0.026410
Epoch: 11 30000/60000 Training loss: 0.053780
Epoch: 11 40000/60000 Training loss: 0.011196
Epoch: 11 50000/60000 Training loss: 0.016875
Training loss: 0.028507
Test loss: 0.019426; Test accuracy: 9935/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.028482
Epoch: 12 10000/60000 Training loss: 0.039891
Epoch: 12 20000/60000 Training loss: 0.013999
Epoch: 12 30000/60000 Training loss: 0.024567
Epoch: 12 40000/60000 Training loss: 0.027483
Epoch: 12 50000/60000 Training loss: 0.047090
Training loss: 0.026624
Test loss: 0.020420; Test accuracy: 9931/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.013879
Epoch: 13 10000/60000 Training loss: 0.005716
Epoch: 13 20000/60000 Training loss: 0.007650
Epoch: 13 30000/60000 Training loss: 0.021142
Epoch: 13 40000/60000 Training loss: 0.014310
Epoch: 13 50000/60000 Training loss: 0.013972
Training loss: 0.024373
Test loss: 0.020833; Test accuracy: 9931/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.044150
Epoch: 14 10000/60000 Training loss: 0.032935
Epoch: 14 20000/60000 Training loss: 0.005058
Epoch: 14 30000/60000 Training loss: 0.032114
Epoch: 14 40000/60000 Training loss: 0.012710
Epoch: 14 50000/60000 Training loss: 0.016218
Training loss: 0.021886
Test loss: 0.020234; Test accuracy: 9930/10000 (99.3%)

[I 2022-11-04 01:42:02,687] Trial 29 finished with value: 0.01942562870681286 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.13946772038468797, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 9.353139721007898e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 32, 'conv2_drop': 0.1607986799478092, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00013683903588250973}
Epoch: 0 0/60000 Training loss: 2.297255
Epoch: 0 10000/60000 Training loss: 0.749506
Epoch: 0 20000/60000 Training loss: 0.431516
Epoch: 0 30000/60000 Training loss: 0.267160
Epoch: 0 40000/60000 Training loss: 0.316565
Epoch: 0 50000/60000 Training loss: 0.237401
Training loss: 0.510766
Test loss: 0.101455; Test accuracy: 9691/10000 (96.9%)

Epoch: 1 0/60000 Training loss: 0.207575
Epoch: 1 10000/60000 Training loss: 0.303424
Epoch: 1 20000/60000 Training loss: 0.160840
Epoch: 1 30000/60000 Training loss: 0.084914
Epoch: 1 40000/60000 Training loss: 0.100477
Epoch: 1 50000/60000 Training loss: 0.209955
Training loss: 0.152340
Test loss: 0.062525; Test accuracy: 9807/10000 (98.1%)

Epoch: 2 0/60000 Training loss: 0.207657
Epoch: 2 10000/60000 Training loss: 0.078390
Epoch: 2 20000/60000 Training loss: 0.121696
Epoch: 2 30000/60000 Training loss: 0.093914
Epoch: 2 40000/60000 Training loss: 0.043054
Epoch: 2 50000/60000 Training loss: 0.116521
Training loss: 0.108491
Test loss: 0.047078; Test accuracy: 9841/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.066756
Epoch: 3 10000/60000 Training loss: 0.130858
Epoch: 3 20000/60000 Training loss: 0.025431
Epoch: 3 30000/60000 Training loss: 0.138920
Epoch: 3 40000/60000 Training loss: 0.091685
Epoch: 3 50000/60000 Training loss: 0.049934
Training loss: 0.087849
Test loss: 0.039576; Test accuracy: 9869/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.061034
Epoch: 4 10000/60000 Training loss: 0.118626
Epoch: 4 20000/60000 Training loss: 0.111512
Epoch: 4 30000/60000 Training loss: 0.068885
Epoch: 4 40000/60000 Training loss: 0.028610
Epoch: 4 50000/60000 Training loss: 0.130131
Training loss: 0.075140
Test loss: 0.036898; Test accuracy: 9879/10000 (98.8%)

Epoch: 5 0/60000 Training loss: 0.081860
Epoch: 5 10000/60000 Training loss: 0.038569
Epoch: 5 20000/60000 Training loss: 0.033720
Epoch: 5 30000/60000 Training loss: 0.060019
Epoch: 5 40000/60000 Training loss: 0.025570
Epoch: 5 50000/60000 Training loss: 0.045329
Training loss: 0.064516
Test loss: 0.029189; Test accuracy: 9909/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.086223
Epoch: 6 10000/60000 Training loss: 0.040256
Epoch: 6 20000/60000 Training loss: 0.049863
Epoch: 6 30000/60000 Training loss: 0.063771
Epoch: 6 40000/60000 Training loss: 0.055457
Epoch: 6 50000/60000 Training loss: 0.024116
Training loss: 0.058318
Test loss: 0.029470; Test accuracy: 9893/10000 (98.9%)

Epoch: 7 0/60000 Training loss: 0.044631
Epoch: 7 10000/60000 Training loss: 0.114769
Epoch: 7 20000/60000 Training loss: 0.076664
Epoch: 7 30000/60000 Training loss: 0.076595
Epoch: 7 40000/60000 Training loss: 0.011505
Epoch: 7 50000/60000 Training loss: 0.021624
Training loss: 0.053355
Test loss: 0.026455; Test accuracy: 9912/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.025877
Epoch: 8 10000/60000 Training loss: 0.051248
Epoch: 8 20000/60000 Training loss: 0.070859
Epoch: 8 30000/60000 Training loss: 0.048251
Epoch: 8 40000/60000 Training loss: 0.026259
Epoch: 8 50000/60000 Training loss: 0.026857
Training loss: 0.047957
Test loss: 0.024803; Test accuracy: 9916/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.049602
Epoch: 9 10000/60000 Training loss: 0.018319
Epoch: 9 20000/60000 Training loss: 0.038784
Epoch: 9 30000/60000 Training loss: 0.033187
Epoch: 9 40000/60000 Training loss: 0.047184
Epoch: 9 50000/60000 Training loss: 0.047311
Training loss: 0.043816
Test loss: 0.023606; Test accuracy: 9923/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.043140
Epoch: 10 10000/60000 Training loss: 0.006702
Epoch: 10 20000/60000 Training loss: 0.023880
Epoch: 10 30000/60000 Training loss: 0.057458
Epoch: 10 40000/60000 Training loss: 0.072113
Epoch: 10 50000/60000 Training loss: 0.040149
Training loss: 0.041675
Test loss: 0.023458; Test accuracy: 9915/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.047682
Epoch: 11 10000/60000 Training loss: 0.020536
Epoch: 11 20000/60000 Training loss: 0.057502
Epoch: 11 30000/60000 Training loss: 0.110506
Epoch: 11 40000/60000 Training loss: 0.010168
Epoch: 11 50000/60000 Training loss: 0.086638
Training loss: 0.039486
Test loss: 0.021567; Test accuracy: 9923/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.004469
Epoch: 12 10000/60000 Training loss: 0.068195
Epoch: 12 20000/60000 Training loss: 0.023803
Epoch: 12 30000/60000 Training loss: 0.011076
Epoch: 12 40000/60000 Training loss: 0.017149
Epoch: 12 50000/60000 Training loss: 0.026190
Training loss: 0.036017
Test loss: 0.022589; Test accuracy: 9923/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.024699
Epoch: 13 10000/60000 Training loss: 0.109479
Epoch: 13 20000/60000 Training loss: 0.049427
Epoch: 13 30000/60000 Training loss: 0.003676
Epoch: 13 40000/60000 Training loss: 0.009162
Epoch: 13 50000/60000 Training loss: 0.043029
Training loss: 0.033939
Test loss: 0.020855; Test accuracy: 9932/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.008431
Epoch: 14 10000/60000 Training loss: 0.040180
Epoch: 14 20000/60000 Training loss: 0.013486
Epoch: 14 30000/60000 Training loss: 0.038812
Epoch: 14 40000/60000 Training loss: 0.010982
Epoch: 14 50000/60000 Training loss: 0.004344
Training loss: 0.032717
Test loss: 0.021991; Test accuracy: 9922/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.050574
Epoch: 15 10000/60000 Training loss: 0.032880
Epoch: 15 20000/60000 Training loss: 0.016753
Epoch: 15 30000/60000 Training loss: 0.026964
Epoch: 15 40000/60000 Training loss: 0.082920
Epoch: 15 50000/60000 Training loss: 0.007915
Training loss: 0.030759
Test loss: 0.021109; Test accuracy: 9932/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.003911
Epoch: 16 10000/60000 Training loss: 0.041962
Epoch: 16 20000/60000 Training loss: 0.004746
Epoch: 16 30000/60000 Training loss: 0.012414
Epoch: 16 40000/60000 Training loss: 0.008457
Epoch: 16 50000/60000 Training loss: 0.041371
Training loss: 0.029434
Test loss: 0.019543; Test accuracy: 9937/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.001266
Epoch: 17 10000/60000 Training loss: 0.003577
Epoch: 17 20000/60000 Training loss: 0.014448
Epoch: 17 30000/60000 Training loss: 0.007674
Epoch: 17 40000/60000 Training loss: 0.009821
Epoch: 17 50000/60000 Training loss: 0.019587
Training loss: 0.026832
Test loss: 0.020852; Test accuracy: 9935/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.030505
Epoch: 18 10000/60000 Training loss: 0.008471
Epoch: 18 20000/60000 Training loss: 0.056013
Epoch: 18 30000/60000 Training loss: 0.041103
Epoch: 18 40000/60000 Training loss: 0.033874
Epoch: 18 50000/60000 Training loss: 0.001148
Training loss: 0.025873
Test loss: 0.018753; Test accuracy: 9936/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.005846
Epoch: 19 10000/60000 Training loss: 0.016554
Epoch: 19 20000/60000 Training loss: 0.037021
Epoch: 19 30000/60000 Training loss: 0.051137
Epoch: 19 40000/60000 Training loss: 0.008730
Epoch: 19 50000/60000 Training loss: 0.014720
Training loss: 0.023556
Test loss: 0.018792; Test accuracy: 9941/10000 (99.4%)

[I 2022-11-04 01:46:45,745] Trial 30 finished with value: 0.018752839416265488 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 32, 'conv2_drop': 0.1607986799478092, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00013683903588250973}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.17428084938881158, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001702918953153649}
Epoch: 0 0/60000 Training loss: 2.344980
Epoch: 0 10000/60000 Training loss: 0.414340
Epoch: 0 20000/60000 Training loss: 0.225389
Epoch: 0 30000/60000 Training loss: 0.157102
Epoch: 0 40000/60000 Training loss: 0.171396
Epoch: 0 50000/60000 Training loss: 0.171189
Training loss: 0.360757
Test loss: 0.072155; Test accuracy: 9769/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.095575
Epoch: 1 10000/60000 Training loss: 0.096810
Epoch: 1 20000/60000 Training loss: 0.078898
Epoch: 1 30000/60000 Training loss: 0.229476
Epoch: 1 40000/60000 Training loss: 0.122420
Epoch: 1 50000/60000 Training loss: 0.048232
Training loss: 0.107675
Test loss: 0.048004; Test accuracy: 9850/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.089912
Epoch: 2 10000/60000 Training loss: 0.105059
Epoch: 2 20000/60000 Training loss: 0.077406
Epoch: 2 30000/60000 Training loss: 0.118250
Epoch: 2 40000/60000 Training loss: 0.082584
Epoch: 2 50000/60000 Training loss: 0.141963
Training loss: 0.077011
Test loss: 0.036159; Test accuracy: 9884/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.113970
Epoch: 3 10000/60000 Training loss: 0.070321
Epoch: 3 20000/60000 Training loss: 0.031120
Epoch: 3 30000/60000 Training loss: 0.023267
Epoch: 3 40000/60000 Training loss: 0.110389
Epoch: 3 50000/60000 Training loss: 0.065135
Training loss: 0.061531
Test loss: 0.028432; Test accuracy: 9912/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.109247
Epoch: 4 10000/60000 Training loss: 0.029401
Epoch: 4 20000/60000 Training loss: 0.015894
Epoch: 4 30000/60000 Training loss: 0.044430
Epoch: 4 40000/60000 Training loss: 0.098058
Epoch: 4 50000/60000 Training loss: 0.074249
Training loss: 0.053229
Test loss: 0.025407; Test accuracy: 9920/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.030724
Epoch: 5 10000/60000 Training loss: 0.030138
Epoch: 5 20000/60000 Training loss: 0.119461
Epoch: 5 30000/60000 Training loss: 0.014998
Epoch: 5 40000/60000 Training loss: 0.066701
Epoch: 5 50000/60000 Training loss: 0.038837
Training loss: 0.045926
Test loss: 0.025202; Test accuracy: 9921/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.064034
Epoch: 6 10000/60000 Training loss: 0.028811
Epoch: 6 20000/60000 Training loss: 0.011317
Epoch: 6 30000/60000 Training loss: 0.016980
Epoch: 6 40000/60000 Training loss: 0.156998
Epoch: 6 50000/60000 Training loss: 0.079832
Training loss: 0.039927
Test loss: 0.024926; Test accuracy: 9909/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.016663
Epoch: 7 10000/60000 Training loss: 0.028300
Epoch: 7 20000/60000 Training loss: 0.020416
Epoch: 7 30000/60000 Training loss: 0.098954
Epoch: 7 40000/60000 Training loss: 0.053786
Epoch: 7 50000/60000 Training loss: 0.006813
Training loss: 0.036390
Test loss: 0.019440; Test accuracy: 9932/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.006807
Epoch: 8 10000/60000 Training loss: 0.038146
Epoch: 8 20000/60000 Training loss: 0.064958
Epoch: 8 30000/60000 Training loss: 0.013428
Epoch: 8 40000/60000 Training loss: 0.046392
Epoch: 8 50000/60000 Training loss: 0.018498
Training loss: 0.031802
Test loss: 0.019384; Test accuracy: 9936/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.029124
Epoch: 9 10000/60000 Training loss: 0.104547
Epoch: 9 20000/60000 Training loss: 0.018381
Epoch: 9 30000/60000 Training loss: 0.006474
Epoch: 9 40000/60000 Training loss: 0.023893
Epoch: 9 50000/60000 Training loss: 0.033527
Training loss: 0.029798
Test loss: 0.021143; Test accuracy: 9928/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.025449
Epoch: 10 10000/60000 Training loss: 0.003991
Epoch: 10 20000/60000 Training loss: 0.026238
Epoch: 10 30000/60000 Training loss: 0.011392
Epoch: 10 40000/60000 Training loss: 0.083410
Epoch: 10 50000/60000 Training loss: 0.021846
Training loss: 0.026733
Test loss: 0.019998; Test accuracy: 9931/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.024713
Epoch: 11 10000/60000 Training loss: 0.053010
Epoch: 11 20000/60000 Training loss: 0.005134
Epoch: 11 30000/60000 Training loss: 0.014175
Epoch: 11 40000/60000 Training loss: 0.100010
Epoch: 11 50000/60000 Training loss: 0.022583
Training loss: 0.024870
Test loss: 0.019261; Test accuracy: 9936/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.066059
Epoch: 12 10000/60000 Training loss: 0.029335
Epoch: 12 20000/60000 Training loss: 0.032235
Epoch: 12 30000/60000 Training loss: 0.008666
Epoch: 12 40000/60000 Training loss: 0.025976
Epoch: 12 50000/60000 Training loss: 0.020580
Training loss: 0.021307
Test loss: 0.021227; Test accuracy: 9935/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.006807
Epoch: 13 10000/60000 Training loss: 0.027410
Epoch: 13 20000/60000 Training loss: 0.020627
Epoch: 13 30000/60000 Training loss: 0.013661
Epoch: 13 40000/60000 Training loss: 0.002884
Epoch: 13 50000/60000 Training loss: 0.056130
Training loss: 0.020268
Test loss: 0.019073; Test accuracy: 9938/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.020625
Epoch: 14 10000/60000 Training loss: 0.027132
Epoch: 14 20000/60000 Training loss: 0.007563
Epoch: 14 30000/60000 Training loss: 0.008566
Epoch: 14 40000/60000 Training loss: 0.002299
Epoch: 14 50000/60000 Training loss: 0.129211
Training loss: 0.018910
Test loss: 0.019336; Test accuracy: 9943/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.017797
Epoch: 15 10000/60000 Training loss: 0.012601
Epoch: 15 20000/60000 Training loss: 0.003268
Epoch: 15 30000/60000 Training loss: 0.028256
Epoch: 15 40000/60000 Training loss: 0.055647
Epoch: 15 50000/60000 Training loss: 0.017714
Training loss: 0.017917
Test loss: 0.020490; Test accuracy: 9939/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.017192
Epoch: 16 10000/60000 Training loss: 0.028211
Epoch: 16 20000/60000 Training loss: 0.032414
Epoch: 16 30000/60000 Training loss: 0.006086
Epoch: 16 40000/60000 Training loss: 0.001442
Epoch: 16 50000/60000 Training loss: 0.045179
Training loss: 0.016829
Test loss: 0.020298; Test accuracy: 9942/10000 (99.4%)

[I 2022-11-04 01:50:42,993] Trial 31 finished with value: 0.01907348446547985 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.17428084938881158, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001702918953153649}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.1826615667590497, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00011196607760987047}
Epoch: 0 0/60000 Training loss: 2.355498
Epoch: 0 10000/60000 Training loss: 0.806683
Epoch: 0 20000/60000 Training loss: 0.400267
Epoch: 0 30000/60000 Training loss: 0.248268
Epoch: 0 40000/60000 Training loss: 0.224221
Epoch: 0 50000/60000 Training loss: 0.253056
Training loss: 0.532456
Test loss: 0.115753; Test accuracy: 9658/10000 (96.6%)

Epoch: 1 0/60000 Training loss: 0.152221
Epoch: 1 10000/60000 Training loss: 0.231150
Epoch: 1 20000/60000 Training loss: 0.156455
Epoch: 1 30000/60000 Training loss: 0.151687
Epoch: 1 40000/60000 Training loss: 0.070360
Epoch: 1 50000/60000 Training loss: 0.153281
Training loss: 0.162702
Test loss: 0.068482; Test accuracy: 9774/10000 (97.7%)

Epoch: 2 0/60000 Training loss: 0.269056
Epoch: 2 10000/60000 Training loss: 0.114092
Epoch: 2 20000/60000 Training loss: 0.104147
Epoch: 2 30000/60000 Training loss: 0.084033
Epoch: 2 40000/60000 Training loss: 0.056674
Epoch: 2 50000/60000 Training loss: 0.115505
Training loss: 0.112742
Test loss: 0.048998; Test accuracy: 9840/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.082580
Epoch: 3 10000/60000 Training loss: 0.177659
Epoch: 3 20000/60000 Training loss: 0.163397
Epoch: 3 30000/60000 Training loss: 0.102441
Epoch: 3 40000/60000 Training loss: 0.065567
Epoch: 3 50000/60000 Training loss: 0.047117
Training loss: 0.092029
Test loss: 0.039993; Test accuracy: 9871/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.105145
Epoch: 4 10000/60000 Training loss: 0.088749
Epoch: 4 20000/60000 Training loss: 0.094472
Epoch: 4 30000/60000 Training loss: 0.025336
Epoch: 4 40000/60000 Training loss: 0.030324
Epoch: 4 50000/60000 Training loss: 0.068863
Training loss: 0.076681
Test loss: 0.033424; Test accuracy: 9896/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.023765
Epoch: 5 10000/60000 Training loss: 0.047313
Epoch: 5 20000/60000 Training loss: 0.112311
Epoch: 5 30000/60000 Training loss: 0.032808
Epoch: 5 40000/60000 Training loss: 0.032004
Epoch: 5 50000/60000 Training loss: 0.079673
Training loss: 0.067488
Test loss: 0.031568; Test accuracy: 9904/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.027643
Epoch: 6 10000/60000 Training loss: 0.057087
Epoch: 6 20000/60000 Training loss: 0.131815
Epoch: 6 30000/60000 Training loss: 0.023588
Epoch: 6 40000/60000 Training loss: 0.031557
Epoch: 6 50000/60000 Training loss: 0.069722
Training loss: 0.060620
Test loss: 0.027483; Test accuracy: 9913/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.036039
Epoch: 7 10000/60000 Training loss: 0.049859
Epoch: 7 20000/60000 Training loss: 0.081630
Epoch: 7 30000/60000 Training loss: 0.046435
Epoch: 7 40000/60000 Training loss: 0.032916
Epoch: 7 50000/60000 Training loss: 0.070214
Training loss: 0.052530
Test loss: 0.024285; Test accuracy: 9919/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.096584
Epoch: 8 10000/60000 Training loss: 0.075503
Epoch: 8 20000/60000 Training loss: 0.026624
Epoch: 8 30000/60000 Training loss: 0.056327
Epoch: 8 40000/60000 Training loss: 0.074108
Epoch: 8 50000/60000 Training loss: 0.069030
Training loss: 0.047973
Test loss: 0.027053; Test accuracy: 9913/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.070126
Epoch: 9 10000/60000 Training loss: 0.095597
Epoch: 9 20000/60000 Training loss: 0.030138
Epoch: 9 30000/60000 Training loss: 0.022593
Epoch: 9 40000/60000 Training loss: 0.061915
Epoch: 9 50000/60000 Training loss: 0.008407
Training loss: 0.044361
Test loss: 0.022726; Test accuracy: 9919/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.013619
Epoch: 10 10000/60000 Training loss: 0.032797
Epoch: 10 20000/60000 Training loss: 0.035313
Epoch: 10 30000/60000 Training loss: 0.017000
Epoch: 10 40000/60000 Training loss: 0.013906
Epoch: 10 50000/60000 Training loss: 0.028478
Training loss: 0.041737
Test loss: 0.021566; Test accuracy: 9921/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.005647
Epoch: 11 10000/60000 Training loss: 0.006688
Epoch: 11 20000/60000 Training loss: 0.051744
Epoch: 11 30000/60000 Training loss: 0.004382
Epoch: 11 40000/60000 Training loss: 0.053373
Epoch: 11 50000/60000 Training loss: 0.018653
Training loss: 0.039778
Test loss: 0.021023; Test accuracy: 9929/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.025354
Epoch: 12 10000/60000 Training loss: 0.010397
Epoch: 12 20000/60000 Training loss: 0.025486
Epoch: 12 30000/60000 Training loss: 0.090307
Epoch: 12 40000/60000 Training loss: 0.014652
Epoch: 12 50000/60000 Training loss: 0.030278
Training loss: 0.036226
Test loss: 0.020158; Test accuracy: 9931/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.008967
Epoch: 13 10000/60000 Training loss: 0.129746
Epoch: 13 20000/60000 Training loss: 0.006658
Epoch: 13 30000/60000 Training loss: 0.061515
Epoch: 13 40000/60000 Training loss: 0.022456
Epoch: 13 50000/60000 Training loss: 0.024083
Training loss: 0.033782
Test loss: 0.020554; Test accuracy: 9930/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.021100
Epoch: 14 10000/60000 Training loss: 0.141775
Epoch: 14 20000/60000 Training loss: 0.027930
Epoch: 14 30000/60000 Training loss: 0.011949
Epoch: 14 40000/60000 Training loss: 0.008192
Epoch: 14 50000/60000 Training loss: 0.035046
Training loss: 0.032502
Test loss: 0.019132; Test accuracy: 9932/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.014722
Epoch: 15 10000/60000 Training loss: 0.020154
Epoch: 15 20000/60000 Training loss: 0.023188
Epoch: 15 30000/60000 Training loss: 0.030772
Epoch: 15 40000/60000 Training loss: 0.040893
Epoch: 15 50000/60000 Training loss: 0.014739
Training loss: 0.029306
Test loss: 0.018003; Test accuracy: 9939/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.097647
Epoch: 16 10000/60000 Training loss: 0.006710
Epoch: 16 20000/60000 Training loss: 0.010317
Epoch: 16 30000/60000 Training loss: 0.019020
Epoch: 16 40000/60000 Training loss: 0.003898
Epoch: 16 50000/60000 Training loss: 0.032525
Training loss: 0.027614
Test loss: 0.018156; Test accuracy: 9942/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.006076
Epoch: 17 10000/60000 Training loss: 0.006075
Epoch: 17 20000/60000 Training loss: 0.038234
Epoch: 17 30000/60000 Training loss: 0.025993
Epoch: 17 40000/60000 Training loss: 0.004253
Epoch: 17 50000/60000 Training loss: 0.006888
Training loss: 0.026681
Test loss: 0.016796; Test accuracy: 9947/10000 (99.5%)

Epoch: 18 0/60000 Training loss: 0.003934
Epoch: 18 10000/60000 Training loss: 0.002924
Epoch: 18 20000/60000 Training loss: 0.006762
Epoch: 18 30000/60000 Training loss: 0.010424
Epoch: 18 40000/60000 Training loss: 0.026207
Epoch: 18 50000/60000 Training loss: 0.051944
Training loss: 0.026427
Test loss: 0.017075; Test accuracy: 9947/10000 (99.5%)

Epoch: 19 0/60000 Training loss: 0.017399
Epoch: 19 10000/60000 Training loss: 0.003154
Epoch: 19 20000/60000 Training loss: 0.055217
Epoch: 19 30000/60000 Training loss: 0.002297
Epoch: 19 40000/60000 Training loss: 0.022755
Epoch: 19 50000/60000 Training loss: 0.005245
Training loss: 0.023706
Test loss: 0.018727; Test accuracy: 9933/10000 (99.3%)

[I 2022-11-04 01:55:23,413] Trial 32 finished with value: 0.016795756295323372 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.1826615667590497, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00011196607760987047}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.18261394608971224, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00011209623666824206}
Epoch: 0 0/60000 Training loss: 2.305127
Epoch: 0 10000/60000 Training loss: 0.701182
Epoch: 0 20000/60000 Training loss: 0.403030
Epoch: 0 30000/60000 Training loss: 0.356997
Epoch: 0 40000/60000 Training loss: 0.244217
Epoch: 0 50000/60000 Training loss: 0.350031
Training loss: 0.525740
Test loss: 0.110768; Test accuracy: 9671/10000 (96.7%)

Epoch: 1 0/60000 Training loss: 0.361913
Epoch: 1 10000/60000 Training loss: 0.181406
Epoch: 1 20000/60000 Training loss: 0.170329
Epoch: 1 30000/60000 Training loss: 0.157615
Epoch: 1 40000/60000 Training loss: 0.080524
Epoch: 1 50000/60000 Training loss: 0.071414
Training loss: 0.166890
Test loss: 0.065991; Test accuracy: 9793/10000 (97.9%)

Epoch: 2 0/60000 Training loss: 0.190169
Epoch: 2 10000/60000 Training loss: 0.104206
Epoch: 2 20000/60000 Training loss: 0.219097
Epoch: 2 30000/60000 Training loss: 0.116793
Epoch: 2 40000/60000 Training loss: 0.116849
Epoch: 2 50000/60000 Training loss: 0.208407
Training loss: 0.118726
Test loss: 0.048811; Test accuracy: 9843/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.092965
Epoch: 3 10000/60000 Training loss: 0.123198
Epoch: 3 20000/60000 Training loss: 0.134528
Epoch: 3 30000/60000 Training loss: 0.079545
Epoch: 3 40000/60000 Training loss: 0.100436
Epoch: 3 50000/60000 Training loss: 0.062962
Training loss: 0.092836
Test loss: 0.041824; Test accuracy: 9861/10000 (98.6%)

Epoch: 4 0/60000 Training loss: 0.060645
Epoch: 4 10000/60000 Training loss: 0.263554
Epoch: 4 20000/60000 Training loss: 0.070338
Epoch: 4 30000/60000 Training loss: 0.077142
Epoch: 4 40000/60000 Training loss: 0.097306
Epoch: 4 50000/60000 Training loss: 0.029407
Training loss: 0.079430
Test loss: 0.034101; Test accuracy: 9888/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.068936
Epoch: 5 10000/60000 Training loss: 0.058911
Epoch: 5 20000/60000 Training loss: 0.093255
Epoch: 5 30000/60000 Training loss: 0.042010
Epoch: 5 40000/60000 Training loss: 0.035188
Epoch: 5 50000/60000 Training loss: 0.149360
Training loss: 0.069280
Test loss: 0.029937; Test accuracy: 9903/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.024367
Epoch: 6 10000/60000 Training loss: 0.053196
Epoch: 6 20000/60000 Training loss: 0.128489
Epoch: 6 30000/60000 Training loss: 0.069750
Epoch: 6 40000/60000 Training loss: 0.102023
Epoch: 6 50000/60000 Training loss: 0.085955
Training loss: 0.062293
Test loss: 0.028586; Test accuracy: 9904/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.044028
Epoch: 7 10000/60000 Training loss: 0.143277
Epoch: 7 20000/60000 Training loss: 0.031901
Epoch: 7 30000/60000 Training loss: 0.025904
Epoch: 7 40000/60000 Training loss: 0.074410
Epoch: 7 50000/60000 Training loss: 0.019412
Training loss: 0.056969
Test loss: 0.026025; Test accuracy: 9916/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.018758
Epoch: 8 10000/60000 Training loss: 0.133309
Epoch: 8 20000/60000 Training loss: 0.067378
Epoch: 8 30000/60000 Training loss: 0.055561
Epoch: 8 40000/60000 Training loss: 0.187352
Epoch: 8 50000/60000 Training loss: 0.104863
Training loss: 0.052303
Test loss: 0.026774; Test accuracy: 9906/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.008092
Epoch: 9 10000/60000 Training loss: 0.058785
Epoch: 9 20000/60000 Training loss: 0.029708
Epoch: 9 30000/60000 Training loss: 0.011811
Epoch: 9 40000/60000 Training loss: 0.058999
Epoch: 9 50000/60000 Training loss: 0.042307
Training loss: 0.047886
Test loss: 0.024269; Test accuracy: 9919/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.051009
Epoch: 10 10000/60000 Training loss: 0.008407
Epoch: 10 20000/60000 Training loss: 0.033341
Epoch: 10 30000/60000 Training loss: 0.038407
Epoch: 10 40000/60000 Training loss: 0.012786
Epoch: 10 50000/60000 Training loss: 0.093657
Training loss: 0.044345
Test loss: 0.020484; Test accuracy: 9933/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.029598
Epoch: 11 10000/60000 Training loss: 0.007145
Epoch: 11 20000/60000 Training loss: 0.030773
Epoch: 11 30000/60000 Training loss: 0.058344
Epoch: 11 40000/60000 Training loss: 0.032317
Epoch: 11 50000/60000 Training loss: 0.024309
Training loss: 0.041315
Test loss: 0.022568; Test accuracy: 9919/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.081421
Epoch: 12 10000/60000 Training loss: 0.014363
Epoch: 12 20000/60000 Training loss: 0.027282
Epoch: 12 30000/60000 Training loss: 0.046774
Epoch: 12 40000/60000 Training loss: 0.017399
Epoch: 12 50000/60000 Training loss: 0.044167
Training loss: 0.037435
Test loss: 0.021324; Test accuracy: 9937/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.032675
Epoch: 13 10000/60000 Training loss: 0.095097
Epoch: 13 20000/60000 Training loss: 0.026856
Epoch: 13 30000/60000 Training loss: 0.028410
Epoch: 13 40000/60000 Training loss: 0.011435
Epoch: 13 50000/60000 Training loss: 0.027641
Training loss: 0.034571
Test loss: 0.020520; Test accuracy: 9934/10000 (99.3%)

[I 2022-11-04 01:58:39,238] Trial 33 finished with value: 0.02048429287970066 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.18261394608971224, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00011209623666824206}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 48, 'conv2_drop': 0.15984958077404585, 'fc1_neurons': 90, 'optimizer': 'Adam', 'learning_rate': 8.344650720208465e-05}
Epoch: 0 0/60000 Training loss: 2.329665
Epoch: 0 10000/60000 Training loss: 0.994767
Epoch: 0 20000/60000 Training loss: 0.605257
Epoch: 0 30000/60000 Training loss: 0.542473
Epoch: 0 40000/60000 Training loss: 0.297170
Epoch: 0 50000/60000 Training loss: 0.390563
Training loss: 0.661925
Test loss: 0.150907; Test accuracy: 9572/10000 (95.7%)

Epoch: 1 0/60000 Training loss: 0.316393
Epoch: 1 10000/60000 Training loss: 0.232060
Epoch: 1 20000/60000 Training loss: 0.233889
Epoch: 1 30000/60000 Training loss: 0.133755
Epoch: 1 40000/60000 Training loss: 0.242630
Epoch: 1 50000/60000 Training loss: 0.104353
Training loss: 0.226740
Test loss: 0.089483; Test accuracy: 9723/10000 (97.2%)

Epoch: 2 0/60000 Training loss: 0.173245
Epoch: 2 10000/60000 Training loss: 0.139834
Epoch: 2 20000/60000 Training loss: 0.140498
Epoch: 2 30000/60000 Training loss: 0.119285
Epoch: 2 40000/60000 Training loss: 0.178102
Epoch: 2 50000/60000 Training loss: 0.141206
Training loss: 0.158309
Test loss: 0.066336; Test accuracy: 9791/10000 (97.9%)

Epoch: 3 0/60000 Training loss: 0.243374
Epoch: 3 10000/60000 Training loss: 0.094621
Epoch: 3 20000/60000 Training loss: 0.116128
Epoch: 3 30000/60000 Training loss: 0.096311
Epoch: 3 40000/60000 Training loss: 0.100613
Epoch: 3 50000/60000 Training loss: 0.118699
Training loss: 0.124282
Test loss: 0.051713; Test accuracy: 9832/10000 (98.3%)

Epoch: 4 0/60000 Training loss: 0.120344
Epoch: 4 10000/60000 Training loss: 0.049317
Epoch: 4 20000/60000 Training loss: 0.109819
Epoch: 4 30000/60000 Training loss: 0.072330
Epoch: 4 40000/60000 Training loss: 0.060298
Epoch: 4 50000/60000 Training loss: 0.145281
Training loss: 0.106362
Test loss: 0.043855; Test accuracy: 9863/10000 (98.6%)

Epoch: 5 0/60000 Training loss: 0.125165
Epoch: 5 10000/60000 Training loss: 0.057901
Epoch: 5 20000/60000 Training loss: 0.055703
Epoch: 5 30000/60000 Training loss: 0.130735
Epoch: 5 40000/60000 Training loss: 0.111757
Epoch: 5 50000/60000 Training loss: 0.104754
Training loss: 0.094792
Test loss: 0.039278; Test accuracy: 9871/10000 (98.7%)

Epoch: 6 0/60000 Training loss: 0.037728
Epoch: 6 10000/60000 Training loss: 0.038792
Epoch: 6 20000/60000 Training loss: 0.064009
Epoch: 6 30000/60000 Training loss: 0.104166
Epoch: 6 40000/60000 Training loss: 0.095291
Epoch: 6 50000/60000 Training loss: 0.057838
Training loss: 0.081713
Test loss: 0.037008; Test accuracy: 9885/10000 (98.8%)

Epoch: 7 0/60000 Training loss: 0.063287
Epoch: 7 10000/60000 Training loss: 0.025020
Epoch: 7 20000/60000 Training loss: 0.045516
Epoch: 7 30000/60000 Training loss: 0.078487
Epoch: 7 40000/60000 Training loss: 0.087436
Epoch: 7 50000/60000 Training loss: 0.026711
Training loss: 0.076266
Test loss: 0.033064; Test accuracy: 9890/10000 (98.9%)

Epoch: 8 0/60000 Training loss: 0.047019
Epoch: 8 10000/60000 Training loss: 0.122063
Epoch: 8 20000/60000 Training loss: 0.019298
Epoch: 8 30000/60000 Training loss: 0.025943
Epoch: 8 40000/60000 Training loss: 0.025159
Epoch: 8 50000/60000 Training loss: 0.143439
Training loss: 0.068698
Test loss: 0.030095; Test accuracy: 9904/10000 (99.0%)

Epoch: 9 0/60000 Training loss: 0.108957
Epoch: 9 10000/60000 Training loss: 0.033743
Epoch: 9 20000/60000 Training loss: 0.037758
Epoch: 9 30000/60000 Training loss: 0.053552
Epoch: 9 40000/60000 Training loss: 0.079248
Epoch: 9 50000/60000 Training loss: 0.034356
Training loss: 0.063656
Test loss: 0.030095; Test accuracy: 9905/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.065673
Epoch: 10 10000/60000 Training loss: 0.053514
Epoch: 10 20000/60000 Training loss: 0.076695
Epoch: 10 30000/60000 Training loss: 0.068576
Epoch: 10 40000/60000 Training loss: 0.099734
Epoch: 10 50000/60000 Training loss: 0.128443
Training loss: 0.060598
Test loss: 0.028508; Test accuracy: 9906/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.076058
Epoch: 11 10000/60000 Training loss: 0.018484
Epoch: 11 20000/60000 Training loss: 0.157438
Epoch: 11 30000/60000 Training loss: 0.032815
Epoch: 11 40000/60000 Training loss: 0.152623
Epoch: 11 50000/60000 Training loss: 0.158439
Training loss: 0.055679
Test loss: 0.026651; Test accuracy: 9909/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.035324
Epoch: 12 10000/60000 Training loss: 0.044033
Epoch: 12 20000/60000 Training loss: 0.033540
Epoch: 12 30000/60000 Training loss: 0.012956
Epoch: 12 40000/60000 Training loss: 0.009804
Epoch: 12 50000/60000 Training loss: 0.016656
Training loss: 0.051639
Test loss: 0.024573; Test accuracy: 9912/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.070016
Epoch: 13 10000/60000 Training loss: 0.073238
Epoch: 13 20000/60000 Training loss: 0.014634
Epoch: 13 30000/60000 Training loss: 0.013225
Epoch: 13 40000/60000 Training loss: 0.038332
Epoch: 13 50000/60000 Training loss: 0.086268
Training loss: 0.049034
Test loss: 0.025063; Test accuracy: 9913/10000 (99.1%)

Epoch: 14 0/60000 Training loss: 0.089184
Epoch: 14 10000/60000 Training loss: 0.127992
Epoch: 14 20000/60000 Training loss: 0.062112
Epoch: 14 30000/60000 Training loss: 0.008462
Epoch: 14 40000/60000 Training loss: 0.010834
Epoch: 14 50000/60000 Training loss: 0.009626
Training loss: 0.046719
Test loss: 0.024233; Test accuracy: 9910/10000 (99.1%)

Epoch: 15 0/60000 Training loss: 0.060528
Epoch: 15 10000/60000 Training loss: 0.026514
Epoch: 15 20000/60000 Training loss: 0.028899
Epoch: 15 30000/60000 Training loss: 0.089476
Epoch: 15 40000/60000 Training loss: 0.065887
Epoch: 15 50000/60000 Training loss: 0.066501
Training loss: 0.045540
Test loss: 0.023714; Test accuracy: 9920/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.049137
Epoch: 16 10000/60000 Training loss: 0.039144
Epoch: 16 20000/60000 Training loss: 0.028160
Epoch: 16 30000/60000 Training loss: 0.012980
Epoch: 16 40000/60000 Training loss: 0.020666
Epoch: 16 50000/60000 Training loss: 0.026293
Training loss: 0.042424
Test loss: 0.022313; Test accuracy: 9927/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.048389
Epoch: 17 10000/60000 Training loss: 0.049501
Epoch: 17 20000/60000 Training loss: 0.063488
Epoch: 17 30000/60000 Training loss: 0.029051
Epoch: 17 40000/60000 Training loss: 0.055254
Epoch: 17 50000/60000 Training loss: 0.046419
Training loss: 0.040793
Test loss: 0.020970; Test accuracy: 9927/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.032363
Epoch: 18 10000/60000 Training loss: 0.096310
Epoch: 18 20000/60000 Training loss: 0.037069
Epoch: 18 30000/60000 Training loss: 0.051542
Epoch: 18 40000/60000 Training loss: 0.016057
Epoch: 18 50000/60000 Training loss: 0.017489
Training loss: 0.037977
Test loss: 0.021500; Test accuracy: 9924/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.036145
Epoch: 19 10000/60000 Training loss: 0.039353
Epoch: 19 20000/60000 Training loss: 0.013142
Epoch: 19 30000/60000 Training loss: 0.028860
Epoch: 19 40000/60000 Training loss: 0.027795
Epoch: 19 50000/60000 Training loss: 0.127530
Training loss: 0.038777
Test loss: 0.021565; Test accuracy: 9928/10000 (99.3%)

[I 2022-11-04 02:03:19,472] Trial 34 finished with value: 0.02096981182694435 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 48, 'conv2_drop': 0.15984958077404585, 'fc1_neurons': 90, 'optimizer': 'Adam', 'learning_rate': 8.344650720208465e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.18269158372388591, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 0.00024783992490940636}
Epoch: 0 0/60000 Training loss: 2.314758
Epoch: 0 10000/60000 Training loss: 0.508966
Epoch: 0 20000/60000 Training loss: 0.370307
Epoch: 0 30000/60000 Training loss: 0.262984
Epoch: 0 40000/60000 Training loss: 0.170895
Epoch: 0 50000/60000 Training loss: 0.174680
Training loss: 0.406173
Test loss: 0.073802; Test accuracy: 9780/10000 (97.8%)

Epoch: 1 0/60000 Training loss: 0.176864
Epoch: 1 10000/60000 Training loss: 0.138803
Epoch: 1 20000/60000 Training loss: 0.089240
Epoch: 1 30000/60000 Training loss: 0.245302
Epoch: 1 40000/60000 Training loss: 0.101079
Epoch: 1 50000/60000 Training loss: 0.214006
Training loss: 0.129492
Test loss: 0.049879; Test accuracy: 9834/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.056570
Epoch: 2 10000/60000 Training loss: 0.141740
Epoch: 2 20000/60000 Training loss: 0.050497
Epoch: 2 30000/60000 Training loss: 0.156517
Epoch: 2 40000/60000 Training loss: 0.030817
Epoch: 2 50000/60000 Training loss: 0.074414
Training loss: 0.091400
Test loss: 0.035318; Test accuracy: 9890/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.038923
Epoch: 3 10000/60000 Training loss: 0.083524
Epoch: 3 20000/60000 Training loss: 0.237617
Epoch: 3 30000/60000 Training loss: 0.067531
Epoch: 3 40000/60000 Training loss: 0.032766
Epoch: 3 50000/60000 Training loss: 0.049790
Training loss: 0.073700
Test loss: 0.030880; Test accuracy: 9904/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.129103
Epoch: 4 10000/60000 Training loss: 0.049315
Epoch: 4 20000/60000 Training loss: 0.043515
Epoch: 4 30000/60000 Training loss: 0.015624
Epoch: 4 40000/60000 Training loss: 0.021459
Epoch: 4 50000/60000 Training loss: 0.039552
Training loss: 0.063770
Test loss: 0.029453; Test accuracy: 9897/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.216623
Epoch: 5 10000/60000 Training loss: 0.075643
Epoch: 5 20000/60000 Training loss: 0.035509
Epoch: 5 30000/60000 Training loss: 0.031578
Epoch: 5 40000/60000 Training loss: 0.079371
Epoch: 5 50000/60000 Training loss: 0.083671
Training loss: 0.056911
Test loss: 0.026164; Test accuracy: 9909/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.038936
Epoch: 6 10000/60000 Training loss: 0.071624
Epoch: 6 20000/60000 Training loss: 0.078662
Epoch: 6 30000/60000 Training loss: 0.069091
Epoch: 6 40000/60000 Training loss: 0.006066
Epoch: 6 50000/60000 Training loss: 0.026244
Training loss: 0.047970
Test loss: 0.023569; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.121711
Epoch: 7 10000/60000 Training loss: 0.046558
Epoch: 7 20000/60000 Training loss: 0.103106
Epoch: 7 30000/60000 Training loss: 0.011581
Epoch: 7 40000/60000 Training loss: 0.079365
Epoch: 7 50000/60000 Training loss: 0.155515
Training loss: 0.044699
Test loss: 0.021608; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.035626
Epoch: 8 10000/60000 Training loss: 0.036375
Epoch: 8 20000/60000 Training loss: 0.007566
Epoch: 8 30000/60000 Training loss: 0.019481
Epoch: 8 40000/60000 Training loss: 0.100366
Epoch: 8 50000/60000 Training loss: 0.029779
Training loss: 0.040666
Test loss: 0.024302; Test accuracy: 9923/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.012470
Epoch: 9 10000/60000 Training loss: 0.036268
Epoch: 9 20000/60000 Training loss: 0.076849
Epoch: 9 30000/60000 Training loss: 0.018633
Epoch: 9 40000/60000 Training loss: 0.138918
Epoch: 9 50000/60000 Training loss: 0.025229
Training loss: 0.036953
Test loss: 0.021002; Test accuracy: 9928/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.002339
Epoch: 10 10000/60000 Training loss: 0.065070
Epoch: 10 20000/60000 Training loss: 0.039351
Epoch: 10 30000/60000 Training loss: 0.016447
Epoch: 10 40000/60000 Training loss: 0.109434
Epoch: 10 50000/60000 Training loss: 0.031819
Training loss: 0.036561
Test loss: 0.020166; Test accuracy: 9933/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.054166
Epoch: 11 10000/60000 Training loss: 0.018070
Epoch: 11 20000/60000 Training loss: 0.049162
Epoch: 11 30000/60000 Training loss: 0.025918
Epoch: 11 40000/60000 Training loss: 0.007382
Epoch: 11 50000/60000 Training loss: 0.015535
Training loss: 0.033421
Test loss: 0.019247; Test accuracy: 9940/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.007693
Epoch: 12 10000/60000 Training loss: 0.004595
Epoch: 12 20000/60000 Training loss: 0.010478
Epoch: 12 30000/60000 Training loss: 0.008080
Epoch: 12 40000/60000 Training loss: 0.019204
Epoch: 12 50000/60000 Training loss: 0.030910
Training loss: 0.030474
Test loss: 0.019673; Test accuracy: 9936/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.006251
Epoch: 13 10000/60000 Training loss: 0.009867
Epoch: 13 20000/60000 Training loss: 0.156088
Epoch: 13 30000/60000 Training loss: 0.049783
Epoch: 13 40000/60000 Training loss: 0.054700
Epoch: 13 50000/60000 Training loss: 0.034618
Training loss: 0.029783
Test loss: 0.018526; Test accuracy: 9941/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.044714
Epoch: 14 10000/60000 Training loss: 0.031454
Epoch: 14 20000/60000 Training loss: 0.011024
Epoch: 14 30000/60000 Training loss: 0.007118
Epoch: 14 40000/60000 Training loss: 0.028069
Epoch: 14 50000/60000 Training loss: 0.046798
Training loss: 0.025974
Test loss: 0.021558; Test accuracy: 9937/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.013585
Epoch: 15 10000/60000 Training loss: 0.030580
Epoch: 15 20000/60000 Training loss: 0.014123
Epoch: 15 30000/60000 Training loss: 0.016985
Epoch: 15 40000/60000 Training loss: 0.009915
Epoch: 15 50000/60000 Training loss: 0.017704
Training loss: 0.025179
Test loss: 0.018733; Test accuracy: 9941/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.029602
Epoch: 16 10000/60000 Training loss: 0.047233
Epoch: 16 20000/60000 Training loss: 0.012963
Epoch: 16 30000/60000 Training loss: 0.005667
Epoch: 16 40000/60000 Training loss: 0.025547
Epoch: 16 50000/60000 Training loss: 0.000482
Training loss: 0.024599
Test loss: 0.019011; Test accuracy: 9937/10000 (99.4%)

[I 2022-11-04 02:07:17,681] Trial 35 finished with value: 0.018525563180446625 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.18269158372388591, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 0.00024783992490940636}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 32, 'conv2_drop': 0.19915397536870513, 'fc1_neurons': 120, 'optimizer': 'SGD', 'learning_rate': 3.528338072625348e-05}
Epoch: 0 0/60000 Training loss: 2.314838
Epoch: 0 10000/60000 Training loss: 2.300951
Epoch: 0 20000/60000 Training loss: 2.285214
Epoch: 0 30000/60000 Training loss: 2.288107
Epoch: 0 40000/60000 Training loss: 2.301268
Epoch: 0 50000/60000 Training loss: 2.292860
Training loss: 2.300868
Test loss: 2.287256; Test accuracy: 1005/10000 (10.1%)

Epoch: 1 0/60000 Training loss: 2.314013
Epoch: 1 10000/60000 Training loss: 2.287540
Epoch: 1 20000/60000 Training loss: 2.293684
Epoch: 1 30000/60000 Training loss: 2.283406
Epoch: 1 40000/60000 Training loss: 2.303888
Epoch: 1 50000/60000 Training loss: 2.300331
Training loss: 2.289818
Test loss: 2.275259; Test accuracy: 1087/10000 (10.9%)

Epoch: 2 0/60000 Training loss: 2.282585
Epoch: 2 10000/60000 Training loss: 2.282769
Epoch: 2 20000/60000 Training loss: 2.285531
Epoch: 2 30000/60000 Training loss: 2.280037
Epoch: 2 40000/60000 Training loss: 2.280256
Epoch: 2 50000/60000 Training loss: 2.296416
Training loss: 2.279842
Test loss: 2.263783; Test accuracy: 1256/10000 (12.6%)

Epoch: 3 0/60000 Training loss: 2.296441
Epoch: 3 10000/60000 Training loss: 2.278183
Epoch: 3 20000/60000 Training loss: 2.278106
Epoch: 3 30000/60000 Training loss: 2.287325
Epoch: 3 40000/60000 Training loss: 2.230947
Epoch: 3 50000/60000 Training loss: 2.262007
Training loss: 2.270122
Test loss: 2.252807; Test accuracy: 1556/10000 (15.6%)

Epoch: 4 0/60000 Training loss: 2.282408
Epoch: 4 10000/60000 Training loss: 2.255259
Epoch: 4 20000/60000 Training loss: 2.265100
Epoch: 4 30000/60000 Training loss: 2.243532
Epoch: 4 40000/60000 Training loss: 2.278816
Epoch: 4 50000/60000 Training loss: 2.256477
Training loss: 2.260051
Test loss: 2.241822; Test accuracy: 1822/10000 (18.2%)

Epoch: 5 0/60000 Training loss: 2.247070
Epoch: 5 10000/60000 Training loss: 2.238381
Epoch: 5 20000/60000 Training loss: 2.267738
Epoch: 5 30000/60000 Training loss: 2.232903
Epoch: 5 40000/60000 Training loss: 2.247542
Epoch: 5 50000/60000 Training loss: 2.226955
Training loss: 2.251996
Test loss: 2.230680; Test accuracy: 2191/10000 (21.9%)

Epoch: 6 0/60000 Training loss: 2.253193
Epoch: 6 10000/60000 Training loss: 2.245499
Epoch: 6 20000/60000 Training loss: 2.252505
Epoch: 6 30000/60000 Training loss: 2.224146
Epoch: 6 40000/60000 Training loss: 2.246102
Epoch: 6 50000/60000 Training loss: 2.242149
Training loss: 2.241281
Test loss: 2.219062; Test accuracy: 2580/10000 (25.8%)

Epoch: 7 0/60000 Training loss: 2.235060
Epoch: 7 10000/60000 Training loss: 2.246353
Epoch: 7 20000/60000 Training loss: 2.221510
Epoch: 7 30000/60000 Training loss: 2.212782
Epoch: 7 40000/60000 Training loss: 2.243173
Epoch: 7 50000/60000 Training loss: 2.236394
Training loss: 2.231835
Test loss: 2.206988; Test accuracy: 2982/10000 (29.8%)

Epoch: 8 0/60000 Training loss: 2.231948
Epoch: 8 10000/60000 Training loss: 2.210385
Epoch: 8 20000/60000 Training loss: 2.251769
Epoch: 8 30000/60000 Training loss: 2.223560
Epoch: 8 40000/60000 Training loss: 2.224947
Epoch: 8 50000/60000 Training loss: 2.225225
Training loss: 2.220870
Test loss: 2.194290; Test accuracy: 3449/10000 (34.5%)

Epoch: 9 0/60000 Training loss: 2.210016
Epoch: 9 10000/60000 Training loss: 2.202960
Epoch: 9 20000/60000 Training loss: 2.207158
Epoch: 9 30000/60000 Training loss: 2.226879
Epoch: 9 40000/60000 Training loss: 2.227009
Epoch: 9 50000/60000 Training loss: 2.218641
Training loss: 2.210321
Test loss: 2.180829; Test accuracy: 4048/10000 (40.5%)

Epoch: 10 0/60000 Training loss: 2.181496
Epoch: 10 10000/60000 Training loss: 2.197667
Epoch: 10 20000/60000 Training loss: 2.194413
Epoch: 10 30000/60000 Training loss: 2.191307
Epoch: 10 40000/60000 Training loss: 2.175933
Epoch: 10 50000/60000 Training loss: 2.197346
Training loss: 2.199114
Test loss: 2.166575; Test accuracy: 4680/10000 (46.8%)

Epoch: 11 0/60000 Training loss: 2.169649
Epoch: 11 10000/60000 Training loss: 2.196357
Epoch: 11 20000/60000 Training loss: 2.177848
Epoch: 11 30000/60000 Training loss: 2.196365
Epoch: 11 40000/60000 Training loss: 2.177926
Epoch: 11 50000/60000 Training loss: 2.173420
Training loss: 2.186414
Test loss: 2.151458; Test accuracy: 5310/10000 (53.1%)

Epoch: 12 0/60000 Training loss: 2.198079
Epoch: 12 10000/60000 Training loss: 2.157967
Epoch: 12 20000/60000 Training loss: 2.184979
Epoch: 12 30000/60000 Training loss: 2.193485
Epoch: 12 40000/60000 Training loss: 2.167443
Epoch: 12 50000/60000 Training loss: 2.160921
Training loss: 2.172423
Test loss: 2.135302; Test accuracy: 5879/10000 (58.8%)

Epoch: 13 0/60000 Training loss: 2.190201
Epoch: 13 10000/60000 Training loss: 2.166206
Epoch: 13 20000/60000 Training loss: 2.173352
Epoch: 13 30000/60000 Training loss: 2.149736
Epoch: 13 40000/60000 Training loss: 2.170479
Epoch: 13 50000/60000 Training loss: 2.144142
Training loss: 2.159098
Test loss: 2.118098; Test accuracy: 6379/10000 (63.8%)

Epoch: 14 0/60000 Training loss: 2.192763
Epoch: 14 10000/60000 Training loss: 2.141628
Epoch: 14 20000/60000 Training loss: 2.142850
Epoch: 14 30000/60000 Training loss: 2.133775
Epoch: 14 40000/60000 Training loss: 2.092693
Epoch: 14 50000/60000 Training loss: 2.148906
Training loss: 2.144702
Test loss: 2.099837; Test accuracy: 6723/10000 (67.2%)

Epoch: 15 0/60000 Training loss: 2.162772
Epoch: 15 10000/60000 Training loss: 2.126755
Epoch: 15 20000/60000 Training loss: 2.103933
Epoch: 15 30000/60000 Training loss: 2.148816
Epoch: 15 40000/60000 Training loss: 2.145159
Epoch: 15 50000/60000 Training loss: 2.126284
Training loss: 2.129970
Test loss: 2.080440; Test accuracy: 6955/10000 (69.5%)

Epoch: 16 0/60000 Training loss: 2.129276
Epoch: 16 10000/60000 Training loss: 2.109366
Epoch: 16 20000/60000 Training loss: 2.139505
Epoch: 16 30000/60000 Training loss: 2.126749
Epoch: 16 40000/60000 Training loss: 2.147829
Epoch: 16 50000/60000 Training loss: 2.095255
Training loss: 2.114268
Test loss: 2.059771; Test accuracy: 7166/10000 (71.7%)

Epoch: 17 0/60000 Training loss: 2.112070
Epoch: 17 10000/60000 Training loss: 2.109680
Epoch: 17 20000/60000 Training loss: 2.094297
Epoch: 17 30000/60000 Training loss: 2.105393
Epoch: 17 40000/60000 Training loss: 2.100738
Epoch: 17 50000/60000 Training loss: 2.069402
Training loss: 2.095974
Test loss: 2.037650; Test accuracy: 7330/10000 (73.3%)

Epoch: 18 0/60000 Training loss: 2.051306
Epoch: 18 10000/60000 Training loss: 2.057752
Epoch: 18 20000/60000 Training loss: 2.096763
Epoch: 18 30000/60000 Training loss: 2.067603
Epoch: 18 40000/60000 Training loss: 2.047677
Epoch: 18 50000/60000 Training loss: 2.062373
Training loss: 2.075933
Test loss: 2.013918; Test accuracy: 7449/10000 (74.5%)

Epoch: 19 0/60000 Training loss: 2.084039
Epoch: 19 10000/60000 Training loss: 2.046713
Epoch: 19 20000/60000 Training loss: 2.056207
Epoch: 19 30000/60000 Training loss: 2.067532
Epoch: 19 40000/60000 Training loss: 2.042634
Epoch: 19 50000/60000 Training loss: 2.086415
Training loss: 2.057026
Test loss: 1.988769; Test accuracy: 7519/10000 (75.2%)

[I 2022-11-04 02:11:55,749] Trial 36 finished with value: 1.988769292831421 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 32, 'conv2_drop': 0.19915397536870513, 'fc1_neurons': 120, 'optimizer': 'SGD', 'learning_rate': 3.528338072625348e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 16, 'num_conv2_channels': 48, 'conv2_drop': 0.14486668366600997, 'fc1_neurons': 40, 'optimizer': 'Adam', 'learning_rate': 0.00037411949910623124}
Epoch: 0 0/60000 Training loss: 2.301882
Epoch: 0 10000/60000 Training loss: 1.103826
Epoch: 0 20000/60000 Training loss: 0.671786
Epoch: 0 30000/60000 Training loss: 0.469094
Epoch: 0 40000/60000 Training loss: 0.312650
Epoch: 0 50000/60000 Training loss: 0.341738
Training loss: 0.702087
Test loss: 0.113112; Test accuracy: 9662/10000 (96.6%)

Epoch: 1 0/60000 Training loss: 0.410601
Epoch: 1 10000/60000 Training loss: 0.242309
Epoch: 1 20000/60000 Training loss: 0.410835
Epoch: 1 30000/60000 Training loss: 0.360856
Epoch: 1 40000/60000 Training loss: 0.181401
Epoch: 1 50000/60000 Training loss: 0.303876
Training loss: 0.275108
Test loss: 0.067687; Test accuracy: 9794/10000 (97.9%)

Epoch: 2 0/60000 Training loss: 0.325377
Epoch: 2 10000/60000 Training loss: 0.316685
Epoch: 2 20000/60000 Training loss: 0.335443
Epoch: 2 30000/60000 Training loss: 0.375783
Epoch: 2 40000/60000 Training loss: 0.253430
Epoch: 2 50000/60000 Training loss: 0.184093
Training loss: 0.213013
Test loss: 0.055248; Test accuracy: 9824/10000 (98.2%)

Epoch: 3 0/60000 Training loss: 0.247194
Epoch: 3 10000/60000 Training loss: 0.144559
Epoch: 3 20000/60000 Training loss: 0.195371
Epoch: 3 30000/60000 Training loss: 0.201170
Epoch: 3 40000/60000 Training loss: 0.162163
Epoch: 3 50000/60000 Training loss: 0.209332
Training loss: 0.176856
Test loss: 0.046925; Test accuracy: 9846/10000 (98.5%)

Epoch: 4 0/60000 Training loss: 0.178373
Epoch: 4 10000/60000 Training loss: 0.326591
Epoch: 4 20000/60000 Training loss: 0.124256
Epoch: 4 30000/60000 Training loss: 0.063818
Epoch: 4 40000/60000 Training loss: 0.171708
Epoch: 4 50000/60000 Training loss: 0.129802
Training loss: 0.153077
Test loss: 0.041385; Test accuracy: 9866/10000 (98.7%)

Epoch: 5 0/60000 Training loss: 0.032221
Epoch: 5 10000/60000 Training loss: 0.090158
Epoch: 5 20000/60000 Training loss: 0.123958
Epoch: 5 30000/60000 Training loss: 0.109033
Epoch: 5 40000/60000 Training loss: 0.199222
Epoch: 5 50000/60000 Training loss: 0.233867
Training loss: 0.136407
Test loss: 0.036701; Test accuracy: 9888/10000 (98.9%)

Epoch: 6 0/60000 Training loss: 0.060124
Epoch: 6 10000/60000 Training loss: 0.127843
Epoch: 6 20000/60000 Training loss: 0.120834
Epoch: 6 30000/60000 Training loss: 0.087435
Epoch: 6 40000/60000 Training loss: 0.141904
Epoch: 6 50000/60000 Training loss: 0.103815
Training loss: 0.128534
Test loss: 0.035804; Test accuracy: 9880/10000 (98.8%)

Epoch: 7 0/60000 Training loss: 0.067003
Epoch: 7 10000/60000 Training loss: 0.090679
Epoch: 7 20000/60000 Training loss: 0.169523
Epoch: 7 30000/60000 Training loss: 0.123648
Epoch: 7 40000/60000 Training loss: 0.150168
Epoch: 7 50000/60000 Training loss: 0.073000
Training loss: 0.119970
Test loss: 0.033359; Test accuracy: 9894/10000 (98.9%)

Epoch: 8 0/60000 Training loss: 0.114406
Epoch: 8 10000/60000 Training loss: 0.072078
Epoch: 8 20000/60000 Training loss: 0.124486
Epoch: 8 30000/60000 Training loss: 0.062094
Epoch: 8 40000/60000 Training loss: 0.051503
Epoch: 8 50000/60000 Training loss: 0.118775
Training loss: 0.106113
Test loss: 0.034814; Test accuracy: 9894/10000 (98.9%)

Epoch: 9 0/60000 Training loss: 0.092117
Epoch: 9 10000/60000 Training loss: 0.149344
Epoch: 9 20000/60000 Training loss: 0.108772
Epoch: 9 30000/60000 Training loss: 0.071435
Epoch: 9 40000/60000 Training loss: 0.065712
Epoch: 9 50000/60000 Training loss: 0.082387
Training loss: 0.104592
Test loss: 0.033102; Test accuracy: 9900/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.101225
Epoch: 10 10000/60000 Training loss: 0.057942
Epoch: 10 20000/60000 Training loss: 0.085186
Epoch: 10 30000/60000 Training loss: 0.060164
Epoch: 10 40000/60000 Training loss: 0.110446
Epoch: 10 50000/60000 Training loss: 0.054001
Training loss: 0.099987
Test loss: 0.029063; Test accuracy: 9906/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.042581
Epoch: 11 10000/60000 Training loss: 0.071331
Epoch: 11 20000/60000 Training loss: 0.085887
Epoch: 11 30000/60000 Training loss: 0.074478
Epoch: 11 40000/60000 Training loss: 0.152414
Epoch: 11 50000/60000 Training loss: 0.061985
Training loss: 0.093769
Test loss: 0.028797; Test accuracy: 9907/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.109137
Epoch: 12 10000/60000 Training loss: 0.217764
Epoch: 12 20000/60000 Training loss: 0.146468
Epoch: 12 30000/60000 Training loss: 0.058157
Epoch: 12 40000/60000 Training loss: 0.105421
Epoch: 12 50000/60000 Training loss: 0.073057
Training loss: 0.088451
Test loss: 0.028777; Test accuracy: 9918/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.045051
Epoch: 13 10000/60000 Training loss: 0.079446
Epoch: 13 20000/60000 Training loss: 0.067064
Epoch: 13 30000/60000 Training loss: 0.221866
Epoch: 13 40000/60000 Training loss: 0.158653
Epoch: 13 50000/60000 Training loss: 0.094540
Training loss: 0.088241
Test loss: 0.028317; Test accuracy: 9913/10000 (99.1%)

Epoch: 14 0/60000 Training loss: 0.170083
Epoch: 14 10000/60000 Training loss: 0.102025
Epoch: 14 20000/60000 Training loss: 0.068648
Epoch: 14 30000/60000 Training loss: 0.062329
Epoch: 14 40000/60000 Training loss: 0.227209
Epoch: 14 50000/60000 Training loss: 0.132315
Training loss: 0.082864
Test loss: 0.027774; Test accuracy: 9912/10000 (99.1%)

Epoch: 15 0/60000 Training loss: 0.047798
Epoch: 15 10000/60000 Training loss: 0.090633
Epoch: 15 20000/60000 Training loss: 0.062965
Epoch: 15 30000/60000 Training loss: 0.064949
Epoch: 15 40000/60000 Training loss: 0.097633
Epoch: 15 50000/60000 Training loss: 0.084830
Training loss: 0.078774
Test loss: 0.026473; Test accuracy: 9916/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.054604
Epoch: 16 10000/60000 Training loss: 0.034756
Epoch: 16 20000/60000 Training loss: 0.107799
Epoch: 16 30000/60000 Training loss: 0.115029
Epoch: 16 40000/60000 Training loss: 0.133703
Epoch: 16 50000/60000 Training loss: 0.049960
Training loss: 0.076494
Test loss: 0.025561; Test accuracy: 9925/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.085967
Epoch: 17 10000/60000 Training loss: 0.072170
Epoch: 17 20000/60000 Training loss: 0.035298
Epoch: 17 30000/60000 Training loss: 0.054631
Epoch: 17 40000/60000 Training loss: 0.057440
Epoch: 17 50000/60000 Training loss: 0.052790
Training loss: 0.075397
Test loss: 0.026463; Test accuracy: 9921/10000 (99.2%)

Epoch: 18 0/60000 Training loss: 0.032696
Epoch: 18 10000/60000 Training loss: 0.023531
Epoch: 18 20000/60000 Training loss: 0.181243
Epoch: 18 30000/60000 Training loss: 0.044507
Epoch: 18 40000/60000 Training loss: 0.087479
Epoch: 18 50000/60000 Training loss: 0.085090
Training loss: 0.072538
Test loss: 0.025877; Test accuracy: 9916/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.057553
Epoch: 19 10000/60000 Training loss: 0.051532
Epoch: 19 20000/60000 Training loss: 0.274128
Epoch: 19 30000/60000 Training loss: 0.081525
Epoch: 19 40000/60000 Training loss: 0.048633
Epoch: 19 50000/60000 Training loss: 0.044975
Training loss: 0.067979
Test loss: 0.024869; Test accuracy: 9928/10000 (99.3%)

[I 2022-11-04 02:16:33,400] Trial 37 finished with value: 0.024869203567504883 and parameters: {'num_conv1_channels': 16, 'num_conv2_channels': 48, 'conv2_drop': 0.14486668366600997, 'fc1_neurons': 40, 'optimizer': 'Adam', 'learning_rate': 0.00037411949910623124}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.11939261250619634, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.0001462791554344665}
Epoch: 0 0/60000 Training loss: 2.315675
Epoch: 0 10000/60000 Training loss: 0.457503
Epoch: 0 20000/60000 Training loss: 0.272990
Epoch: 0 30000/60000 Training loss: 0.202713
Epoch: 0 40000/60000 Training loss: 0.180064
Epoch: 0 50000/60000 Training loss: 0.121658
Training loss: 0.341172
Test loss: 0.073294; Test accuracy: 9770/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.177848
Epoch: 1 10000/60000 Training loss: 0.056674
Epoch: 1 20000/60000 Training loss: 0.113660
Epoch: 1 30000/60000 Training loss: 0.031347
Epoch: 1 40000/60000 Training loss: 0.061168
Epoch: 1 50000/60000 Training loss: 0.060545
Training loss: 0.097805
Test loss: 0.044007; Test accuracy: 9858/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.024637
Epoch: 2 10000/60000 Training loss: 0.110130
Epoch: 2 20000/60000 Training loss: 0.092800
Epoch: 2 30000/60000 Training loss: 0.045752
Epoch: 2 40000/60000 Training loss: 0.028285
Epoch: 2 50000/60000 Training loss: 0.040030
Training loss: 0.069806
Test loss: 0.033765; Test accuracy: 9891/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.017008
Epoch: 3 10000/60000 Training loss: 0.044720
Epoch: 3 20000/60000 Training loss: 0.011867
Epoch: 3 30000/60000 Training loss: 0.064433
Epoch: 3 40000/60000 Training loss: 0.027818
Epoch: 3 50000/60000 Training loss: 0.062922
Training loss: 0.057272
Test loss: 0.028798; Test accuracy: 9911/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.020318
Epoch: 4 10000/60000 Training loss: 0.037197
Epoch: 4 20000/60000 Training loss: 0.098756
Epoch: 4 30000/60000 Training loss: 0.018808
Epoch: 4 40000/60000 Training loss: 0.036384
Epoch: 4 50000/60000 Training loss: 0.047569
Training loss: 0.046623
Test loss: 0.027212; Test accuracy: 9910/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.037976
Epoch: 5 10000/60000 Training loss: 0.023527
Epoch: 5 20000/60000 Training loss: 0.018377
Epoch: 5 30000/60000 Training loss: 0.025061
Epoch: 5 40000/60000 Training loss: 0.013034
Epoch: 5 50000/60000 Training loss: 0.038990
Training loss: 0.039716
Test loss: 0.026073; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.095062
Epoch: 6 10000/60000 Training loss: 0.074477
Epoch: 6 20000/60000 Training loss: 0.032725
Epoch: 6 30000/60000 Training loss: 0.007189
Epoch: 6 40000/60000 Training loss: 0.012935
Epoch: 6 50000/60000 Training loss: 0.013104
Training loss: 0.035246
Test loss: 0.025390; Test accuracy: 9919/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.033592
Epoch: 7 10000/60000 Training loss: 0.011089
Epoch: 7 20000/60000 Training loss: 0.026058
Epoch: 7 30000/60000 Training loss: 0.031964
Epoch: 7 40000/60000 Training loss: 0.010507
Epoch: 7 50000/60000 Training loss: 0.017750
Training loss: 0.032303
Test loss: 0.023470; Test accuracy: 9923/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.057789
Epoch: 8 10000/60000 Training loss: 0.053710
Epoch: 8 20000/60000 Training loss: 0.051563
Epoch: 8 30000/60000 Training loss: 0.007754
Epoch: 8 40000/60000 Training loss: 0.016212
Epoch: 8 50000/60000 Training loss: 0.066564
Training loss: 0.028700
Test loss: 0.022130; Test accuracy: 9921/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.058554
Epoch: 9 10000/60000 Training loss: 0.025303
Epoch: 9 20000/60000 Training loss: 0.100584
Epoch: 9 30000/60000 Training loss: 0.028015
Epoch: 9 40000/60000 Training loss: 0.001501
Epoch: 9 50000/60000 Training loss: 0.006262
Training loss: 0.024446
Test loss: 0.022905; Test accuracy: 9922/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.013072
Epoch: 10 10000/60000 Training loss: 0.024662
Epoch: 10 20000/60000 Training loss: 0.018766
Epoch: 10 30000/60000 Training loss: 0.004816
Epoch: 10 40000/60000 Training loss: 0.017446
Epoch: 10 50000/60000 Training loss: 0.045826
Training loss: 0.022581
Test loss: 0.021213; Test accuracy: 9932/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.010931
Epoch: 11 10000/60000 Training loss: 0.082697
Epoch: 11 20000/60000 Training loss: 0.006372
Epoch: 11 30000/60000 Training loss: 0.018433
Epoch: 11 40000/60000 Training loss: 0.040983
Epoch: 11 50000/60000 Training loss: 0.008358
Training loss: 0.020980
Test loss: 0.022175; Test accuracy: 9931/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.016940
Epoch: 12 10000/60000 Training loss: 0.092183
Epoch: 12 20000/60000 Training loss: 0.001858
Epoch: 12 30000/60000 Training loss: 0.028192
Epoch: 12 40000/60000 Training loss: 0.003911
Epoch: 12 50000/60000 Training loss: 0.049279
Training loss: 0.018740
Test loss: 0.021032; Test accuracy: 9932/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.025486
Epoch: 13 10000/60000 Training loss: 0.009001
Epoch: 13 20000/60000 Training loss: 0.001712
Epoch: 13 30000/60000 Training loss: 0.001035
Epoch: 13 40000/60000 Training loss: 0.025705
Epoch: 13 50000/60000 Training loss: 0.003638
Training loss: 0.017690
Test loss: 0.020226; Test accuracy: 9934/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.006032
Epoch: 14 10000/60000 Training loss: 0.015369
Epoch: 14 20000/60000 Training loss: 0.008991
Epoch: 14 30000/60000 Training loss: 0.003684
Epoch: 14 40000/60000 Training loss: 0.029395
Epoch: 14 50000/60000 Training loss: 0.013521
Training loss: 0.016610
Test loss: 0.018323; Test accuracy: 9936/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.017807
Epoch: 15 10000/60000 Training loss: 0.000636
Epoch: 15 20000/60000 Training loss: 0.033160
Epoch: 15 30000/60000 Training loss: 0.017547
Epoch: 15 40000/60000 Training loss: 0.001524
Epoch: 15 50000/60000 Training loss: 0.004377
Training loss: 0.013713
Test loss: 0.021054; Test accuracy: 9928/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.016204
Epoch: 16 10000/60000 Training loss: 0.003100
Epoch: 16 20000/60000 Training loss: 0.003983
Epoch: 16 30000/60000 Training loss: 0.004166
Epoch: 16 40000/60000 Training loss: 0.018158
Epoch: 16 50000/60000 Training loss: 0.026862
Training loss: 0.013395
Test loss: 0.020368; Test accuracy: 9938/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.005775
Epoch: 17 10000/60000 Training loss: 0.012763
Epoch: 17 20000/60000 Training loss: 0.000948
Epoch: 17 30000/60000 Training loss: 0.021089
Epoch: 17 40000/60000 Training loss: 0.009411
Epoch: 17 50000/60000 Training loss: 0.008373
Training loss: 0.011584
Test loss: 0.019265; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 02:20:45,572] Trial 38 finished with value: 0.0183226577937603 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.11939261250619634, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.0001462791554344665}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 32, 'num_conv2_channels': 112, 'conv2_drop': 0.09995204080953675, 'fc1_neurons': 170, 'optimizer': 'SGD', 'learning_rate': 6.59528910995622e-05}
Epoch: 0 0/60000 Training loss: 2.319312
Epoch: 0 10000/60000 Training loss: 2.323113
Epoch: 0 20000/60000 Training loss: 2.317143
Epoch: 0 30000/60000 Training loss: 2.312440
Epoch: 0 40000/60000 Training loss: 2.292134
Epoch: 0 50000/60000 Training loss: 2.297793
Training loss: 2.308621
Test loss: 2.289977; Test accuracy: 1241/10000 (12.4%)

Epoch: 1 0/60000 Training loss: 2.290159
Epoch: 1 10000/60000 Training loss: 2.310247
Epoch: 1 20000/60000 Training loss: 2.281496
Epoch: 1 30000/60000 Training loss: 2.302740
Epoch: 1 40000/60000 Training loss: 2.275281
Epoch: 1 50000/60000 Training loss: 2.303351
Training loss: 2.288101
Test loss: 2.270200; Test accuracy: 1594/10000 (15.9%)

Epoch: 2 0/60000 Training loss: 2.253342
Epoch: 2 10000/60000 Training loss: 2.257780
Epoch: 2 20000/60000 Training loss: 2.268315
Epoch: 2 30000/60000 Training loss: 2.285356
Epoch: 2 40000/60000 Training loss: 2.252871
Epoch: 2 50000/60000 Training loss: 2.263874
Training loss: 2.268988
Test loss: 2.251490; Test accuracy: 2050/10000 (20.5%)

Epoch: 3 0/60000 Training loss: 2.267052
Epoch: 3 10000/60000 Training loss: 2.262236
Epoch: 3 20000/60000 Training loss: 2.269302
Epoch: 3 30000/60000 Training loss: 2.258855
Epoch: 3 40000/60000 Training loss: 2.263959
Epoch: 3 50000/60000 Training loss: 2.230730
Training loss: 2.251714
Test loss: 2.232864; Test accuracy: 3009/10000 (30.1%)

Epoch: 4 0/60000 Training loss: 2.242324
Epoch: 4 10000/60000 Training loss: 2.231599
Epoch: 4 20000/60000 Training loss: 2.221828
Epoch: 4 30000/60000 Training loss: 2.227159
Epoch: 4 40000/60000 Training loss: 2.237762
Epoch: 4 50000/60000 Training loss: 2.245631
Training loss: 2.234128
Test loss: 2.213665; Test accuracy: 4233/10000 (42.3%)

Epoch: 5 0/60000 Training loss: 2.237153
Epoch: 5 10000/60000 Training loss: 2.219431
Epoch: 5 20000/60000 Training loss: 2.236074
Epoch: 5 30000/60000 Training loss: 2.202157
Epoch: 5 40000/60000 Training loss: 2.241559
Epoch: 5 50000/60000 Training loss: 2.195457
Training loss: 2.216093
Test loss: 2.193422; Test accuracy: 5208/10000 (52.1%)

Epoch: 6 0/60000 Training loss: 2.201532
Epoch: 6 10000/60000 Training loss: 2.193387
Epoch: 6 20000/60000 Training loss: 2.203227
Epoch: 6 30000/60000 Training loss: 2.170395
Epoch: 6 40000/60000 Training loss: 2.187169
Epoch: 6 50000/60000 Training loss: 2.199789
Training loss: 2.195594
Test loss: 2.171608; Test accuracy: 5942/10000 (59.4%)

Epoch: 7 0/60000 Training loss: 2.169934
Epoch: 7 10000/60000 Training loss: 2.186909
Epoch: 7 20000/60000 Training loss: 2.165763
Epoch: 7 30000/60000 Training loss: 2.186570
Epoch: 7 40000/60000 Training loss: 2.182275
Epoch: 7 50000/60000 Training loss: 2.159806
Training loss: 2.175703
Test loss: 2.147896; Test accuracy: 6488/10000 (64.9%)

Epoch: 8 0/60000 Training loss: 2.166305
Epoch: 8 10000/60000 Training loss: 2.179856
Epoch: 8 20000/60000 Training loss: 2.147758
Epoch: 8 30000/60000 Training loss: 2.151209
Epoch: 8 40000/60000 Training loss: 2.134100
Epoch: 8 50000/60000 Training loss: 2.120256
Training loss: 2.151191
Test loss: 2.121626; Test accuracy: 6849/10000 (68.5%)

Epoch: 9 0/60000 Training loss: 2.116395
Epoch: 9 10000/60000 Training loss: 2.145435
Epoch: 9 20000/60000 Training loss: 2.104810
Epoch: 9 30000/60000 Training loss: 2.125985
Epoch: 9 40000/60000 Training loss: 2.135635
Epoch: 9 50000/60000 Training loss: 2.123633
Training loss: 2.124990
Test loss: 2.092577; Test accuracy: 7113/10000 (71.1%)

Epoch: 10 0/60000 Training loss: 2.117005
Epoch: 10 10000/60000 Training loss: 2.127520
Epoch: 10 20000/60000 Training loss: 2.132972
Epoch: 10 30000/60000 Training loss: 2.089286
Epoch: 10 40000/60000 Training loss: 2.067647
Epoch: 10 50000/60000 Training loss: 2.050720
Training loss: 2.096440
Test loss: 2.060136; Test accuracy: 7297/10000 (73.0%)

Epoch: 11 0/60000 Training loss: 2.039573
Epoch: 11 10000/60000 Training loss: 2.055736
Epoch: 11 20000/60000 Training loss: 2.063380
Epoch: 11 30000/60000 Training loss: 2.078109
Epoch: 11 40000/60000 Training loss: 2.071019
Epoch: 11 50000/60000 Training loss: 2.051163
Training loss: 2.067175
Test loss: 2.024304; Test accuracy: 7433/10000 (74.3%)

Epoch: 12 0/60000 Training loss: 2.085942
Epoch: 12 10000/60000 Training loss: 2.039656
Epoch: 12 20000/60000 Training loss: 2.029847
Epoch: 12 30000/60000 Training loss: 2.067870
Epoch: 12 40000/60000 Training loss: 1.986201
Epoch: 12 50000/60000 Training loss: 1.995614
Training loss: 2.030182
Test loss: 1.984328; Test accuracy: 7509/10000 (75.1%)

Epoch: 13 0/60000 Training loss: 2.015343
Epoch: 13 10000/60000 Training loss: 1.999907
Epoch: 13 20000/60000 Training loss: 1.998264
Epoch: 13 30000/60000 Training loss: 1.989203
Epoch: 13 40000/60000 Training loss: 1.943010
Epoch: 13 50000/60000 Training loss: 1.976752
Training loss: 1.993338
Test loss: 1.940148; Test accuracy: 7573/10000 (75.7%)

Epoch: 14 0/60000 Training loss: 1.944988
Epoch: 14 10000/60000 Training loss: 1.925131
Epoch: 14 20000/60000 Training loss: 1.917867
Epoch: 14 30000/60000 Training loss: 1.986109
Epoch: 14 40000/60000 Training loss: 1.978375
Epoch: 14 50000/60000 Training loss: 1.953202
Training loss: 1.949909
Test loss: 1.891385; Test accuracy: 7621/10000 (76.2%)

Epoch: 15 0/60000 Training loss: 1.913544
Epoch: 15 10000/60000 Training loss: 1.866953
Epoch: 15 20000/60000 Training loss: 1.851097
Epoch: 15 30000/60000 Training loss: 1.948592
Epoch: 15 40000/60000 Training loss: 1.924646
Epoch: 15 50000/60000 Training loss: 1.892583
Training loss: 1.904596
Test loss: 1.837893; Test accuracy: 7676/10000 (76.8%)

Epoch: 16 0/60000 Training loss: 1.853093
Epoch: 16 10000/60000 Training loss: 1.884803
Epoch: 16 20000/60000 Training loss: 1.815097
Epoch: 16 30000/60000 Training loss: 1.854181
Epoch: 16 40000/60000 Training loss: 1.844979
Epoch: 16 50000/60000 Training loss: 1.812215
Training loss: 1.856051
Test loss: 1.779503; Test accuracy: 7753/10000 (77.5%)

Epoch: 17 0/60000 Training loss: 1.828626
Epoch: 17 10000/60000 Training loss: 1.775422
Epoch: 17 20000/60000 Training loss: 1.832344
Epoch: 17 30000/60000 Training loss: 1.816011
Epoch: 17 40000/60000 Training loss: 1.794125
Epoch: 17 50000/60000 Training loss: 1.811462
Training loss: 1.800830
Test loss: 1.715920; Test accuracy: 7795/10000 (77.9%)

Epoch: 18 0/60000 Training loss: 1.771012
Epoch: 18 10000/60000 Training loss: 1.765889
Epoch: 18 20000/60000 Training loss: 1.773487
Epoch: 18 30000/60000 Training loss: 1.709818
Epoch: 18 40000/60000 Training loss: 1.717371
Epoch: 18 50000/60000 Training loss: 1.780900
Training loss: 1.742929
Test loss: 1.647339; Test accuracy: 7881/10000 (78.8%)

Epoch: 19 0/60000 Training loss: 1.664767
Epoch: 19 10000/60000 Training loss: 1.758100
Epoch: 19 20000/60000 Training loss: 1.667818
Epoch: 19 30000/60000 Training loss: 1.650260
Epoch: 19 40000/60000 Training loss: 1.688985
Epoch: 19 50000/60000 Training loss: 1.721157
Training loss: 1.678460
Test loss: 1.574527; Test accuracy: 7961/10000 (79.6%)

[I 2022-11-04 02:25:22,954] Trial 39 finished with value: 1.5745265483856201 and parameters: {'num_conv1_channels': 32, 'num_conv2_channels': 112, 'conv2_drop': 0.09995204080953675, 'fc1_neurons': 170, 'optimizer': 'SGD', 'learning_rate': 6.59528910995622e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.19386025748026814, 'fc1_neurons': 20, 'optimizer': 'Adam', 'learning_rate': 9.476488953751791e-05}
Epoch: 0 0/60000 Training loss: 2.313961
Epoch: 0 10000/60000 Training loss: 1.292154
Epoch: 0 20000/60000 Training loss: 0.989551
Epoch: 0 30000/60000 Training loss: 0.666852
Epoch: 0 40000/60000 Training loss: 0.793778
Epoch: 0 50000/60000 Training loss: 0.650889
Training loss: 0.994878
Test loss: 0.189472; Test accuracy: 9574/10000 (95.7%)

Epoch: 1 0/60000 Training loss: 0.560938
Epoch: 1 10000/60000 Training loss: 0.722575
Epoch: 1 20000/60000 Training loss: 0.569591
Epoch: 1 30000/60000 Training loss: 0.678515
Epoch: 1 40000/60000 Training loss: 0.517713
Epoch: 1 50000/60000 Training loss: 0.502199
Training loss: 0.563762
Test loss: 0.109999; Test accuracy: 9739/10000 (97.4%)

Epoch: 2 0/60000 Training loss: 0.485058
Epoch: 2 10000/60000 Training loss: 0.546423
Epoch: 2 20000/60000 Training loss: 0.267021
Epoch: 2 30000/60000 Training loss: 0.598799
Epoch: 2 40000/60000 Training loss: 0.482363
Epoch: 2 50000/60000 Training loss: 0.427659
Training loss: 0.454904
Test loss: 0.083404; Test accuracy: 9773/10000 (97.7%)

Epoch: 3 0/60000 Training loss: 0.291818
Epoch: 3 10000/60000 Training loss: 0.400029
Epoch: 3 20000/60000 Training loss: 0.428865
Epoch: 3 30000/60000 Training loss: 0.339043
Epoch: 3 40000/60000 Training loss: 0.429069
Epoch: 3 50000/60000 Training loss: 0.479521
Training loss: 0.400399
Test loss: 0.064908; Test accuracy: 9817/10000 (98.2%)

Epoch: 4 0/60000 Training loss: 0.356353
Epoch: 4 10000/60000 Training loss: 0.296946
Epoch: 4 20000/60000 Training loss: 0.389897
Epoch: 4 30000/60000 Training loss: 0.334386
Epoch: 4 40000/60000 Training loss: 0.493863
Epoch: 4 50000/60000 Training loss: 0.307325
Training loss: 0.363946
Test loss: 0.053904; Test accuracy: 9831/10000 (98.3%)

Epoch: 5 0/60000 Training loss: 0.285740
Epoch: 5 10000/60000 Training loss: 0.344809
Epoch: 5 20000/60000 Training loss: 0.312689
Epoch: 5 30000/60000 Training loss: 0.351396
Epoch: 5 40000/60000 Training loss: 0.331611
Epoch: 5 50000/60000 Training loss: 0.204531
Training loss: 0.331368
Test loss: 0.046890; Test accuracy: 9852/10000 (98.5%)

Epoch: 6 0/60000 Training loss: 0.284688
Epoch: 6 10000/60000 Training loss: 0.354100
Epoch: 6 20000/60000 Training loss: 0.329123
Epoch: 6 30000/60000 Training loss: 0.422689
Epoch: 6 40000/60000 Training loss: 0.339296
Epoch: 6 50000/60000 Training loss: 0.362165
Training loss: 0.317568
Test loss: 0.045602; Test accuracy: 9856/10000 (98.6%)

Epoch: 7 0/60000 Training loss: 0.303152
Epoch: 7 10000/60000 Training loss: 0.406883
Epoch: 7 20000/60000 Training loss: 0.289276
Epoch: 7 30000/60000 Training loss: 0.276608
Epoch: 7 40000/60000 Training loss: 0.298484
Epoch: 7 50000/60000 Training loss: 0.288118
Training loss: 0.297192
Test loss: 0.039268; Test accuracy: 9875/10000 (98.8%)

Epoch: 8 0/60000 Training loss: 0.373767
Epoch: 8 10000/60000 Training loss: 0.319317
Epoch: 8 20000/60000 Training loss: 0.333816
Epoch: 8 30000/60000 Training loss: 0.404971
Epoch: 8 40000/60000 Training loss: 0.153858
Epoch: 8 50000/60000 Training loss: 0.400251
Training loss: 0.282713
Test loss: 0.040623; Test accuracy: 9876/10000 (98.8%)

Epoch: 9 0/60000 Training loss: 0.287802
Epoch: 9 10000/60000 Training loss: 0.476568
Epoch: 9 20000/60000 Training loss: 0.220619
Epoch: 9 30000/60000 Training loss: 0.296319
Epoch: 9 40000/60000 Training loss: 0.319692
Epoch: 9 50000/60000 Training loss: 0.272293
Training loss: 0.270691
Test loss: 0.036061; Test accuracy: 9889/10000 (98.9%)

Epoch: 10 0/60000 Training loss: 0.399475
Epoch: 10 10000/60000 Training loss: 0.370866
Epoch: 10 20000/60000 Training loss: 0.228695
Epoch: 10 30000/60000 Training loss: 0.310374
Epoch: 10 40000/60000 Training loss: 0.317508
Epoch: 10 50000/60000 Training loss: 0.248390
Training loss: 0.262273
Test loss: 0.036572; Test accuracy: 9885/10000 (98.8%)

Epoch: 11 0/60000 Training loss: 0.236308
Epoch: 11 10000/60000 Training loss: 0.215247
Epoch: 11 20000/60000 Training loss: 0.163526
Epoch: 11 30000/60000 Training loss: 0.217692
Epoch: 11 40000/60000 Training loss: 0.170853
Epoch: 11 50000/60000 Training loss: 0.160271
Training loss: 0.255349
Test loss: 0.032321; Test accuracy: 9904/10000 (99.0%)

Epoch: 12 0/60000 Training loss: 0.309432
Epoch: 12 10000/60000 Training loss: 0.421117
Epoch: 12 20000/60000 Training loss: 0.143291
Epoch: 12 30000/60000 Training loss: 0.354199
Epoch: 12 40000/60000 Training loss: 0.323135
Epoch: 12 50000/60000 Training loss: 0.371230
Training loss: 0.250030
Test loss: 0.032379; Test accuracy: 9902/10000 (99.0%)

Epoch: 13 0/60000 Training loss: 0.160100
Epoch: 13 10000/60000 Training loss: 0.253019
Epoch: 13 20000/60000 Training loss: 0.176910
Epoch: 13 30000/60000 Training loss: 0.188594
Epoch: 13 40000/60000 Training loss: 0.303691
Epoch: 13 50000/60000 Training loss: 0.188359
Training loss: 0.235755
Test loss: 0.029223; Test accuracy: 9902/10000 (99.0%)

Epoch: 14 0/60000 Training loss: 0.237374
Epoch: 14 10000/60000 Training loss: 0.224351
Epoch: 14 20000/60000 Training loss: 0.168349
Epoch: 14 30000/60000 Training loss: 0.230956
Epoch: 14 40000/60000 Training loss: 0.114476
Epoch: 14 50000/60000 Training loss: 0.198108
Training loss: 0.231238
Test loss: 0.029760; Test accuracy: 9904/10000 (99.0%)

Epoch: 15 0/60000 Training loss: 0.228075
Epoch: 15 10000/60000 Training loss: 0.277470
Epoch: 15 20000/60000 Training loss: 0.263917
Epoch: 15 30000/60000 Training loss: 0.234743
Epoch: 15 40000/60000 Training loss: 0.326680
Epoch: 15 50000/60000 Training loss: 0.228692
Training loss: 0.224479
Test loss: 0.030626; Test accuracy: 9902/10000 (99.0%)

Epoch: 16 0/60000 Training loss: 0.146041
Epoch: 16 10000/60000 Training loss: 0.272139
Epoch: 16 20000/60000 Training loss: 0.212101
Epoch: 16 30000/60000 Training loss: 0.181759
Epoch: 16 40000/60000 Training loss: 0.171292
Epoch: 16 50000/60000 Training loss: 0.192771
Training loss: 0.218035
Test loss: 0.027760; Test accuracy: 9908/10000 (99.1%)

Epoch: 17 0/60000 Training loss: 0.126695
Epoch: 17 10000/60000 Training loss: 0.247036
Epoch: 17 20000/60000 Training loss: 0.183009
Epoch: 17 30000/60000 Training loss: 0.249180
Epoch: 17 40000/60000 Training loss: 0.182608
Epoch: 17 50000/60000 Training loss: 0.183152
Training loss: 0.219845
Test loss: 0.027921; Test accuracy: 9905/10000 (99.0%)

Epoch: 18 0/60000 Training loss: 0.187612
Epoch: 18 10000/60000 Training loss: 0.216651
Epoch: 18 20000/60000 Training loss: 0.165544
Epoch: 18 30000/60000 Training loss: 0.304647
Epoch: 18 40000/60000 Training loss: 0.257869
Epoch: 18 50000/60000 Training loss: 0.192383
Training loss: 0.210959
Test loss: 0.028582; Test accuracy: 9901/10000 (99.0%)

Epoch: 19 0/60000 Training loss: 0.223194
Epoch: 19 10000/60000 Training loss: 0.178860
Epoch: 19 20000/60000 Training loss: 0.144805
Epoch: 19 30000/60000 Training loss: 0.202413
Epoch: 19 40000/60000 Training loss: 0.207988
Epoch: 19 50000/60000 Training loss: 0.198266
Training loss: 0.208063
Test loss: 0.026471; Test accuracy: 9916/10000 (99.2%)

[I 2022-11-04 02:30:02,123] Trial 40 finished with value: 0.026471422985196114 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 128, 'conv2_drop': 0.19386025748026814, 'fc1_neurons': 20, 'optimizer': 'Adam', 'learning_rate': 9.476488953751791e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1765260042339029, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 0.0002170838952402101}
Epoch: 0 0/60000 Training loss: 2.280428
Epoch: 0 10000/60000 Training loss: 0.512202
Epoch: 0 20000/60000 Training loss: 0.166707
Epoch: 0 30000/60000 Training loss: 0.169151
Epoch: 0 40000/60000 Training loss: 0.256441
Epoch: 0 50000/60000 Training loss: 0.133826
Training loss: 0.372948
Test loss: 0.072609; Test accuracy: 9770/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.124815
Epoch: 1 10000/60000 Training loss: 0.131751
Epoch: 1 20000/60000 Training loss: 0.133633
Epoch: 1 30000/60000 Training loss: 0.126067
Epoch: 1 40000/60000 Training loss: 0.039355
Epoch: 1 50000/60000 Training loss: 0.056462
Training loss: 0.111024
Test loss: 0.045229; Test accuracy: 9848/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.103261
Epoch: 2 10000/60000 Training loss: 0.043964
Epoch: 2 20000/60000 Training loss: 0.152915
Epoch: 2 30000/60000 Training loss: 0.221434
Epoch: 2 40000/60000 Training loss: 0.074409
Epoch: 2 50000/60000 Training loss: 0.049331
Training loss: 0.076883
Test loss: 0.033563; Test accuracy: 9894/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.064593
Epoch: 3 10000/60000 Training loss: 0.069208
Epoch: 3 20000/60000 Training loss: 0.083214
Epoch: 3 30000/60000 Training loss: 0.116750
Epoch: 3 40000/60000 Training loss: 0.129133
Epoch: 3 50000/60000 Training loss: 0.037835
Training loss: 0.064528
Test loss: 0.030182; Test accuracy: 9905/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.063556
Epoch: 4 10000/60000 Training loss: 0.028472
Epoch: 4 20000/60000 Training loss: 0.072404
Epoch: 4 30000/60000 Training loss: 0.181727
Epoch: 4 40000/60000 Training loss: 0.034638
Epoch: 4 50000/60000 Training loss: 0.017555
Training loss: 0.052556
Test loss: 0.025946; Test accuracy: 9907/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.054279
Epoch: 5 10000/60000 Training loss: 0.014825
Epoch: 5 20000/60000 Training loss: 0.055864
Epoch: 5 30000/60000 Training loss: 0.021255
Epoch: 5 40000/60000 Training loss: 0.012497
Epoch: 5 50000/60000 Training loss: 0.021409
Training loss: 0.046320
Test loss: 0.024394; Test accuracy: 9925/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.098419
Epoch: 6 10000/60000 Training loss: 0.006682
Epoch: 6 20000/60000 Training loss: 0.070202
Epoch: 6 30000/60000 Training loss: 0.011957
Epoch: 6 40000/60000 Training loss: 0.010849
Epoch: 6 50000/60000 Training loss: 0.069733
Training loss: 0.041023
Test loss: 0.026051; Test accuracy: 9909/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.049745
Epoch: 7 10000/60000 Training loss: 0.004105
Epoch: 7 20000/60000 Training loss: 0.013854
Epoch: 7 30000/60000 Training loss: 0.064488
Epoch: 7 40000/60000 Training loss: 0.016138
Epoch: 7 50000/60000 Training loss: 0.012400
Training loss: 0.035913
Test loss: 0.023443; Test accuracy: 9921/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.012295
Epoch: 8 10000/60000 Training loss: 0.009072
Epoch: 8 20000/60000 Training loss: 0.010979
Epoch: 8 30000/60000 Training loss: 0.004979
Epoch: 8 40000/60000 Training loss: 0.007342
Epoch: 8 50000/60000 Training loss: 0.051535
Training loss: 0.034267
Test loss: 0.021105; Test accuracy: 9933/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.013836
Epoch: 9 10000/60000 Training loss: 0.004605
Epoch: 9 20000/60000 Training loss: 0.089064
Epoch: 9 30000/60000 Training loss: 0.026043
Epoch: 9 40000/60000 Training loss: 0.022390
Epoch: 9 50000/60000 Training loss: 0.027809
Training loss: 0.029911
Test loss: 0.019139; Test accuracy: 9941/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.013918
Epoch: 10 10000/60000 Training loss: 0.008219
Epoch: 10 20000/60000 Training loss: 0.013334
Epoch: 10 30000/60000 Training loss: 0.019700
Epoch: 10 40000/60000 Training loss: 0.001825
Epoch: 10 50000/60000 Training loss: 0.003593
Training loss: 0.026987
Test loss: 0.019437; Test accuracy: 9934/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.005961
Epoch: 11 10000/60000 Training loss: 0.005809
Epoch: 11 20000/60000 Training loss: 0.031557
Epoch: 11 30000/60000 Training loss: 0.002844
Epoch: 11 40000/60000 Training loss: 0.008055
Epoch: 11 50000/60000 Training loss: 0.030804
Training loss: 0.025490
Test loss: 0.020267; Test accuracy: 9935/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.044994
Epoch: 12 10000/60000 Training loss: 0.013375
Epoch: 12 20000/60000 Training loss: 0.014020
Epoch: 12 30000/60000 Training loss: 0.042640
Epoch: 12 40000/60000 Training loss: 0.014346
Epoch: 12 50000/60000 Training loss: 0.005133
Training loss: 0.022751
Test loss: 0.019628; Test accuracy: 9927/10000 (99.3%)

[I 2022-11-04 02:33:04,439] Trial 41 finished with value: 0.019138922914862633 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1765260042339029, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 0.0002170838952402101}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1876768367426998, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00012793474563720363}
Epoch: 0 0/60000 Training loss: 2.291634
Epoch: 0 10000/60000 Training loss: 0.600142
Epoch: 0 20000/60000 Training loss: 0.230367
Epoch: 0 30000/60000 Training loss: 0.270903
Epoch: 0 40000/60000 Training loss: 0.178177
Epoch: 0 50000/60000 Training loss: 0.249833
Training loss: 0.457938
Test loss: 0.097040; Test accuracy: 9716/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.191573
Epoch: 1 10000/60000 Training loss: 0.116436
Epoch: 1 20000/60000 Training loss: 0.167798
Epoch: 1 30000/60000 Training loss: 0.261738
Epoch: 1 40000/60000 Training loss: 0.200968
Epoch: 1 50000/60000 Training loss: 0.189648
Training loss: 0.144235
Test loss: 0.061418; Test accuracy: 9797/10000 (98.0%)

Epoch: 2 0/60000 Training loss: 0.071255
Epoch: 2 10000/60000 Training loss: 0.049401
Epoch: 2 20000/60000 Training loss: 0.087887
Epoch: 2 30000/60000 Training loss: 0.187032
Epoch: 2 40000/60000 Training loss: 0.214116
Epoch: 2 50000/60000 Training loss: 0.051413
Training loss: 0.102332
Test loss: 0.041894; Test accuracy: 9859/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.066548
Epoch: 3 10000/60000 Training loss: 0.098047
Epoch: 3 20000/60000 Training loss: 0.075714
Epoch: 3 30000/60000 Training loss: 0.127354
Epoch: 3 40000/60000 Training loss: 0.079012
Epoch: 3 50000/60000 Training loss: 0.035967
Training loss: 0.080892
Test loss: 0.035457; Test accuracy: 9886/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.115601
Epoch: 4 10000/60000 Training loss: 0.078284
Epoch: 4 20000/60000 Training loss: 0.080668
Epoch: 4 30000/60000 Training loss: 0.025813
Epoch: 4 40000/60000 Training loss: 0.041813
Epoch: 4 50000/60000 Training loss: 0.039145
Training loss: 0.070593
Test loss: 0.032926; Test accuracy: 9886/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.061227
Epoch: 5 10000/60000 Training loss: 0.050487
Epoch: 5 20000/60000 Training loss: 0.025738
Epoch: 5 30000/60000 Training loss: 0.117130
Epoch: 5 40000/60000 Training loss: 0.068021
Epoch: 5 50000/60000 Training loss: 0.017498
Training loss: 0.061409
Test loss: 0.029384; Test accuracy: 9905/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.070900
Epoch: 6 10000/60000 Training loss: 0.042334
Epoch: 6 20000/60000 Training loss: 0.083186
Epoch: 6 30000/60000 Training loss: 0.049237
Epoch: 6 40000/60000 Training loss: 0.084314
Epoch: 6 50000/60000 Training loss: 0.044503
Training loss: 0.054582
Test loss: 0.025570; Test accuracy: 9909/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.089226
Epoch: 7 10000/60000 Training loss: 0.010927
Epoch: 7 20000/60000 Training loss: 0.005241
Epoch: 7 30000/60000 Training loss: 0.050800
Epoch: 7 40000/60000 Training loss: 0.015776
Epoch: 7 50000/60000 Training loss: 0.031826
Training loss: 0.048849
Test loss: 0.022868; Test accuracy: 9923/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.106959
Epoch: 8 10000/60000 Training loss: 0.005831
Epoch: 8 20000/60000 Training loss: 0.033237
Epoch: 8 30000/60000 Training loss: 0.022414
Epoch: 8 40000/60000 Training loss: 0.101187
Epoch: 8 50000/60000 Training loss: 0.054064
Training loss: 0.045894
Test loss: 0.023285; Test accuracy: 9923/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.045012
Epoch: 9 10000/60000 Training loss: 0.020522
Epoch: 9 20000/60000 Training loss: 0.013874
Epoch: 9 30000/60000 Training loss: 0.073949
Epoch: 9 40000/60000 Training loss: 0.052578
Epoch: 9 50000/60000 Training loss: 0.029813
Training loss: 0.040266
Test loss: 0.021878; Test accuracy: 9925/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.016132
Epoch: 10 10000/60000 Training loss: 0.008019
Epoch: 10 20000/60000 Training loss: 0.022712
Epoch: 10 30000/60000 Training loss: 0.049347
Epoch: 10 40000/60000 Training loss: 0.043362
Epoch: 10 50000/60000 Training loss: 0.026553
Training loss: 0.037800
Test loss: 0.021032; Test accuracy: 9936/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.018679
Epoch: 11 10000/60000 Training loss: 0.154997
Epoch: 11 20000/60000 Training loss: 0.079284
Epoch: 11 30000/60000 Training loss: 0.099411
Epoch: 11 40000/60000 Training loss: 0.012943
Epoch: 11 50000/60000 Training loss: 0.010253
Training loss: 0.035286
Test loss: 0.020753; Test accuracy: 9927/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.007730
Epoch: 12 10000/60000 Training loss: 0.026593
Epoch: 12 20000/60000 Training loss: 0.045072
Epoch: 12 30000/60000 Training loss: 0.006881
Epoch: 12 40000/60000 Training loss: 0.010931
Epoch: 12 50000/60000 Training loss: 0.007210
Training loss: 0.034011
Test loss: 0.019607; Test accuracy: 9933/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.035038
Epoch: 13 10000/60000 Training loss: 0.014511
Epoch: 13 20000/60000 Training loss: 0.019068
Epoch: 13 30000/60000 Training loss: 0.111787
Epoch: 13 40000/60000 Training loss: 0.073362
Epoch: 13 50000/60000 Training loss: 0.035757
Training loss: 0.029528
Test loss: 0.020272; Test accuracy: 9934/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.070083
Epoch: 14 10000/60000 Training loss: 0.007093
Epoch: 14 20000/60000 Training loss: 0.018483
Epoch: 14 30000/60000 Training loss: 0.005617
Epoch: 14 40000/60000 Training loss: 0.023188
Epoch: 14 50000/60000 Training loss: 0.015684
Training loss: 0.028873
Test loss: 0.018417; Test accuracy: 9939/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.008036
Epoch: 15 10000/60000 Training loss: 0.052086
Epoch: 15 20000/60000 Training loss: 0.005522
Epoch: 15 30000/60000 Training loss: 0.024508
Epoch: 15 40000/60000 Training loss: 0.021683
Epoch: 15 50000/60000 Training loss: 0.034306
Training loss: 0.026819
Test loss: 0.018416; Test accuracy: 9937/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.021007
Epoch: 16 10000/60000 Training loss: 0.035819
Epoch: 16 20000/60000 Training loss: 0.021667
Epoch: 16 30000/60000 Training loss: 0.005989
Epoch: 16 40000/60000 Training loss: 0.040947
Epoch: 16 50000/60000 Training loss: 0.013723
Training loss: 0.026144
Test loss: 0.021623; Test accuracy: 9933/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.007119
Epoch: 17 10000/60000 Training loss: 0.022945
Epoch: 17 20000/60000 Training loss: 0.016022
Epoch: 17 30000/60000 Training loss: 0.008006
Epoch: 17 40000/60000 Training loss: 0.018255
Epoch: 17 50000/60000 Training loss: 0.008502
Training loss: 0.023039
Test loss: 0.019132; Test accuracy: 9938/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.027511
Epoch: 18 10000/60000 Training loss: 0.030771
Epoch: 18 20000/60000 Training loss: 0.022672
Epoch: 18 30000/60000 Training loss: 0.096578
Epoch: 18 40000/60000 Training loss: 0.072734
Epoch: 18 50000/60000 Training loss: 0.001973
Training loss: 0.022627
Test loss: 0.021912; Test accuracy: 9926/10000 (99.3%)

[I 2022-11-04 02:37:29,989] Trial 42 finished with value: 0.018416155129671097 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1876768367426998, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.00012793474563720363}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.16448321659722115, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001706749981051476}
Epoch: 0 0/60000 Training loss: 2.335570
Epoch: 0 10000/60000 Training loss: 0.387730
Epoch: 0 20000/60000 Training loss: 0.146524
Epoch: 0 30000/60000 Training loss: 0.335229
Epoch: 0 40000/60000 Training loss: 0.254468
Epoch: 0 50000/60000 Training loss: 0.176543
Training loss: 0.377815
Test loss: 0.078457; Test accuracy: 9747/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.235072
Epoch: 1 10000/60000 Training loss: 0.054988
Epoch: 1 20000/60000 Training loss: 0.089647
Epoch: 1 30000/60000 Training loss: 0.107566
Epoch: 1 40000/60000 Training loss: 0.080665
Epoch: 1 50000/60000 Training loss: 0.071053
Training loss: 0.112802
Test loss: 0.054099; Test accuracy: 9829/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.076901
Epoch: 2 10000/60000 Training loss: 0.057073
Epoch: 2 20000/60000 Training loss: 0.069676
Epoch: 2 30000/60000 Training loss: 0.111118
Epoch: 2 40000/60000 Training loss: 0.047219
Epoch: 2 50000/60000 Training loss: 0.074930
Training loss: 0.083300
Test loss: 0.034747; Test accuracy: 9886/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.017968
Epoch: 3 10000/60000 Training loss: 0.106981
Epoch: 3 20000/60000 Training loss: 0.039629
Epoch: 3 30000/60000 Training loss: 0.147527
Epoch: 3 40000/60000 Training loss: 0.100488
Epoch: 3 50000/60000 Training loss: 0.021780
Training loss: 0.067461
Test loss: 0.029370; Test accuracy: 9902/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.083367
Epoch: 4 10000/60000 Training loss: 0.055746
Epoch: 4 20000/60000 Training loss: 0.059996
Epoch: 4 30000/60000 Training loss: 0.043692
Epoch: 4 40000/60000 Training loss: 0.044420
Epoch: 4 50000/60000 Training loss: 0.016812
Training loss: 0.056161
Test loss: 0.027065; Test accuracy: 9913/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.076205
Epoch: 5 10000/60000 Training loss: 0.031541
Epoch: 5 20000/60000 Training loss: 0.040386
Epoch: 5 30000/60000 Training loss: 0.041226
Epoch: 5 40000/60000 Training loss: 0.020816
Epoch: 5 50000/60000 Training loss: 0.013588
Training loss: 0.047589
Test loss: 0.025115; Test accuracy: 9920/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.055698
Epoch: 6 10000/60000 Training loss: 0.026241
Epoch: 6 20000/60000 Training loss: 0.037807
Epoch: 6 30000/60000 Training loss: 0.037044
Epoch: 6 40000/60000 Training loss: 0.060851
Epoch: 6 50000/60000 Training loss: 0.012920
Training loss: 0.042229
Test loss: 0.025052; Test accuracy: 9911/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.002956
Epoch: 7 10000/60000 Training loss: 0.028976
Epoch: 7 20000/60000 Training loss: 0.015202
Epoch: 7 30000/60000 Training loss: 0.041060
Epoch: 7 40000/60000 Training loss: 0.030805
Epoch: 7 50000/60000 Training loss: 0.026690
Training loss: 0.039055
Test loss: 0.020904; Test accuracy: 9930/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.011403
Epoch: 8 10000/60000 Training loss: 0.046617
Epoch: 8 20000/60000 Training loss: 0.036028
Epoch: 8 30000/60000 Training loss: 0.034804
Epoch: 8 40000/60000 Training loss: 0.048718
Epoch: 8 50000/60000 Training loss: 0.018411
Training loss: 0.034069
Test loss: 0.019962; Test accuracy: 9936/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.025169
Epoch: 9 10000/60000 Training loss: 0.018472
Epoch: 9 20000/60000 Training loss: 0.004972
Epoch: 9 30000/60000 Training loss: 0.043696
Epoch: 9 40000/60000 Training loss: 0.029928
Epoch: 9 50000/60000 Training loss: 0.039757
Training loss: 0.030662
Test loss: 0.022106; Test accuracy: 9921/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.011901
Epoch: 10 10000/60000 Training loss: 0.013704
Epoch: 10 20000/60000 Training loss: 0.040038
Epoch: 10 30000/60000 Training loss: 0.007063
Epoch: 10 40000/60000 Training loss: 0.023004
Epoch: 10 50000/60000 Training loss: 0.010954
Training loss: 0.027787
Test loss: 0.020373; Test accuracy: 9932/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.037592
Epoch: 11 10000/60000 Training loss: 0.017838
Epoch: 11 20000/60000 Training loss: 0.051029
Epoch: 11 30000/60000 Training loss: 0.010630
Epoch: 11 40000/60000 Training loss: 0.008685
Epoch: 11 50000/60000 Training loss: 0.013278
Training loss: 0.023914
Test loss: 0.020550; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 02:40:17,945] Trial 43 finished with value: 0.019961532205343246 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.16448321659722115, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001706749981051476}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 48, 'num_conv2_channels': 64, 'conv2_drop': 0.15376431563053214, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0002657529132738181}
Epoch: 0 0/60000 Training loss: 2.302714
Epoch: 0 10000/60000 Training loss: 0.421784
Epoch: 0 20000/60000 Training loss: 0.194927
Epoch: 0 30000/60000 Training loss: 0.198898
Epoch: 0 40000/60000 Training loss: 0.160867
Epoch: 0 50000/60000 Training loss: 0.137147
Training loss: 0.340639
Test loss: 0.071800; Test accuracy: 9778/10000 (97.8%)

Epoch: 1 0/60000 Training loss: 0.214829
Epoch: 1 10000/60000 Training loss: 0.051033
Epoch: 1 20000/60000 Training loss: 0.051878
Epoch: 1 30000/60000 Training loss: 0.061346
Epoch: 1 40000/60000 Training loss: 0.062366
Epoch: 1 50000/60000 Training loss: 0.036778
Training loss: 0.099857
Test loss: 0.041013; Test accuracy: 9868/10000 (98.7%)

Epoch: 2 0/60000 Training loss: 0.027464
Epoch: 2 10000/60000 Training loss: 0.119835
Epoch: 2 20000/60000 Training loss: 0.047518
Epoch: 2 30000/60000 Training loss: 0.202739
Epoch: 2 40000/60000 Training loss: 0.062335
Epoch: 2 50000/60000 Training loss: 0.049732
Training loss: 0.071781
Test loss: 0.033738; Test accuracy: 9884/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.057429
Epoch: 3 10000/60000 Training loss: 0.042765
Epoch: 3 20000/60000 Training loss: 0.076970
Epoch: 3 30000/60000 Training loss: 0.032104
Epoch: 3 40000/60000 Training loss: 0.022447
Epoch: 3 50000/60000 Training loss: 0.053946
Training loss: 0.057249
Test loss: 0.025739; Test accuracy: 9908/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.059270
Epoch: 4 10000/60000 Training loss: 0.059744
Epoch: 4 20000/60000 Training loss: 0.042986
Epoch: 4 30000/60000 Training loss: 0.033066
Epoch: 4 40000/60000 Training loss: 0.019835
Epoch: 4 50000/60000 Training loss: 0.030339
Training loss: 0.046570
Test loss: 0.024253; Test accuracy: 9907/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.068264
Epoch: 5 10000/60000 Training loss: 0.032855
Epoch: 5 20000/60000 Training loss: 0.042608
Epoch: 5 30000/60000 Training loss: 0.002395
Epoch: 5 40000/60000 Training loss: 0.034057
Epoch: 5 50000/60000 Training loss: 0.021206
Training loss: 0.041383
Test loss: 0.023942; Test accuracy: 9921/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.042936
Epoch: 6 10000/60000 Training loss: 0.064338
Epoch: 6 20000/60000 Training loss: 0.010885
Epoch: 6 30000/60000 Training loss: 0.015303
Epoch: 6 40000/60000 Training loss: 0.008986
Epoch: 6 50000/60000 Training loss: 0.030832
Training loss: 0.037717
Test loss: 0.023866; Test accuracy: 9919/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.010953
Epoch: 7 10000/60000 Training loss: 0.018145
Epoch: 7 20000/60000 Training loss: 0.009611
Epoch: 7 30000/60000 Training loss: 0.080580
Epoch: 7 40000/60000 Training loss: 0.014123
Epoch: 7 50000/60000 Training loss: 0.016444
Training loss: 0.033606
Test loss: 0.021223; Test accuracy: 9935/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.026511
Epoch: 8 10000/60000 Training loss: 0.011396
Epoch: 8 20000/60000 Training loss: 0.036926
Epoch: 8 30000/60000 Training loss: 0.015312
Epoch: 8 40000/60000 Training loss: 0.015597
Epoch: 8 50000/60000 Training loss: 0.010877
Training loss: 0.029765
Test loss: 0.019473; Test accuracy: 9938/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.022404
Epoch: 9 10000/60000 Training loss: 0.008588
Epoch: 9 20000/60000 Training loss: 0.037662
Epoch: 9 30000/60000 Training loss: 0.020460
Epoch: 9 40000/60000 Training loss: 0.084235
Epoch: 9 50000/60000 Training loss: 0.011873
Training loss: 0.026479
Test loss: 0.020209; Test accuracy: 9936/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.079747
Epoch: 10 10000/60000 Training loss: 0.003165
Epoch: 10 20000/60000 Training loss: 0.024958
Epoch: 10 30000/60000 Training loss: 0.012468
Epoch: 10 40000/60000 Training loss: 0.005478
Epoch: 10 50000/60000 Training loss: 0.002497
Training loss: 0.024448
Test loss: 0.018613; Test accuracy: 9935/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.022912
Epoch: 11 10000/60000 Training loss: 0.018391
Epoch: 11 20000/60000 Training loss: 0.028195
Epoch: 11 30000/60000 Training loss: 0.032894
Epoch: 11 40000/60000 Training loss: 0.006678
Epoch: 11 50000/60000 Training loss: 0.003243
Training loss: 0.022590
Test loss: 0.021586; Test accuracy: 9932/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.044818
Epoch: 12 10000/60000 Training loss: 0.001632
Epoch: 12 20000/60000 Training loss: 0.006457
Epoch: 12 30000/60000 Training loss: 0.043298
Epoch: 12 40000/60000 Training loss: 0.005068
Epoch: 12 50000/60000 Training loss: 0.046597
Training loss: 0.020432
Test loss: 0.018825; Test accuracy: 9941/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.036479
Epoch: 13 10000/60000 Training loss: 0.017005
Epoch: 13 20000/60000 Training loss: 0.005805
Epoch: 13 30000/60000 Training loss: 0.045967
Epoch: 13 40000/60000 Training loss: 0.001426
Epoch: 13 50000/60000 Training loss: 0.002082
Training loss: 0.018849
Test loss: 0.019013; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 02:43:32,599] Trial 44 finished with value: 0.018612679094076157 and parameters: {'num_conv1_channels': 48, 'num_conv2_channels': 64, 'conv2_drop': 0.15376431563053214, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0002657529132738181}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 32, 'num_conv2_channels': 96, 'conv2_drop': 0.17972994402967854, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.00011600059898485451}
Epoch: 0 0/60000 Training loss: 2.296690
Epoch: 0 10000/60000 Training loss: 0.820981
Epoch: 0 20000/60000 Training loss: 0.365820
Epoch: 0 30000/60000 Training loss: 0.381870
Epoch: 0 40000/60000 Training loss: 0.356093
Epoch: 0 50000/60000 Training loss: 0.194957
Training loss: 0.559662
Test loss: 0.121824; Test accuracy: 9632/10000 (96.3%)

Epoch: 1 0/60000 Training loss: 0.206646
Epoch: 1 10000/60000 Training loss: 0.234084
Epoch: 1 20000/60000 Training loss: 0.117031
Epoch: 1 30000/60000 Training loss: 0.170926
Epoch: 1 40000/60000 Training loss: 0.103455
Epoch: 1 50000/60000 Training loss: 0.127732
Training loss: 0.175931
Test loss: 0.075644; Test accuracy: 9760/10000 (97.6%)

Epoch: 2 0/60000 Training loss: 0.086749
Epoch: 2 10000/60000 Training loss: 0.121692
Epoch: 2 20000/60000 Training loss: 0.052287
Epoch: 2 30000/60000 Training loss: 0.112417
Epoch: 2 40000/60000 Training loss: 0.099427
Epoch: 2 50000/60000 Training loss: 0.105813
Training loss: 0.121990
Test loss: 0.055355; Test accuracy: 9825/10000 (98.2%)

Epoch: 3 0/60000 Training loss: 0.085843
Epoch: 3 10000/60000 Training loss: 0.196291
Epoch: 3 20000/60000 Training loss: 0.150899
Epoch: 3 30000/60000 Training loss: 0.098014
Epoch: 3 40000/60000 Training loss: 0.091356
Epoch: 3 50000/60000 Training loss: 0.090263
Training loss: 0.098645
Test loss: 0.044596; Test accuracy: 9866/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.105392
Epoch: 4 10000/60000 Training loss: 0.104469
Epoch: 4 20000/60000 Training loss: 0.135729
Epoch: 4 30000/60000 Training loss: 0.109159
Epoch: 4 40000/60000 Training loss: 0.115477
Epoch: 4 50000/60000 Training loss: 0.091235
Training loss: 0.087065
Test loss: 0.039609; Test accuracy: 9872/10000 (98.7%)

Epoch: 5 0/60000 Training loss: 0.070274
Epoch: 5 10000/60000 Training loss: 0.087145
Epoch: 5 20000/60000 Training loss: 0.130625
Epoch: 5 30000/60000 Training loss: 0.024229
Epoch: 5 40000/60000 Training loss: 0.063784
Epoch: 5 50000/60000 Training loss: 0.083676
Training loss: 0.074534
Test loss: 0.034966; Test accuracy: 9871/10000 (98.7%)

Epoch: 6 0/60000 Training loss: 0.063198
Epoch: 6 10000/60000 Training loss: 0.203541
Epoch: 6 20000/60000 Training loss: 0.171125
Epoch: 6 30000/60000 Training loss: 0.063877
Epoch: 6 40000/60000 Training loss: 0.070897
Epoch: 6 50000/60000 Training loss: 0.118654
Training loss: 0.066313
Test loss: 0.033543; Test accuracy: 9895/10000 (98.9%)

Epoch: 7 0/60000 Training loss: 0.037535
Epoch: 7 10000/60000 Training loss: 0.048113
Epoch: 7 20000/60000 Training loss: 0.117116
Epoch: 7 30000/60000 Training loss: 0.049675
Epoch: 7 40000/60000 Training loss: 0.074830
Epoch: 7 50000/60000 Training loss: 0.008897
Training loss: 0.060554
Test loss: 0.030117; Test accuracy: 9893/10000 (98.9%)

Epoch: 8 0/60000 Training loss: 0.052204
Epoch: 8 10000/60000 Training loss: 0.038914
Epoch: 8 20000/60000 Training loss: 0.033635
Epoch: 8 30000/60000 Training loss: 0.016517
Epoch: 8 40000/60000 Training loss: 0.026451
Epoch: 8 50000/60000 Training loss: 0.051086
Training loss: 0.055265
Test loss: 0.029928; Test accuracy: 9902/10000 (99.0%)

Epoch: 9 0/60000 Training loss: 0.051116
Epoch: 9 10000/60000 Training loss: 0.049768
Epoch: 9 20000/60000 Training loss: 0.085350
Epoch: 9 30000/60000 Training loss: 0.019713
Epoch: 9 40000/60000 Training loss: 0.131096
Epoch: 9 50000/60000 Training loss: 0.030690
Training loss: 0.051246
Test loss: 0.027558; Test accuracy: 9909/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.059775
Epoch: 10 10000/60000 Training loss: 0.091124
Epoch: 10 20000/60000 Training loss: 0.060994
Epoch: 10 30000/60000 Training loss: 0.068733
Epoch: 10 40000/60000 Training loss: 0.024885
Epoch: 10 50000/60000 Training loss: 0.007960
Training loss: 0.047508
Test loss: 0.025930; Test accuracy: 9914/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.053932
Epoch: 11 10000/60000 Training loss: 0.012382
Epoch: 11 20000/60000 Training loss: 0.051210
Epoch: 11 30000/60000 Training loss: 0.024070
Epoch: 11 40000/60000 Training loss: 0.018984
Epoch: 11 50000/60000 Training loss: 0.095755
Training loss: 0.043611
Test loss: 0.023814; Test accuracy: 9921/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.039687
Epoch: 12 10000/60000 Training loss: 0.010526
Epoch: 12 20000/60000 Training loss: 0.042020
Epoch: 12 30000/60000 Training loss: 0.014005
Epoch: 12 40000/60000 Training loss: 0.039590
Epoch: 12 50000/60000 Training loss: 0.044773
Training loss: 0.041593
Test loss: 0.024947; Test accuracy: 9920/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.039639
Epoch: 13 10000/60000 Training loss: 0.014628
Epoch: 13 20000/60000 Training loss: 0.028715
Epoch: 13 30000/60000 Training loss: 0.037908
Epoch: 13 40000/60000 Training loss: 0.059519
Epoch: 13 50000/60000 Training loss: 0.037172
Training loss: 0.037963
Test loss: 0.023399; Test accuracy: 9925/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.058686
Epoch: 14 10000/60000 Training loss: 0.010131
Epoch: 14 20000/60000 Training loss: 0.033008
Epoch: 14 30000/60000 Training loss: 0.046379
Epoch: 14 40000/60000 Training loss: 0.015866
Epoch: 14 50000/60000 Training loss: 0.045613
Training loss: 0.035546
Test loss: 0.022286; Test accuracy: 9924/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.043281
Epoch: 15 10000/60000 Training loss: 0.004639
Epoch: 15 20000/60000 Training loss: 0.023137
Epoch: 15 30000/60000 Training loss: 0.039028
Epoch: 15 40000/60000 Training loss: 0.018038
Epoch: 15 50000/60000 Training loss: 0.050485
Training loss: 0.034434
Test loss: 0.023038; Test accuracy: 9929/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.007514
Epoch: 16 10000/60000 Training loss: 0.015181
Epoch: 16 20000/60000 Training loss: 0.041883
Epoch: 16 30000/60000 Training loss: 0.035171
Epoch: 16 40000/60000 Training loss: 0.022341
Epoch: 16 50000/60000 Training loss: 0.046350
Training loss: 0.032692
Test loss: 0.023467; Test accuracy: 9927/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.050520
Epoch: 17 10000/60000 Training loss: 0.066093
Epoch: 17 20000/60000 Training loss: 0.018221
Epoch: 17 30000/60000 Training loss: 0.021376
Epoch: 17 40000/60000 Training loss: 0.004878
Epoch: 17 50000/60000 Training loss: 0.016728
Training loss: 0.028749
Test loss: 0.021866; Test accuracy: 9933/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.064676
Epoch: 18 10000/60000 Training loss: 0.038621
Epoch: 18 20000/60000 Training loss: 0.032809
Epoch: 18 30000/60000 Training loss: 0.016932
Epoch: 18 40000/60000 Training loss: 0.034382
Epoch: 18 50000/60000 Training loss: 0.107511
Training loss: 0.029136
Test loss: 0.020498; Test accuracy: 9937/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.037241
Epoch: 19 10000/60000 Training loss: 0.021656
Epoch: 19 20000/60000 Training loss: 0.012399
Epoch: 19 30000/60000 Training loss: 0.011493
Epoch: 19 40000/60000 Training loss: 0.097844
Epoch: 19 50000/60000 Training loss: 0.009003
Training loss: 0.026041
Test loss: 0.021308; Test accuracy: 9924/10000 (99.2%)

[I 2022-11-04 02:48:10,637] Trial 45 finished with value: 0.02049810066819191 and parameters: {'num_conv1_channels': 32, 'num_conv2_channels': 96, 'conv2_drop': 0.17972994402967854, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.00011600059898485451}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 48, 'conv2_drop': 0.1905032366984544, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.000355749529398081}
Epoch: 0 0/60000 Training loss: 2.312762
Epoch: 0 10000/60000 Training loss: 0.303605
Epoch: 0 20000/60000 Training loss: 0.165757
Epoch: 0 30000/60000 Training loss: 0.067134
Epoch: 0 40000/60000 Training loss: 0.153042
Epoch: 0 50000/60000 Training loss: 0.117314
Training loss: 0.309865
Test loss: 0.065518; Test accuracy: 9797/10000 (98.0%)

Epoch: 1 0/60000 Training loss: 0.135336
Epoch: 1 10000/60000 Training loss: 0.150176
Epoch: 1 20000/60000 Training loss: 0.162152
Epoch: 1 30000/60000 Training loss: 0.154397
Epoch: 1 40000/60000 Training loss: 0.110023
Epoch: 1 50000/60000 Training loss: 0.059327
Training loss: 0.096842
Test loss: 0.041489; Test accuracy: 9860/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.076843
Epoch: 2 10000/60000 Training loss: 0.092308
Epoch: 2 20000/60000 Training loss: 0.040716
Epoch: 2 30000/60000 Training loss: 0.076982
Epoch: 2 40000/60000 Training loss: 0.047260
Epoch: 2 50000/60000 Training loss: 0.140757
Training loss: 0.071795
Test loss: 0.034635; Test accuracy: 9892/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.097559
Epoch: 3 10000/60000 Training loss: 0.034068
Epoch: 3 20000/60000 Training loss: 0.086270
Epoch: 3 30000/60000 Training loss: 0.018101
Epoch: 3 40000/60000 Training loss: 0.040225
Epoch: 3 50000/60000 Training loss: 0.102970
Training loss: 0.057766
Test loss: 0.027024; Test accuracy: 9907/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.067390
Epoch: 4 10000/60000 Training loss: 0.027368
Epoch: 4 20000/60000 Training loss: 0.006031
Epoch: 4 30000/60000 Training loss: 0.151844
Epoch: 4 40000/60000 Training loss: 0.061604
Epoch: 4 50000/60000 Training loss: 0.034984
Training loss: 0.048820
Test loss: 0.024057; Test accuracy: 9911/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.024616
Epoch: 5 10000/60000 Training loss: 0.034692
Epoch: 5 20000/60000 Training loss: 0.134622
Epoch: 5 30000/60000 Training loss: 0.020308
Epoch: 5 40000/60000 Training loss: 0.016804
Epoch: 5 50000/60000 Training loss: 0.032872
Training loss: 0.044992
Test loss: 0.021695; Test accuracy: 9927/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.005361
Epoch: 6 10000/60000 Training loss: 0.069598
Epoch: 6 20000/60000 Training loss: 0.020553
Epoch: 6 30000/60000 Training loss: 0.020782
Epoch: 6 40000/60000 Training loss: 0.029215
Epoch: 6 50000/60000 Training loss: 0.025080
Training loss: 0.039964
Test loss: 0.022059; Test accuracy: 9922/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.035949
Epoch: 7 10000/60000 Training loss: 0.008270
Epoch: 7 20000/60000 Training loss: 0.008449
Epoch: 7 30000/60000 Training loss: 0.019232
Epoch: 7 40000/60000 Training loss: 0.031041
Epoch: 7 50000/60000 Training loss: 0.026448
Training loss: 0.033906
Test loss: 0.021414; Test accuracy: 9931/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.031980
Epoch: 8 10000/60000 Training loss: 0.024713
Epoch: 8 20000/60000 Training loss: 0.030826
Epoch: 8 30000/60000 Training loss: 0.047772
Epoch: 8 40000/60000 Training loss: 0.022937
Epoch: 8 50000/60000 Training loss: 0.021409
Training loss: 0.031066
Test loss: 0.019671; Test accuracy: 9938/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.084113
Epoch: 9 10000/60000 Training loss: 0.001080
Epoch: 9 20000/60000 Training loss: 0.053466
Epoch: 9 30000/60000 Training loss: 0.031008
Epoch: 9 40000/60000 Training loss: 0.012179
Epoch: 9 50000/60000 Training loss: 0.018875
Training loss: 0.030744
Test loss: 0.018167; Test accuracy: 9941/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.044134
Epoch: 10 10000/60000 Training loss: 0.009972
Epoch: 10 20000/60000 Training loss: 0.018390
Epoch: 10 30000/60000 Training loss: 0.036344
Epoch: 10 40000/60000 Training loss: 0.010913
Epoch: 10 50000/60000 Training loss: 0.010648
Training loss: 0.025857
Test loss: 0.023571; Test accuracy: 9932/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.152184
Epoch: 11 10000/60000 Training loss: 0.057245
Epoch: 11 20000/60000 Training loss: 0.036303
Epoch: 11 30000/60000 Training loss: 0.007942
Epoch: 11 40000/60000 Training loss: 0.002486
Epoch: 11 50000/60000 Training loss: 0.075451
Training loss: 0.025003
Test loss: 0.020487; Test accuracy: 9930/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.021173
Epoch: 12 10000/60000 Training loss: 0.018209
Epoch: 12 20000/60000 Training loss: 0.004611
Epoch: 12 30000/60000 Training loss: 0.008213
Epoch: 12 40000/60000 Training loss: 0.013571
Epoch: 12 50000/60000 Training loss: 0.008870
Training loss: 0.024331
Test loss: 0.020930; Test accuracy: 9929/10000 (99.3%)

[I 2022-11-04 02:51:13,066] Trial 46 finished with value: 0.018167272210121155 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 48, 'conv2_drop': 0.1905032366984544, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.000355749529398081}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 128, 'conv2_drop': 0.15119115006201123, 'fc1_neurons': 80, 'optimizer': 'SGD', 'learning_rate': 0.00015567861757720497}
Epoch: 0 0/60000 Training loss: 2.316078
Epoch: 0 10000/60000 Training loss: 2.301021
Epoch: 0 20000/60000 Training loss: 2.284044
Epoch: 0 30000/60000 Training loss: 2.265629
Epoch: 0 40000/60000 Training loss: 2.282363
Epoch: 0 50000/60000 Training loss: 2.276787
Training loss: 2.289147
Test loss: 2.258034; Test accuracy: 2094/10000 (20.9%)

Epoch: 1 0/60000 Training loss: 2.266740
Epoch: 1 10000/60000 Training loss: 2.241904
Epoch: 1 20000/60000 Training loss: 2.237482
Epoch: 1 30000/60000 Training loss: 2.221711
Epoch: 1 40000/60000 Training loss: 2.228901
Epoch: 1 50000/60000 Training loss: 2.229542
Training loss: 2.241907
Test loss: 2.205332; Test accuracy: 4024/10000 (40.2%)

Epoch: 2 0/60000 Training loss: 2.227864
Epoch: 2 10000/60000 Training loss: 2.234992
Epoch: 2 20000/60000 Training loss: 2.149420
Epoch: 2 30000/60000 Training loss: 2.188153
Epoch: 2 40000/60000 Training loss: 2.183165
Epoch: 2 50000/60000 Training loss: 2.169098
Training loss: 2.189955
Test loss: 2.140695; Test accuracy: 5835/10000 (58.3%)

Epoch: 3 0/60000 Training loss: 2.175709
Epoch: 3 10000/60000 Training loss: 2.158179
Epoch: 3 20000/60000 Training loss: 2.135793
Epoch: 3 30000/60000 Training loss: 2.149528
Epoch: 3 40000/60000 Training loss: 2.109101
Epoch: 3 50000/60000 Training loss: 2.113625
Training loss: 2.125881
Test loss: 2.060988; Test accuracy: 6580/10000 (65.8%)

Epoch: 4 0/60000 Training loss: 2.097677
Epoch: 4 10000/60000 Training loss: 2.046611
Epoch: 4 20000/60000 Training loss: 2.079342
Epoch: 4 30000/60000 Training loss: 2.056678
Epoch: 4 40000/60000 Training loss: 2.038005
Epoch: 4 50000/60000 Training loss: 2.033145
Training loss: 2.046332
Test loss: 1.960386; Test accuracy: 7023/10000 (70.2%)

Epoch: 5 0/60000 Training loss: 2.003317
Epoch: 5 10000/60000 Training loss: 1.939172
Epoch: 5 20000/60000 Training loss: 1.963743
Epoch: 5 30000/60000 Training loss: 1.928017
Epoch: 5 40000/60000 Training loss: 1.980483
Epoch: 5 50000/60000 Training loss: 1.923494
Training loss: 1.950329
Test loss: 1.838436; Test accuracy: 7380/10000 (73.8%)

Epoch: 6 0/60000 Training loss: 1.893356
Epoch: 6 10000/60000 Training loss: 1.937779
Epoch: 6 20000/60000 Training loss: 1.844150
Epoch: 6 30000/60000 Training loss: 1.856253
Epoch: 6 40000/60000 Training loss: 1.854219
Epoch: 6 50000/60000 Training loss: 1.769265
Training loss: 1.834189
Test loss: 1.692340; Test accuracy: 7656/10000 (76.6%)

Epoch: 7 0/60000 Training loss: 1.714355
Epoch: 7 10000/60000 Training loss: 1.750854
Epoch: 7 20000/60000 Training loss: 1.749401
Epoch: 7 30000/60000 Training loss: 1.649891
Epoch: 7 40000/60000 Training loss: 1.710013
Epoch: 7 50000/60000 Training loss: 1.649553
Training loss: 1.706954
Test loss: 1.528926; Test accuracy: 7909/10000 (79.1%)

Epoch: 8 0/60000 Training loss: 1.533275
Epoch: 8 10000/60000 Training loss: 1.668234
Epoch: 8 20000/60000 Training loss: 1.524942
Epoch: 8 30000/60000 Training loss: 1.616379
Epoch: 8 40000/60000 Training loss: 1.554630
Epoch: 8 50000/60000 Training loss: 1.544133
Training loss: 1.568706
Test loss: 1.362074; Test accuracy: 8143/10000 (81.4%)

Epoch: 9 0/60000 Training loss: 1.433856
Epoch: 9 10000/60000 Training loss: 1.443343
Epoch: 9 20000/60000 Training loss: 1.435524
Epoch: 9 30000/60000 Training loss: 1.452456
Epoch: 9 40000/60000 Training loss: 1.551077
Epoch: 9 50000/60000 Training loss: 1.359751
Training loss: 1.435101
Test loss: 1.204867; Test accuracy: 8317/10000 (83.2%)

Epoch: 10 0/60000 Training loss: 1.316580
Epoch: 10 10000/60000 Training loss: 1.301976
Epoch: 10 20000/60000 Training loss: 1.371517
Epoch: 10 30000/60000 Training loss: 1.391480
Epoch: 10 40000/60000 Training loss: 1.324659
Epoch: 10 50000/60000 Training loss: 1.269536
Training loss: 1.311410
Test loss: 1.062388; Test accuracy: 8422/10000 (84.2%)

Epoch: 11 0/60000 Training loss: 1.323271
Epoch: 11 10000/60000 Training loss: 1.208150
Epoch: 11 20000/60000 Training loss: 1.321440
Epoch: 11 30000/60000 Training loss: 1.159141
Epoch: 11 40000/60000 Training loss: 1.232158
Epoch: 11 50000/60000 Training loss: 1.050167
Training loss: 1.198453
Test loss: 0.937729; Test accuracy: 8556/10000 (85.6%)

Epoch: 12 0/60000 Training loss: 1.161788
Epoch: 12 10000/60000 Training loss: 1.121178
Epoch: 12 20000/60000 Training loss: 1.091919
Epoch: 12 30000/60000 Training loss: 1.067012
Epoch: 12 40000/60000 Training loss: 1.274186
Epoch: 12 50000/60000 Training loss: 1.072483
Training loss: 1.105167
Test loss: 0.833969; Test accuracy: 8658/10000 (86.6%)

Epoch: 13 0/60000 Training loss: 1.070286
Epoch: 13 10000/60000 Training loss: 1.131292
Epoch: 13 20000/60000 Training loss: 1.162932
Epoch: 13 30000/60000 Training loss: 0.999786
Epoch: 13 40000/60000 Training loss: 0.970145
Epoch: 13 50000/60000 Training loss: 0.841486
Training loss: 1.018690
Test loss: 0.747540; Test accuracy: 8722/10000 (87.2%)

Epoch: 14 0/60000 Training loss: 0.989216
Epoch: 14 10000/60000 Training loss: 0.846545
Epoch: 14 20000/60000 Training loss: 0.832903
Epoch: 14 30000/60000 Training loss: 1.008442
Epoch: 14 40000/60000 Training loss: 0.923542
Epoch: 14 50000/60000 Training loss: 0.832372
Training loss: 0.949500
Test loss: 0.675526; Test accuracy: 8789/10000 (87.9%)

Epoch: 15 0/60000 Training loss: 0.861309
Epoch: 15 10000/60000 Training loss: 0.802031
Epoch: 15 20000/60000 Training loss: 0.910941
Epoch: 15 30000/60000 Training loss: 0.994470
Epoch: 15 40000/60000 Training loss: 0.972651
Epoch: 15 50000/60000 Training loss: 0.905991
Training loss: 0.884356
Test loss: 0.616629; Test accuracy: 8840/10000 (88.4%)

Epoch: 16 0/60000 Training loss: 0.894110
Epoch: 16 10000/60000 Training loss: 0.766382
Epoch: 16 20000/60000 Training loss: 0.812003
Epoch: 16 30000/60000 Training loss: 0.784286
Epoch: 16 40000/60000 Training loss: 0.765095
Epoch: 16 50000/60000 Training loss: 0.772135
Training loss: 0.836655
Test loss: 0.569831; Test accuracy: 8905/10000 (89.0%)

Epoch: 17 0/60000 Training loss: 0.828028
Epoch: 17 10000/60000 Training loss: 0.749267
Epoch: 17 20000/60000 Training loss: 0.738372
Epoch: 17 30000/60000 Training loss: 0.703646
Epoch: 17 40000/60000 Training loss: 0.717231
Epoch: 17 50000/60000 Training loss: 0.665017
Training loss: 0.791868
Test loss: 0.527736; Test accuracy: 8943/10000 (89.4%)

Epoch: 18 0/60000 Training loss: 0.812253
Epoch: 18 10000/60000 Training loss: 0.727077
Epoch: 18 20000/60000 Training loss: 0.766431
Epoch: 18 30000/60000 Training loss: 0.681683
Epoch: 18 40000/60000 Training loss: 0.913095
Epoch: 18 50000/60000 Training loss: 0.774172
Training loss: 0.750718
Test loss: 0.494072; Test accuracy: 8971/10000 (89.7%)

Epoch: 19 0/60000 Training loss: 0.816616
Epoch: 19 10000/60000 Training loss: 0.560094
Epoch: 19 20000/60000 Training loss: 0.705297
Epoch: 19 30000/60000 Training loss: 0.616840
Epoch: 19 40000/60000 Training loss: 0.706585
Epoch: 19 50000/60000 Training loss: 0.623744
Training loss: 0.716551
Test loss: 0.464303; Test accuracy: 9020/10000 (90.2%)

[I 2022-11-04 02:55:51,949] Trial 47 finished with value: 0.4643031656742096 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 128, 'conv2_drop': 0.15119115006201123, 'fc1_neurons': 80, 'optimizer': 'SGD', 'learning_rate': 0.00015567861757720497}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.13509851100032705, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00010796646921616633}
Epoch: 0 0/60000 Training loss: 2.286717
Epoch: 0 10000/60000 Training loss: 0.607221
Epoch: 0 20000/60000 Training loss: 0.345401
Epoch: 0 30000/60000 Training loss: 0.198930
Epoch: 0 40000/60000 Training loss: 0.290805
Epoch: 0 50000/60000 Training loss: 0.302009
Training loss: 0.442699
Test loss: 0.099473; Test accuracy: 9684/10000 (96.8%)

Epoch: 1 0/60000 Training loss: 0.248637
Epoch: 1 10000/60000 Training loss: 0.084822
Epoch: 1 20000/60000 Training loss: 0.097904
Epoch: 1 30000/60000 Training loss: 0.128412
Epoch: 1 40000/60000 Training loss: 0.176786
Epoch: 1 50000/60000 Training loss: 0.070603
Training loss: 0.136358
Test loss: 0.061497; Test accuracy: 9809/10000 (98.1%)

Epoch: 2 0/60000 Training loss: 0.047801
Epoch: 2 10000/60000 Training loss: 0.089700
Epoch: 2 20000/60000 Training loss: 0.111077
Epoch: 2 30000/60000 Training loss: 0.064594
Epoch: 2 40000/60000 Training loss: 0.076128
Epoch: 2 50000/60000 Training loss: 0.174672
Training loss: 0.095745
Test loss: 0.046226; Test accuracy: 9844/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.060345
Epoch: 3 10000/60000 Training loss: 0.037012
Epoch: 3 20000/60000 Training loss: 0.092756
Epoch: 3 30000/60000 Training loss: 0.060344
Epoch: 3 40000/60000 Training loss: 0.091081
Epoch: 3 50000/60000 Training loss: 0.067209
Training loss: 0.077342
Test loss: 0.038840; Test accuracy: 9873/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.040835
Epoch: 4 10000/60000 Training loss: 0.081395
Epoch: 4 20000/60000 Training loss: 0.074710
Epoch: 4 30000/60000 Training loss: 0.115854
Epoch: 4 40000/60000 Training loss: 0.042607
Epoch: 4 50000/60000 Training loss: 0.072160
Training loss: 0.063907
Test loss: 0.035578; Test accuracy: 9897/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.139944
Epoch: 5 10000/60000 Training loss: 0.066107
Epoch: 5 20000/60000 Training loss: 0.076877
Epoch: 5 30000/60000 Training loss: 0.158390
Epoch: 5 40000/60000 Training loss: 0.057497
Epoch: 5 50000/60000 Training loss: 0.067199
Training loss: 0.055725
Test loss: 0.031114; Test accuracy: 9892/10000 (98.9%)

Epoch: 6 0/60000 Training loss: 0.041040
Epoch: 6 10000/60000 Training loss: 0.006093
Epoch: 6 20000/60000 Training loss: 0.068141
Epoch: 6 30000/60000 Training loss: 0.021162
Epoch: 6 40000/60000 Training loss: 0.034520
Epoch: 6 50000/60000 Training loss: 0.063193
Training loss: 0.048065
Test loss: 0.028965; Test accuracy: 9905/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.053461
Epoch: 7 10000/60000 Training loss: 0.052110
Epoch: 7 20000/60000 Training loss: 0.040051
Epoch: 7 30000/60000 Training loss: 0.049013
Epoch: 7 40000/60000 Training loss: 0.072038
Epoch: 7 50000/60000 Training loss: 0.075548
Training loss: 0.042925
Test loss: 0.024460; Test accuracy: 9920/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.054265
Epoch: 8 10000/60000 Training loss: 0.097473
Epoch: 8 20000/60000 Training loss: 0.064456
Epoch: 8 30000/60000 Training loss: 0.054032
Epoch: 8 40000/60000 Training loss: 0.011610
Epoch: 8 50000/60000 Training loss: 0.053533
Training loss: 0.038572
Test loss: 0.025179; Test accuracy: 9903/10000 (99.0%)

Epoch: 9 0/60000 Training loss: 0.010277
Epoch: 9 10000/60000 Training loss: 0.034439
Epoch: 9 20000/60000 Training loss: 0.053961
Epoch: 9 30000/60000 Training loss: 0.009969
Epoch: 9 40000/60000 Training loss: 0.040825
Epoch: 9 50000/60000 Training loss: 0.036085
Training loss: 0.035660
Test loss: 0.024591; Test accuracy: 9917/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.043817
Epoch: 10 10000/60000 Training loss: 0.028320
Epoch: 10 20000/60000 Training loss: 0.045771
Epoch: 10 30000/60000 Training loss: 0.045299
Epoch: 10 40000/60000 Training loss: 0.026540
Epoch: 10 50000/60000 Training loss: 0.108044
Training loss: 0.033920
Test loss: 0.022026; Test accuracy: 9931/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.103904
Epoch: 11 10000/60000 Training loss: 0.016739
Epoch: 11 20000/60000 Training loss: 0.006439
Epoch: 11 30000/60000 Training loss: 0.018761
Epoch: 11 40000/60000 Training loss: 0.005287
Epoch: 11 50000/60000 Training loss: 0.012815
Training loss: 0.029211
Test loss: 0.022043; Test accuracy: 9921/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.022820
Epoch: 12 10000/60000 Training loss: 0.018622
Epoch: 12 20000/60000 Training loss: 0.006736
Epoch: 12 30000/60000 Training loss: 0.007004
Epoch: 12 40000/60000 Training loss: 0.044367
Epoch: 12 50000/60000 Training loss: 0.011826
Training loss: 0.028054
Test loss: 0.022681; Test accuracy: 9925/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.016711
Epoch: 13 10000/60000 Training loss: 0.010527
Epoch: 13 20000/60000 Training loss: 0.024165
Epoch: 13 30000/60000 Training loss: 0.015757
Epoch: 13 40000/60000 Training loss: 0.005245
Epoch: 13 50000/60000 Training loss: 0.009163
Training loss: 0.026036
Test loss: 0.022094; Test accuracy: 9922/10000 (99.2%)

[I 2022-11-04 02:59:07,527] Trial 48 finished with value: 0.02202610857784748 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.13509851100032705, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00010796646921616633}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.1660647729714996, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 7.538858506995618e-05}
Epoch: 0 0/60000 Training loss: 2.315590
Epoch: 0 10000/60000 Training loss: 0.818646
Epoch: 0 20000/60000 Training loss: 0.522827
Epoch: 0 30000/60000 Training loss: 0.279973
Epoch: 0 40000/60000 Training loss: 0.322439
Epoch: 0 50000/60000 Training loss: 0.344389
Training loss: 0.520656
Test loss: 0.111609; Test accuracy: 9660/10000 (96.6%)

Epoch: 1 0/60000 Training loss: 0.179087
Epoch: 1 10000/60000 Training loss: 0.171635
Epoch: 1 20000/60000 Training loss: 0.088710
Epoch: 1 30000/60000 Training loss: 0.186166
Epoch: 1 40000/60000 Training loss: 0.124703
Epoch: 1 50000/60000 Training loss: 0.144505
Training loss: 0.158501
Test loss: 0.066828; Test accuracy: 9795/10000 (97.9%)

Epoch: 2 0/60000 Training loss: 0.085072
Epoch: 2 10000/60000 Training loss: 0.128410
Epoch: 2 20000/60000 Training loss: 0.056626
Epoch: 2 30000/60000 Training loss: 0.049392
Epoch: 2 40000/60000 Training loss: 0.090127
Epoch: 2 50000/60000 Training loss: 0.107470
Training loss: 0.114277
Test loss: 0.049799; Test accuracy: 9844/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.042205
Epoch: 3 10000/60000 Training loss: 0.100933
Epoch: 3 20000/60000 Training loss: 0.064343
Epoch: 3 30000/60000 Training loss: 0.092662
Epoch: 3 40000/60000 Training loss: 0.092337
Epoch: 3 50000/60000 Training loss: 0.042565
Training loss: 0.089856
Test loss: 0.040654; Test accuracy: 9867/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.090623
Epoch: 4 10000/60000 Training loss: 0.032035
Epoch: 4 20000/60000 Training loss: 0.068259
Epoch: 4 30000/60000 Training loss: 0.036411
Epoch: 4 40000/60000 Training loss: 0.051071
Epoch: 4 50000/60000 Training loss: 0.011886
Training loss: 0.075769
Test loss: 0.033308; Test accuracy: 9891/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.046068
Epoch: 5 10000/60000 Training loss: 0.038024
Epoch: 5 20000/60000 Training loss: 0.064017
Epoch: 5 30000/60000 Training loss: 0.055065
Epoch: 5 40000/60000 Training loss: 0.121409
Epoch: 5 50000/60000 Training loss: 0.041303
Training loss: 0.065986
Test loss: 0.031586; Test accuracy: 9900/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.033709
Epoch: 6 10000/60000 Training loss: 0.059918
Epoch: 6 20000/60000 Training loss: 0.026387
Epoch: 6 30000/60000 Training loss: 0.028340
Epoch: 6 40000/60000 Training loss: 0.043965
Epoch: 6 50000/60000 Training loss: 0.128502
Training loss: 0.058491
Test loss: 0.027471; Test accuracy: 9906/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.037202
Epoch: 7 10000/60000 Training loss: 0.012829
Epoch: 7 20000/60000 Training loss: 0.030042
Epoch: 7 30000/60000 Training loss: 0.043611
Epoch: 7 40000/60000 Training loss: 0.085051
Epoch: 7 50000/60000 Training loss: 0.016072
Training loss: 0.053131
Test loss: 0.027684; Test accuracy: 9912/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.030759
Epoch: 8 10000/60000 Training loss: 0.063498
Epoch: 8 20000/60000 Training loss: 0.056200
Epoch: 8 30000/60000 Training loss: 0.041808
Epoch: 8 40000/60000 Training loss: 0.118467
Epoch: 8 50000/60000 Training loss: 0.016111
Training loss: 0.048817
Test loss: 0.025903; Test accuracy: 9910/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.043175
Epoch: 9 10000/60000 Training loss: 0.008453
Epoch: 9 20000/60000 Training loss: 0.034722
Epoch: 9 30000/60000 Training loss: 0.028247
Epoch: 9 40000/60000 Training loss: 0.013252
Epoch: 9 50000/60000 Training loss: 0.034962
Training loss: 0.046537
Test loss: 0.024816; Test accuracy: 9910/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.068636
Epoch: 10 10000/60000 Training loss: 0.064295
Epoch: 10 20000/60000 Training loss: 0.076579
Epoch: 10 30000/60000 Training loss: 0.073175
Epoch: 10 40000/60000 Training loss: 0.009254
Epoch: 10 50000/60000 Training loss: 0.053749
Training loss: 0.040794
Test loss: 0.023119; Test accuracy: 9914/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.084784
Epoch: 11 10000/60000 Training loss: 0.060196
Epoch: 11 20000/60000 Training loss: 0.029214
Epoch: 11 30000/60000 Training loss: 0.018214
Epoch: 11 40000/60000 Training loss: 0.022053
Epoch: 11 50000/60000 Training loss: 0.026859
Training loss: 0.038465
Test loss: 0.023193; Test accuracy: 9920/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.017652
Epoch: 12 10000/60000 Training loss: 0.032766
Epoch: 12 20000/60000 Training loss: 0.025247
Epoch: 12 30000/60000 Training loss: 0.021208
Epoch: 12 40000/60000 Training loss: 0.041833
Epoch: 12 50000/60000 Training loss: 0.015189
Training loss: 0.033656
Test loss: 0.021481; Test accuracy: 9931/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.024670
Epoch: 13 10000/60000 Training loss: 0.016425
Epoch: 13 20000/60000 Training loss: 0.043124
Epoch: 13 30000/60000 Training loss: 0.049527
Epoch: 13 40000/60000 Training loss: 0.010940
Epoch: 13 50000/60000 Training loss: 0.006061
Training loss: 0.032212
Test loss: 0.022158; Test accuracy: 9921/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.026096
Epoch: 14 10000/60000 Training loss: 0.128904
Epoch: 14 20000/60000 Training loss: 0.083265
Epoch: 14 30000/60000 Training loss: 0.022460
Epoch: 14 40000/60000 Training loss: 0.013003
Epoch: 14 50000/60000 Training loss: 0.008635
Training loss: 0.031631
Test loss: 0.019919; Test accuracy: 9935/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.043173
Epoch: 15 10000/60000 Training loss: 0.018727
Epoch: 15 20000/60000 Training loss: 0.144633
Epoch: 15 30000/60000 Training loss: 0.059041
Epoch: 15 40000/60000 Training loss: 0.018034
Epoch: 15 50000/60000 Training loss: 0.087181
Training loss: 0.028625
Test loss: 0.020010; Test accuracy: 9935/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.019300
Epoch: 16 10000/60000 Training loss: 0.011658
Epoch: 16 20000/60000 Training loss: 0.011137
Epoch: 16 30000/60000 Training loss: 0.024661
Epoch: 16 40000/60000 Training loss: 0.024235
Epoch: 16 50000/60000 Training loss: 0.032806
Training loss: 0.027075
Test loss: 0.018482; Test accuracy: 9940/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.007058
Epoch: 17 10000/60000 Training loss: 0.007176
Epoch: 17 20000/60000 Training loss: 0.002856
Epoch: 17 30000/60000 Training loss: 0.067482
Epoch: 17 40000/60000 Training loss: 0.003005
Epoch: 17 50000/60000 Training loss: 0.105584
Training loss: 0.026074
Test loss: 0.018021; Test accuracy: 9934/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.014654
Epoch: 18 10000/60000 Training loss: 0.010639
Epoch: 18 20000/60000 Training loss: 0.004648
Epoch: 18 30000/60000 Training loss: 0.006251
Epoch: 18 40000/60000 Training loss: 0.009991
Epoch: 18 50000/60000 Training loss: 0.004086
Training loss: 0.023987
Test loss: 0.019076; Test accuracy: 9937/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.008776
Epoch: 19 10000/60000 Training loss: 0.063536
Epoch: 19 20000/60000 Training loss: 0.009762
Epoch: 19 30000/60000 Training loss: 0.005801
Epoch: 19 40000/60000 Training loss: 0.031858
Epoch: 19 50000/60000 Training loss: 0.034043
Training loss: 0.023769
Test loss: 0.019786; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 03:03:47,965] Trial 49 finished with value: 0.0180211178958416 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.1660647729714996, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 7.538858506995618e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16338969894879884, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 5.095841812903029e-05}
Epoch: 0 0/60000 Training loss: 2.328872
Epoch: 0 10000/60000 Training loss: 1.048200
Epoch: 0 20000/60000 Training loss: 0.673818
Epoch: 0 30000/60000 Training loss: 0.532248
Epoch: 0 40000/60000 Training loss: 0.330644
Epoch: 0 50000/60000 Training loss: 0.386044
Training loss: 0.718406
Test loss: 0.160314; Test accuracy: 9555/10000 (95.5%)

Epoch: 1 0/60000 Training loss: 0.316883
Epoch: 1 10000/60000 Training loss: 0.298707
Epoch: 1 20000/60000 Training loss: 0.344930
Epoch: 1 30000/60000 Training loss: 0.350277
Epoch: 1 40000/60000 Training loss: 0.166599
Epoch: 1 50000/60000 Training loss: 0.260922
Training loss: 0.247069
Test loss: 0.096641; Test accuracy: 9711/10000 (97.1%)

Epoch: 2 0/60000 Training loss: 0.217988
Epoch: 2 10000/60000 Training loss: 0.152948
Epoch: 2 20000/60000 Training loss: 0.197493
Epoch: 2 30000/60000 Training loss: 0.415548
Epoch: 2 40000/60000 Training loss: 0.064486
Epoch: 2 50000/60000 Training loss: 0.224069
Training loss: 0.174889
Test loss: 0.069682; Test accuracy: 9783/10000 (97.8%)

Epoch: 3 0/60000 Training loss: 0.166612
Epoch: 3 10000/60000 Training loss: 0.119389
Epoch: 3 20000/60000 Training loss: 0.083507
Epoch: 3 30000/60000 Training loss: 0.137188
Epoch: 3 40000/60000 Training loss: 0.045081
Epoch: 3 50000/60000 Training loss: 0.197767
Training loss: 0.141412
Test loss: 0.057836; Test accuracy: 9826/10000 (98.3%)

Epoch: 4 0/60000 Training loss: 0.085119
Epoch: 4 10000/60000 Training loss: 0.116779
Epoch: 4 20000/60000 Training loss: 0.105979
Epoch: 4 30000/60000 Training loss: 0.133834
Epoch: 4 40000/60000 Training loss: 0.200404
Epoch: 4 50000/60000 Training loss: 0.166101
Training loss: 0.120014
Test loss: 0.048154; Test accuracy: 9840/10000 (98.4%)

Epoch: 5 0/60000 Training loss: 0.244000
Epoch: 5 10000/60000 Training loss: 0.030295
Epoch: 5 20000/60000 Training loss: 0.096510
Epoch: 5 30000/60000 Training loss: 0.112491
Epoch: 5 40000/60000 Training loss: 0.144400
Epoch: 5 50000/60000 Training loss: 0.101987
Training loss: 0.103805
Test loss: 0.041301; Test accuracy: 9869/10000 (98.7%)

Epoch: 6 0/60000 Training loss: 0.106080
Epoch: 6 10000/60000 Training loss: 0.069093
Epoch: 6 20000/60000 Training loss: 0.081731
Epoch: 6 30000/60000 Training loss: 0.039524
Epoch: 6 40000/60000 Training loss: 0.050958
Epoch: 6 50000/60000 Training loss: 0.089457
Training loss: 0.091892
Test loss: 0.035174; Test accuracy: 9891/10000 (98.9%)

Epoch: 7 0/60000 Training loss: 0.105455
Epoch: 7 10000/60000 Training loss: 0.081853
Epoch: 7 20000/60000 Training loss: 0.167868
Epoch: 7 30000/60000 Training loss: 0.104612
Epoch: 7 40000/60000 Training loss: 0.137005
Epoch: 7 50000/60000 Training loss: 0.047825
Training loss: 0.081725
Test loss: 0.035348; Test accuracy: 9877/10000 (98.8%)

Epoch: 8 0/60000 Training loss: 0.123224
Epoch: 8 10000/60000 Training loss: 0.048697
Epoch: 8 20000/60000 Training loss: 0.091257
Epoch: 8 30000/60000 Training loss: 0.016854
Epoch: 8 40000/60000 Training loss: 0.126859
Epoch: 8 50000/60000 Training loss: 0.040988
Training loss: 0.077285
Test loss: 0.031746; Test accuracy: 9896/10000 (99.0%)

Epoch: 9 0/60000 Training loss: 0.055716
Epoch: 9 10000/60000 Training loss: 0.122975
Epoch: 9 20000/60000 Training loss: 0.110557
Epoch: 9 30000/60000 Training loss: 0.028228
Epoch: 9 40000/60000 Training loss: 0.121297
Epoch: 9 50000/60000 Training loss: 0.025252
Training loss: 0.070359
Test loss: 0.031615; Test accuracy: 9892/10000 (98.9%)

Epoch: 10 0/60000 Training loss: 0.048531
Epoch: 10 10000/60000 Training loss: 0.015727
Epoch: 10 20000/60000 Training loss: 0.040008
Epoch: 10 30000/60000 Training loss: 0.062325
Epoch: 10 40000/60000 Training loss: 0.049659
Epoch: 10 50000/60000 Training loss: 0.027195
Training loss: 0.064873
Test loss: 0.029382; Test accuracy: 9896/10000 (99.0%)

Epoch: 11 0/60000 Training loss: 0.048504
Epoch: 11 10000/60000 Training loss: 0.079982
Epoch: 11 20000/60000 Training loss: 0.068782
Epoch: 11 30000/60000 Training loss: 0.057497
Epoch: 11 40000/60000 Training loss: 0.131145
Epoch: 11 50000/60000 Training loss: 0.026323
Training loss: 0.061623
Test loss: 0.026604; Test accuracy: 9908/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.086181
Epoch: 12 10000/60000 Training loss: 0.045476
Epoch: 12 20000/60000 Training loss: 0.038506
Epoch: 12 30000/60000 Training loss: 0.061824
Epoch: 12 40000/60000 Training loss: 0.120378
Epoch: 12 50000/60000 Training loss: 0.035376
Training loss: 0.057953
Test loss: 0.026619; Test accuracy: 9903/10000 (99.0%)

Epoch: 13 0/60000 Training loss: 0.046493
Epoch: 13 10000/60000 Training loss: 0.013880
Epoch: 13 20000/60000 Training loss: 0.034410
Epoch: 13 30000/60000 Training loss: 0.036263
Epoch: 13 40000/60000 Training loss: 0.032286
Epoch: 13 50000/60000 Training loss: 0.061643
Training loss: 0.053850
Test loss: 0.026063; Test accuracy: 9912/10000 (99.1%)

Epoch: 14 0/60000 Training loss: 0.026605
Epoch: 14 10000/60000 Training loss: 0.014622
Epoch: 14 20000/60000 Training loss: 0.041461
Epoch: 14 30000/60000 Training loss: 0.019899
Epoch: 14 40000/60000 Training loss: 0.027862
Epoch: 14 50000/60000 Training loss: 0.010330
Training loss: 0.051041
Test loss: 0.025146; Test accuracy: 9920/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.052787
Epoch: 15 10000/60000 Training loss: 0.037561
Epoch: 15 20000/60000 Training loss: 0.016892
Epoch: 15 30000/60000 Training loss: 0.085389
Epoch: 15 40000/60000 Training loss: 0.071912
Epoch: 15 50000/60000 Training loss: 0.022618
Training loss: 0.048857
Test loss: 0.024071; Test accuracy: 9920/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.047344
Epoch: 16 10000/60000 Training loss: 0.079577
Epoch: 16 20000/60000 Training loss: 0.045806
Epoch: 16 30000/60000 Training loss: 0.092127
Epoch: 16 40000/60000 Training loss: 0.039744
Epoch: 16 50000/60000 Training loss: 0.033855
Training loss: 0.045691
Test loss: 0.023765; Test accuracy: 9913/10000 (99.1%)

Epoch: 17 0/60000 Training loss: 0.065209
Epoch: 17 10000/60000 Training loss: 0.030005
Epoch: 17 20000/60000 Training loss: 0.056875
Epoch: 17 30000/60000 Training loss: 0.070129
Epoch: 17 40000/60000 Training loss: 0.066975
Epoch: 17 50000/60000 Training loss: 0.045103
Training loss: 0.043723
Test loss: 0.022087; Test accuracy: 9921/10000 (99.2%)

Epoch: 18 0/60000 Training loss: 0.012652
Epoch: 18 10000/60000 Training loss: 0.044226
Epoch: 18 20000/60000 Training loss: 0.019509
Epoch: 18 30000/60000 Training loss: 0.015393
Epoch: 18 40000/60000 Training loss: 0.216272
Epoch: 18 50000/60000 Training loss: 0.014754
Training loss: 0.040603
Test loss: 0.022073; Test accuracy: 9922/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.011256
Epoch: 19 10000/60000 Training loss: 0.012394
Epoch: 19 20000/60000 Training loss: 0.010079
Epoch: 19 30000/60000 Training loss: 0.021363
Epoch: 19 40000/60000 Training loss: 0.027456
Epoch: 19 50000/60000 Training loss: 0.130861
Training loss: 0.038891
Test loss: 0.021841; Test accuracy: 9925/10000 (99.2%)

[I 2022-11-04 03:08:28,269] Trial 50 finished with value: 0.021841200068593025 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16338969894879884, 'fc1_neurons': 80, 'optimizer': 'Adam', 'learning_rate': 5.095841812903029e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 96, 'conv2_drop': 0.16901929039016117, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 7.410348510244934e-05}
Epoch: 0 0/60000 Training loss: 2.312156
Epoch: 0 10000/60000 Training loss: 0.764577
Epoch: 0 20000/60000 Training loss: 0.398995
Epoch: 0 30000/60000 Training loss: 0.271537
Epoch: 0 40000/60000 Training loss: 0.369707
Epoch: 0 50000/60000 Training loss: 0.306967
Training loss: 0.567287
Test loss: 0.127961; Test accuracy: 9629/10000 (96.3%)

Epoch: 1 0/60000 Training loss: 0.167248
Epoch: 1 10000/60000 Training loss: 0.277726
Epoch: 1 20000/60000 Training loss: 0.131715
Epoch: 1 30000/60000 Training loss: 0.231321
Epoch: 1 40000/60000 Training loss: 0.123022
Epoch: 1 50000/60000 Training loss: 0.161307
Training loss: 0.175209
Test loss: 0.075078; Test accuracy: 9771/10000 (97.7%)

Epoch: 2 0/60000 Training loss: 0.218764
Epoch: 2 10000/60000 Training loss: 0.088603
Epoch: 2 20000/60000 Training loss: 0.119266
Epoch: 2 30000/60000 Training loss: 0.082736
Epoch: 2 40000/60000 Training loss: 0.084480
Epoch: 2 50000/60000 Training loss: 0.087317
Training loss: 0.124593
Test loss: 0.055218; Test accuracy: 9812/10000 (98.1%)

Epoch: 3 0/60000 Training loss: 0.150172
Epoch: 3 10000/60000 Training loss: 0.049122
Epoch: 3 20000/60000 Training loss: 0.118410
Epoch: 3 30000/60000 Training loss: 0.032087
Epoch: 3 40000/60000 Training loss: 0.237940
Epoch: 3 50000/60000 Training loss: 0.099495
Training loss: 0.098686
Test loss: 0.049253; Test accuracy: 9850/10000 (98.5%)

Epoch: 4 0/60000 Training loss: 0.099077
Epoch: 4 10000/60000 Training loss: 0.117083
Epoch: 4 20000/60000 Training loss: 0.064191
Epoch: 4 30000/60000 Training loss: 0.067635
Epoch: 4 40000/60000 Training loss: 0.060877
Epoch: 4 50000/60000 Training loss: 0.120119
Training loss: 0.083712
Test loss: 0.038211; Test accuracy: 9872/10000 (98.7%)

Epoch: 5 0/60000 Training loss: 0.069890
Epoch: 5 10000/60000 Training loss: 0.056659
Epoch: 5 20000/60000 Training loss: 0.038641
Epoch: 5 30000/60000 Training loss: 0.023625
Epoch: 5 40000/60000 Training loss: 0.063814
Epoch: 5 50000/60000 Training loss: 0.153380
Training loss: 0.072043
Test loss: 0.033131; Test accuracy: 9891/10000 (98.9%)

Epoch: 6 0/60000 Training loss: 0.075184
Epoch: 6 10000/60000 Training loss: 0.075187
Epoch: 6 20000/60000 Training loss: 0.042827
Epoch: 6 30000/60000 Training loss: 0.039719
Epoch: 6 40000/60000 Training loss: 0.030532
Epoch: 6 50000/60000 Training loss: 0.085210
Training loss: 0.064866
Test loss: 0.030214; Test accuracy: 9902/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.060369
Epoch: 7 10000/60000 Training loss: 0.044189
Epoch: 7 20000/60000 Training loss: 0.087987
Epoch: 7 30000/60000 Training loss: 0.036537
Epoch: 7 40000/60000 Training loss: 0.052382
Epoch: 7 50000/60000 Training loss: 0.071858
Training loss: 0.058065
Test loss: 0.029306; Test accuracy: 9903/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.020552
Epoch: 8 10000/60000 Training loss: 0.047002
Epoch: 8 20000/60000 Training loss: 0.032917
Epoch: 8 30000/60000 Training loss: 0.029582
Epoch: 8 40000/60000 Training loss: 0.059678
Epoch: 8 50000/60000 Training loss: 0.077919
Training loss: 0.053841
Test loss: 0.026434; Test accuracy: 9916/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.005337
Epoch: 9 10000/60000 Training loss: 0.021705
Epoch: 9 20000/60000 Training loss: 0.053074
Epoch: 9 30000/60000 Training loss: 0.058885
Epoch: 9 40000/60000 Training loss: 0.046244
Epoch: 9 50000/60000 Training loss: 0.020457
Training loss: 0.047799
Test loss: 0.025442; Test accuracy: 9917/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.059998
Epoch: 10 10000/60000 Training loss: 0.013111
Epoch: 10 20000/60000 Training loss: 0.081991
Epoch: 10 30000/60000 Training loss: 0.006792
Epoch: 10 40000/60000 Training loss: 0.014911
Epoch: 10 50000/60000 Training loss: 0.010114
Training loss: 0.044305
Test loss: 0.025037; Test accuracy: 9923/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.102153
Epoch: 11 10000/60000 Training loss: 0.049871
Epoch: 11 20000/60000 Training loss: 0.088278
Epoch: 11 30000/60000 Training loss: 0.016665
Epoch: 11 40000/60000 Training loss: 0.015137
Epoch: 11 50000/60000 Training loss: 0.024066
Training loss: 0.042262
Test loss: 0.023261; Test accuracy: 9923/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.051955
Epoch: 12 10000/60000 Training loss: 0.058363
Epoch: 12 20000/60000 Training loss: 0.027843
Epoch: 12 30000/60000 Training loss: 0.013385
Epoch: 12 40000/60000 Training loss: 0.015125
Epoch: 12 50000/60000 Training loss: 0.028810
Training loss: 0.038519
Test loss: 0.023833; Test accuracy: 9918/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.132736
Epoch: 13 10000/60000 Training loss: 0.100917
Epoch: 13 20000/60000 Training loss: 0.069777
Epoch: 13 30000/60000 Training loss: 0.060693
Epoch: 13 40000/60000 Training loss: 0.020291
Epoch: 13 50000/60000 Training loss: 0.083487
Training loss: 0.037160
Test loss: 0.023906; Test accuracy: 9917/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.015583
Epoch: 14 10000/60000 Training loss: 0.010327
Epoch: 14 20000/60000 Training loss: 0.016875
Epoch: 14 30000/60000 Training loss: 0.021608
Epoch: 14 40000/60000 Training loss: 0.002031
Epoch: 14 50000/60000 Training loss: 0.008740
Training loss: 0.033412
Test loss: 0.020939; Test accuracy: 9928/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.018290
Epoch: 15 10000/60000 Training loss: 0.048348
Epoch: 15 20000/60000 Training loss: 0.034173
Epoch: 15 30000/60000 Training loss: 0.015530
Epoch: 15 40000/60000 Training loss: 0.021848
Epoch: 15 50000/60000 Training loss: 0.048255
Training loss: 0.032785
Test loss: 0.021610; Test accuracy: 9928/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.078489
Epoch: 16 10000/60000 Training loss: 0.006581
Epoch: 16 20000/60000 Training loss: 0.043805
Epoch: 16 30000/60000 Training loss: 0.034649
Epoch: 16 40000/60000 Training loss: 0.049738
Epoch: 16 50000/60000 Training loss: 0.045559
Training loss: 0.031237
Test loss: 0.019730; Test accuracy: 9933/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.018910
Epoch: 17 10000/60000 Training loss: 0.016640
Epoch: 17 20000/60000 Training loss: 0.079676
Epoch: 17 30000/60000 Training loss: 0.011260
Epoch: 17 40000/60000 Training loss: 0.044373
Epoch: 17 50000/60000 Training loss: 0.005061
Training loss: 0.028763
Test loss: 0.021086; Test accuracy: 9928/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.014835
Epoch: 18 10000/60000 Training loss: 0.001579
Epoch: 18 20000/60000 Training loss: 0.003818
Epoch: 18 30000/60000 Training loss: 0.015001
Epoch: 18 40000/60000 Training loss: 0.021715
Epoch: 18 50000/60000 Training loss: 0.051938
Training loss: 0.027564
Test loss: 0.021573; Test accuracy: 9924/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.039783
Epoch: 19 10000/60000 Training loss: 0.028774
Epoch: 19 20000/60000 Training loss: 0.023955
Epoch: 19 30000/60000 Training loss: 0.021946
Epoch: 19 40000/60000 Training loss: 0.057671
Epoch: 19 50000/60000 Training loss: 0.119155
Training loss: 0.025660
Test loss: 0.020219; Test accuracy: 9931/10000 (99.3%)

[I 2022-11-04 03:13:07,769] Trial 51 finished with value: 0.01972959190607071 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 96, 'conv2_drop': 0.16901929039016117, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 7.410348510244934e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.14363099545891037, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00021098260492857405}
Epoch: 0 0/60000 Training loss: 2.303298
Epoch: 0 10000/60000 Training loss: 0.208782
Epoch: 0 20000/60000 Training loss: 0.200128
Epoch: 0 30000/60000 Training loss: 0.206597
Epoch: 0 40000/60000 Training loss: 0.137230
Epoch: 0 50000/60000 Training loss: 0.069626
Training loss: 0.293192
Test loss: 0.057604; Test accuracy: 9801/10000 (98.0%)

Epoch: 1 0/60000 Training loss: 0.121412
Epoch: 1 10000/60000 Training loss: 0.110541
Epoch: 1 20000/60000 Training loss: 0.120564
Epoch: 1 30000/60000 Training loss: 0.107195
Epoch: 1 40000/60000 Training loss: 0.177547
Epoch: 1 50000/60000 Training loss: 0.114659
Training loss: 0.093301
Test loss: 0.039137; Test accuracy: 9858/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.044661
Epoch: 2 10000/60000 Training loss: 0.045200
Epoch: 2 20000/60000 Training loss: 0.020649
Epoch: 2 30000/60000 Training loss: 0.063766
Epoch: 2 40000/60000 Training loss: 0.007647
Epoch: 2 50000/60000 Training loss: 0.020066
Training loss: 0.064194
Test loss: 0.033379; Test accuracy: 9888/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.022265
Epoch: 3 10000/60000 Training loss: 0.031769
Epoch: 3 20000/60000 Training loss: 0.019669
Epoch: 3 30000/60000 Training loss: 0.053111
Epoch: 3 40000/60000 Training loss: 0.070681
Epoch: 3 50000/60000 Training loss: 0.013227
Training loss: 0.052613
Test loss: 0.024594; Test accuracy: 9914/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.055314
Epoch: 4 10000/60000 Training loss: 0.029243
Epoch: 4 20000/60000 Training loss: 0.008130
Epoch: 4 30000/60000 Training loss: 0.020690
Epoch: 4 40000/60000 Training loss: 0.027567
Epoch: 4 50000/60000 Training loss: 0.016212
Training loss: 0.043652
Test loss: 0.024600; Test accuracy: 9915/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.038618
Epoch: 5 10000/60000 Training loss: 0.051353
Epoch: 5 20000/60000 Training loss: 0.016331
Epoch: 5 30000/60000 Training loss: 0.008879
Epoch: 5 40000/60000 Training loss: 0.017670
Epoch: 5 50000/60000 Training loss: 0.110236
Training loss: 0.035641
Test loss: 0.021253; Test accuracy: 9926/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.018198
Epoch: 6 10000/60000 Training loss: 0.022175
Epoch: 6 20000/60000 Training loss: 0.040254
Epoch: 6 30000/60000 Training loss: 0.020350
Epoch: 6 40000/60000 Training loss: 0.009090
Epoch: 6 50000/60000 Training loss: 0.031479
Training loss: 0.033247
Test loss: 0.019515; Test accuracy: 9927/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.046728
Epoch: 7 10000/60000 Training loss: 0.054078
Epoch: 7 20000/60000 Training loss: 0.050858
Epoch: 7 30000/60000 Training loss: 0.002297
Epoch: 7 40000/60000 Training loss: 0.007473
Epoch: 7 50000/60000 Training loss: 0.043993
Training loss: 0.029351
Test loss: 0.020885; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.023768
Epoch: 8 10000/60000 Training loss: 0.011809
Epoch: 8 20000/60000 Training loss: 0.006632
Epoch: 8 30000/60000 Training loss: 0.008803
Epoch: 8 40000/60000 Training loss: 0.066041
Epoch: 8 50000/60000 Training loss: 0.045775
Training loss: 0.024383
Test loss: 0.021314; Test accuracy: 9932/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.042625
Epoch: 9 10000/60000 Training loss: 0.029653
Epoch: 9 20000/60000 Training loss: 0.006693
Epoch: 9 30000/60000 Training loss: 0.003006
Epoch: 9 40000/60000 Training loss: 0.012298
Epoch: 9 50000/60000 Training loss: 0.064765
Training loss: 0.022374
Test loss: 0.018783; Test accuracy: 9936/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.037370
Epoch: 10 10000/60000 Training loss: 0.015610
Epoch: 10 20000/60000 Training loss: 0.016658
Epoch: 10 30000/60000 Training loss: 0.006470
Epoch: 10 40000/60000 Training loss: 0.026647
Epoch: 10 50000/60000 Training loss: 0.000628
Training loss: 0.020157
Test loss: 0.020976; Test accuracy: 9926/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.021722
Epoch: 11 10000/60000 Training loss: 0.020198
Epoch: 11 20000/60000 Training loss: 0.006491
Epoch: 11 30000/60000 Training loss: 0.000487
Epoch: 11 40000/60000 Training loss: 0.055807
Epoch: 11 50000/60000 Training loss: 0.003708
Training loss: 0.018782
Test loss: 0.020618; Test accuracy: 9932/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.005817
Epoch: 12 10000/60000 Training loss: 0.008841
Epoch: 12 20000/60000 Training loss: 0.074624
Epoch: 12 30000/60000 Training loss: 0.018018
Epoch: 12 40000/60000 Training loss: 0.002312
Epoch: 12 50000/60000 Training loss: 0.016171
Training loss: 0.016860
Test loss: 0.020135; Test accuracy: 9932/10000 (99.3%)

[I 2022-11-04 03:16:09,384] Trial 52 finished with value: 0.01878318563103676 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.14363099545891037, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00021098260492857405}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 128, 'conv2_drop': 0.07035299424536091, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.0002784740253438091}
Epoch: 0 0/60000 Training loss: 2.330308
Epoch: 0 10000/60000 Training loss: 0.285689
Epoch: 0 20000/60000 Training loss: 0.161787
Epoch: 0 30000/60000 Training loss: 0.180241
Epoch: 0 40000/60000 Training loss: 0.082904
Epoch: 0 50000/60000 Training loss: 0.152634
Training loss: 0.281025
Test loss: 0.049993; Test accuracy: 9839/10000 (98.4%)

Epoch: 1 0/60000 Training loss: 0.112664
Epoch: 1 10000/60000 Training loss: 0.109884
Epoch: 1 20000/60000 Training loss: 0.094167
Epoch: 1 30000/60000 Training loss: 0.125758
Epoch: 1 40000/60000 Training loss: 0.172504
Epoch: 1 50000/60000 Training loss: 0.065835
Training loss: 0.088076
Test loss: 0.033169; Test accuracy: 9889/10000 (98.9%)

Epoch: 2 0/60000 Training loss: 0.022753
Epoch: 2 10000/60000 Training loss: 0.020218
Epoch: 2 20000/60000 Training loss: 0.058813
Epoch: 2 30000/60000 Training loss: 0.069236
Epoch: 2 40000/60000 Training loss: 0.058073
Epoch: 2 50000/60000 Training loss: 0.067158
Training loss: 0.065816
Test loss: 0.029345; Test accuracy: 9910/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.023074
Epoch: 3 10000/60000 Training loss: 0.030071
Epoch: 3 20000/60000 Training loss: 0.019287
Epoch: 3 30000/60000 Training loss: 0.061315
Epoch: 3 40000/60000 Training loss: 0.054733
Epoch: 3 50000/60000 Training loss: 0.103029
Training loss: 0.053117
Test loss: 0.027435; Test accuracy: 9907/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.032468
Epoch: 4 10000/60000 Training loss: 0.035213
Epoch: 4 20000/60000 Training loss: 0.044108
Epoch: 4 30000/60000 Training loss: 0.005115
Epoch: 4 40000/60000 Training loss: 0.024733
Epoch: 4 50000/60000 Training loss: 0.117459
Training loss: 0.042357
Test loss: 0.021136; Test accuracy: 9931/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.036245
Epoch: 5 10000/60000 Training loss: 0.019231
Epoch: 5 20000/60000 Training loss: 0.030186
Epoch: 5 30000/60000 Training loss: 0.035234
Epoch: 5 40000/60000 Training loss: 0.022988
Epoch: 5 50000/60000 Training loss: 0.032249
Training loss: 0.035885
Test loss: 0.022739; Test accuracy: 9930/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.050963
Epoch: 6 10000/60000 Training loss: 0.016319
Epoch: 6 20000/60000 Training loss: 0.021318
Epoch: 6 30000/60000 Training loss: 0.012749
Epoch: 6 40000/60000 Training loss: 0.067378
Epoch: 6 50000/60000 Training loss: 0.058543
Training loss: 0.030411
Test loss: 0.022119; Test accuracy: 9928/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.014270
Epoch: 7 10000/60000 Training loss: 0.030691
Epoch: 7 20000/60000 Training loss: 0.001824
Epoch: 7 30000/60000 Training loss: 0.003724
Epoch: 7 40000/60000 Training loss: 0.015286
Epoch: 7 50000/60000 Training loss: 0.021877
Training loss: 0.026156
Test loss: 0.021676; Test accuracy: 9939/10000 (99.4%)

[I 2022-11-04 03:18:01,679] Trial 53 finished with value: 0.02113582380115986 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 128, 'conv2_drop': 0.07035299424536091, 'fc1_neurons': 110, 'optimizer': 'Adam', 'learning_rate': 0.0002784740253438091}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.1715851381365764, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.0001931644409160057}
Epoch: 0 0/60000 Training loss: 2.317939
Epoch: 0 10000/60000 Training loss: 0.413923
Epoch: 0 20000/60000 Training loss: 0.215439
Epoch: 0 30000/60000 Training loss: 0.198436
Epoch: 0 40000/60000 Training loss: 0.089109
Epoch: 0 50000/60000 Training loss: 0.146912
Training loss: 0.351654
Test loss: 0.069371; Test accuracy: 9796/10000 (98.0%)

Epoch: 1 0/60000 Training loss: 0.104223
Epoch: 1 10000/60000 Training loss: 0.175239
Epoch: 1 20000/60000 Training loss: 0.203939
Epoch: 1 30000/60000 Training loss: 0.078908
Epoch: 1 40000/60000 Training loss: 0.061225
Epoch: 1 50000/60000 Training loss: 0.087245
Training loss: 0.108949
Test loss: 0.046340; Test accuracy: 9855/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.121836
Epoch: 2 10000/60000 Training loss: 0.115688
Epoch: 2 20000/60000 Training loss: 0.067904
Epoch: 2 30000/60000 Training loss: 0.100936
Epoch: 2 40000/60000 Training loss: 0.074098
Epoch: 2 50000/60000 Training loss: 0.109210
Training loss: 0.079273
Test loss: 0.033490; Test accuracy: 9886/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.036034
Epoch: 3 10000/60000 Training loss: 0.042490
Epoch: 3 20000/60000 Training loss: 0.057451
Epoch: 3 30000/60000 Training loss: 0.056973
Epoch: 3 40000/60000 Training loss: 0.050256
Epoch: 3 50000/60000 Training loss: 0.043704
Training loss: 0.061350
Test loss: 0.026738; Test accuracy: 9912/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.042139
Epoch: 4 10000/60000 Training loss: 0.023372
Epoch: 4 20000/60000 Training loss: 0.028267
Epoch: 4 30000/60000 Training loss: 0.016080
Epoch: 4 40000/60000 Training loss: 0.010358
Epoch: 4 50000/60000 Training loss: 0.019102
Training loss: 0.052044
Test loss: 0.025643; Test accuracy: 9913/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.057867
Epoch: 5 10000/60000 Training loss: 0.030029
Epoch: 5 20000/60000 Training loss: 0.177846
Epoch: 5 30000/60000 Training loss: 0.008127
Epoch: 5 40000/60000 Training loss: 0.029642
Epoch: 5 50000/60000 Training loss: 0.012260
Training loss: 0.043599
Test loss: 0.023938; Test accuracy: 9926/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.067322
Epoch: 6 10000/60000 Training loss: 0.021929
Epoch: 6 20000/60000 Training loss: 0.013697
Epoch: 6 30000/60000 Training loss: 0.015026
Epoch: 6 40000/60000 Training loss: 0.049845
Epoch: 6 50000/60000 Training loss: 0.085261
Training loss: 0.039495
Test loss: 0.022710; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.015839
Epoch: 7 10000/60000 Training loss: 0.075461
Epoch: 7 20000/60000 Training loss: 0.008803
Epoch: 7 30000/60000 Training loss: 0.006563
Epoch: 7 40000/60000 Training loss: 0.099886
Epoch: 7 50000/60000 Training loss: 0.008246
Training loss: 0.033669
Test loss: 0.023063; Test accuracy: 9920/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.064135
Epoch: 8 10000/60000 Training loss: 0.016058
Epoch: 8 20000/60000 Training loss: 0.066183
Epoch: 8 30000/60000 Training loss: 0.035511
Epoch: 8 40000/60000 Training loss: 0.011810
Epoch: 8 50000/60000 Training loss: 0.040249
Training loss: 0.032743
Test loss: 0.019934; Test accuracy: 9932/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.040411
Epoch: 9 10000/60000 Training loss: 0.010280
Epoch: 9 20000/60000 Training loss: 0.003850
Epoch: 9 30000/60000 Training loss: 0.026056
Epoch: 9 40000/60000 Training loss: 0.018955
Epoch: 9 50000/60000 Training loss: 0.006367
Training loss: 0.028603
Test loss: 0.019450; Test accuracy: 9935/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.088460
Epoch: 10 10000/60000 Training loss: 0.040721
Epoch: 10 20000/60000 Training loss: 0.018869
Epoch: 10 30000/60000 Training loss: 0.007114
Epoch: 10 40000/60000 Training loss: 0.015362
Epoch: 10 50000/60000 Training loss: 0.020211
Training loss: 0.025098
Test loss: 0.018306; Test accuracy: 9939/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.020011
Epoch: 11 10000/60000 Training loss: 0.007548
Epoch: 11 20000/60000 Training loss: 0.023484
Epoch: 11 30000/60000 Training loss: 0.006625
Epoch: 11 40000/60000 Training loss: 0.026470
Epoch: 11 50000/60000 Training loss: 0.071943
Training loss: 0.024991
Test loss: 0.019006; Test accuracy: 9938/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.004952
Epoch: 12 10000/60000 Training loss: 0.003049
Epoch: 12 20000/60000 Training loss: 0.002589
Epoch: 12 30000/60000 Training loss: 0.148302
Epoch: 12 40000/60000 Training loss: 0.004782
Epoch: 12 50000/60000 Training loss: 0.004554
Training loss: 0.022428
Test loss: 0.017024; Test accuracy: 9941/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.000987
Epoch: 13 10000/60000 Training loss: 0.003613
Epoch: 13 20000/60000 Training loss: 0.007933
Epoch: 13 30000/60000 Training loss: 0.002746
Epoch: 13 40000/60000 Training loss: 0.012784
Epoch: 13 50000/60000 Training loss: 0.003179
Training loss: 0.019808
Test loss: 0.016576; Test accuracy: 9950/10000 (99.5%)

Epoch: 14 0/60000 Training loss: 0.064996
Epoch: 14 10000/60000 Training loss: 0.017750
Epoch: 14 20000/60000 Training loss: 0.042246
Epoch: 14 30000/60000 Training loss: 0.017263
Epoch: 14 40000/60000 Training loss: 0.043674
Epoch: 14 50000/60000 Training loss: 0.008590
Training loss: 0.018368
Test loss: 0.016699; Test accuracy: 9948/10000 (99.5%)

Epoch: 15 0/60000 Training loss: 0.008774
Epoch: 15 10000/60000 Training loss: 0.010065
Epoch: 15 20000/60000 Training loss: 0.018455
Epoch: 15 30000/60000 Training loss: 0.001427
Epoch: 15 40000/60000 Training loss: 0.034376
Epoch: 15 50000/60000 Training loss: 0.002253
Training loss: 0.016960
Test loss: 0.018937; Test accuracy: 9941/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.006526
Epoch: 16 10000/60000 Training loss: 0.010427
Epoch: 16 20000/60000 Training loss: 0.005304
Epoch: 16 30000/60000 Training loss: 0.001189
Epoch: 16 40000/60000 Training loss: 0.022837
Epoch: 16 50000/60000 Training loss: 0.023313
Training loss: 0.017765
Test loss: 0.017477; Test accuracy: 9944/10000 (99.4%)

[I 2022-11-04 03:21:59,337] Trial 54 finished with value: 0.016575662419199944 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.1715851381365764, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 0.0001931644409160057}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.17512320763432465, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.0001308195044949799}
Epoch: 0 0/60000 Training loss: 2.338241
Epoch: 0 10000/60000 Training loss: 0.668169
Epoch: 0 20000/60000 Training loss: 0.371460
Epoch: 0 30000/60000 Training loss: 0.274445
Epoch: 0 40000/60000 Training loss: 0.202042
Epoch: 0 50000/60000 Training loss: 0.170265
Training loss: 0.429070
Test loss: 0.084943; Test accuracy: 9739/10000 (97.4%)

Epoch: 1 0/60000 Training loss: 0.218675
Epoch: 1 10000/60000 Training loss: 0.169038
Epoch: 1 20000/60000 Training loss: 0.054774
Epoch: 1 30000/60000 Training loss: 0.248179
Epoch: 1 40000/60000 Training loss: 0.095690
Epoch: 1 50000/60000 Training loss: 0.098572
Training loss: 0.131453
Test loss: 0.051375; Test accuracy: 9850/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.149964
Epoch: 2 10000/60000 Training loss: 0.058967
Epoch: 2 20000/60000 Training loss: 0.047829
Epoch: 2 30000/60000 Training loss: 0.123488
Epoch: 2 40000/60000 Training loss: 0.214153
Epoch: 2 50000/60000 Training loss: 0.052053
Training loss: 0.095095
Test loss: 0.041141; Test accuracy: 9870/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.208176
Epoch: 3 10000/60000 Training loss: 0.028819
Epoch: 3 20000/60000 Training loss: 0.130647
Epoch: 3 30000/60000 Training loss: 0.074623
Epoch: 3 40000/60000 Training loss: 0.106624
Epoch: 3 50000/60000 Training loss: 0.099282
Training loss: 0.079294
Test loss: 0.033339; Test accuracy: 9891/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.081111
Epoch: 4 10000/60000 Training loss: 0.044830
Epoch: 4 20000/60000 Training loss: 0.078193
Epoch: 4 30000/60000 Training loss: 0.019633
Epoch: 4 40000/60000 Training loss: 0.012840
Epoch: 4 50000/60000 Training loss: 0.066927
Training loss: 0.066208
Test loss: 0.032411; Test accuracy: 9896/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.013093
Epoch: 5 10000/60000 Training loss: 0.046964
Epoch: 5 20000/60000 Training loss: 0.008851
Epoch: 5 30000/60000 Training loss: 0.038902
Epoch: 5 40000/60000 Training loss: 0.033585
Epoch: 5 50000/60000 Training loss: 0.018184
Training loss: 0.056190
Test loss: 0.027387; Test accuracy: 9907/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.107879
Epoch: 6 10000/60000 Training loss: 0.068643
Epoch: 6 20000/60000 Training loss: 0.046167
Epoch: 6 30000/60000 Training loss: 0.066379
Epoch: 6 40000/60000 Training loss: 0.077140
Epoch: 6 50000/60000 Training loss: 0.128788
Training loss: 0.050793
Test loss: 0.025791; Test accuracy: 9912/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.017427
Epoch: 7 10000/60000 Training loss: 0.159339
Epoch: 7 20000/60000 Training loss: 0.049466
Epoch: 7 30000/60000 Training loss: 0.042367
Epoch: 7 40000/60000 Training loss: 0.034066
Epoch: 7 50000/60000 Training loss: 0.026435
Training loss: 0.044985
Test loss: 0.022259; Test accuracy: 9930/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.096579
Epoch: 8 10000/60000 Training loss: 0.090914
Epoch: 8 20000/60000 Training loss: 0.045051
Epoch: 8 30000/60000 Training loss: 0.026064
Epoch: 8 40000/60000 Training loss: 0.005641
Epoch: 8 50000/60000 Training loss: 0.060576
Training loss: 0.041046
Test loss: 0.024583; Test accuracy: 9919/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.047114
Epoch: 9 10000/60000 Training loss: 0.014923
Epoch: 9 20000/60000 Training loss: 0.050247
Epoch: 9 30000/60000 Training loss: 0.120396
Epoch: 9 40000/60000 Training loss: 0.026049
Epoch: 9 50000/60000 Training loss: 0.013244
Training loss: 0.038387
Test loss: 0.023154; Test accuracy: 9916/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.082402
Epoch: 10 10000/60000 Training loss: 0.003324
Epoch: 10 20000/60000 Training loss: 0.043186
Epoch: 10 30000/60000 Training loss: 0.021608
Epoch: 10 40000/60000 Training loss: 0.029085
Epoch: 10 50000/60000 Training loss: 0.062049
Training loss: 0.034329
Test loss: 0.021437; Test accuracy: 9925/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.084260
Epoch: 11 10000/60000 Training loss: 0.035998
Epoch: 11 20000/60000 Training loss: 0.007366
Epoch: 11 30000/60000 Training loss: 0.006377
Epoch: 11 40000/60000 Training loss: 0.004725
Epoch: 11 50000/60000 Training loss: 0.009098
Training loss: 0.032425
Test loss: 0.021472; Test accuracy: 9932/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.038001
Epoch: 12 10000/60000 Training loss: 0.028780
Epoch: 12 20000/60000 Training loss: 0.006228
Epoch: 12 30000/60000 Training loss: 0.013048
Epoch: 12 40000/60000 Training loss: 0.021936
Epoch: 12 50000/60000 Training loss: 0.037350
Training loss: 0.027952
Test loss: 0.022847; Test accuracy: 9932/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.066254
Epoch: 13 10000/60000 Training loss: 0.028593
Epoch: 13 20000/60000 Training loss: 0.019603
Epoch: 13 30000/60000 Training loss: 0.013987
Epoch: 13 40000/60000 Training loss: 0.016122
Epoch: 13 50000/60000 Training loss: 0.018394
Training loss: 0.026598
Test loss: 0.021429; Test accuracy: 9929/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.056737
Epoch: 14 10000/60000 Training loss: 0.019675
Epoch: 14 20000/60000 Training loss: 0.047681
Epoch: 14 30000/60000 Training loss: 0.003625
Epoch: 14 40000/60000 Training loss: 0.008468
Epoch: 14 50000/60000 Training loss: 0.012980
Training loss: 0.025017
Test loss: 0.021443; Test accuracy: 9925/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.010222
Epoch: 15 10000/60000 Training loss: 0.029243
Epoch: 15 20000/60000 Training loss: 0.006675
Epoch: 15 30000/60000 Training loss: 0.041060
Epoch: 15 40000/60000 Training loss: 0.027227
Epoch: 15 50000/60000 Training loss: 0.040900
Training loss: 0.023015
Test loss: 0.019564; Test accuracy: 9934/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.065997
Epoch: 16 10000/60000 Training loss: 0.063500
Epoch: 16 20000/60000 Training loss: 0.012921
Epoch: 16 30000/60000 Training loss: 0.001108
Epoch: 16 40000/60000 Training loss: 0.008391
Epoch: 16 50000/60000 Training loss: 0.017403
Training loss: 0.022439
Test loss: 0.021431; Test accuracy: 9931/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.040142
Epoch: 17 10000/60000 Training loss: 0.004296
Epoch: 17 20000/60000 Training loss: 0.018658
Epoch: 17 30000/60000 Training loss: 0.006897
Epoch: 17 40000/60000 Training loss: 0.002093
Epoch: 17 50000/60000 Training loss: 0.013069
Training loss: 0.021275
Test loss: 0.018942; Test accuracy: 9937/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.010732
Epoch: 18 10000/60000 Training loss: 0.064304
Epoch: 18 20000/60000 Training loss: 0.010437
Epoch: 18 30000/60000 Training loss: 0.008072
Epoch: 18 40000/60000 Training loss: 0.029738
Epoch: 18 50000/60000 Training loss: 0.103585
Training loss: 0.020982
Test loss: 0.020931; Test accuracy: 9928/10000 (99.3%)

Epoch: 19 0/60000 Training loss: 0.002219
Epoch: 19 10000/60000 Training loss: 0.006054
Epoch: 19 20000/60000 Training loss: 0.005168
Epoch: 19 30000/60000 Training loss: 0.016197
Epoch: 19 40000/60000 Training loss: 0.018415
Epoch: 19 50000/60000 Training loss: 0.022008
Training loss: 0.019214
Test loss: 0.018661; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 03:26:39,694] Trial 55 finished with value: 0.018660567700862885 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.17512320763432465, 'fc1_neurons': 100, 'optimizer': 'Adam', 'learning_rate': 0.0001308195044949799}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.15400498902728843, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 5.4770045840495305e-05}
Epoch: 0 0/60000 Training loss: 2.310345
Epoch: 0 10000/60000 Training loss: 1.092222
Epoch: 0 20000/60000 Training loss: 0.448435
Epoch: 0 30000/60000 Training loss: 0.571496
Epoch: 0 40000/60000 Training loss: 0.254323
Epoch: 0 50000/60000 Training loss: 0.447196
Training loss: 0.655792
Test loss: 0.159817; Test accuracy: 9539/10000 (95.4%)

Epoch: 1 0/60000 Training loss: 0.218762
Epoch: 1 10000/60000 Training loss: 0.102978
Epoch: 1 20000/60000 Training loss: 0.129827
Epoch: 1 30000/60000 Training loss: 0.130385
Epoch: 1 40000/60000 Training loss: 0.178688
Epoch: 1 50000/60000 Training loss: 0.292454
Training loss: 0.208693
Test loss: 0.094356; Test accuracy: 9693/10000 (96.9%)

Epoch: 2 0/60000 Training loss: 0.173567
Epoch: 2 10000/60000 Training loss: 0.131431
Epoch: 2 20000/60000 Training loss: 0.170433
Epoch: 2 30000/60000 Training loss: 0.172925
Epoch: 2 40000/60000 Training loss: 0.150975
Epoch: 2 50000/60000 Training loss: 0.196230
Training loss: 0.147551
Test loss: 0.066824; Test accuracy: 9797/10000 (98.0%)

Epoch: 3 0/60000 Training loss: 0.064027
Epoch: 3 10000/60000 Training loss: 0.108850
Epoch: 3 20000/60000 Training loss: 0.077914
Epoch: 3 30000/60000 Training loss: 0.064840
Epoch: 3 40000/60000 Training loss: 0.049920
Epoch: 3 50000/60000 Training loss: 0.106882
Training loss: 0.112639
Test loss: 0.055156; Test accuracy: 9827/10000 (98.3%)

Epoch: 4 0/60000 Training loss: 0.117798
Epoch: 4 10000/60000 Training loss: 0.165119
Epoch: 4 20000/60000 Training loss: 0.049880
Epoch: 4 30000/60000 Training loss: 0.160063
Epoch: 4 40000/60000 Training loss: 0.058542
Epoch: 4 50000/60000 Training loss: 0.079468
Training loss: 0.096358
Test loss: 0.046686; Test accuracy: 9840/10000 (98.4%)

Epoch: 5 0/60000 Training loss: 0.077195
Epoch: 5 10000/60000 Training loss: 0.079626
Epoch: 5 20000/60000 Training loss: 0.087481
Epoch: 5 30000/60000 Training loss: 0.104029
Epoch: 5 40000/60000 Training loss: 0.098096
Epoch: 5 50000/60000 Training loss: 0.085371
Training loss: 0.082768
Test loss: 0.041375; Test accuracy: 9860/10000 (98.6%)

Epoch: 6 0/60000 Training loss: 0.038519
Epoch: 6 10000/60000 Training loss: 0.056330
Epoch: 6 20000/60000 Training loss: 0.054903
Epoch: 6 30000/60000 Training loss: 0.043004
Epoch: 6 40000/60000 Training loss: 0.073895
Epoch: 6 50000/60000 Training loss: 0.121319
Training loss: 0.073576
Test loss: 0.037731; Test accuracy: 9871/10000 (98.7%)

Epoch: 7 0/60000 Training loss: 0.071840
Epoch: 7 10000/60000 Training loss: 0.095533
Epoch: 7 20000/60000 Training loss: 0.071147
Epoch: 7 30000/60000 Training loss: 0.062014
Epoch: 7 40000/60000 Training loss: 0.054772
Epoch: 7 50000/60000 Training loss: 0.046970
Training loss: 0.069290
Test loss: 0.033101; Test accuracy: 9885/10000 (98.8%)

Epoch: 8 0/60000 Training loss: 0.091948
Epoch: 8 10000/60000 Training loss: 0.025234
Epoch: 8 20000/60000 Training loss: 0.082367
Epoch: 8 30000/60000 Training loss: 0.031927
Epoch: 8 40000/60000 Training loss: 0.062089
Epoch: 8 50000/60000 Training loss: 0.083403
Training loss: 0.060778
Test loss: 0.031906; Test accuracy: 9893/10000 (98.9%)

Epoch: 9 0/60000 Training loss: 0.031944
Epoch: 9 10000/60000 Training loss: 0.010816
Epoch: 9 20000/60000 Training loss: 0.023691
Epoch: 9 30000/60000 Training loss: 0.045372
Epoch: 9 40000/60000 Training loss: 0.034757
Epoch: 9 50000/60000 Training loss: 0.070220
Training loss: 0.056062
Test loss: 0.027782; Test accuracy: 9905/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.031805
Epoch: 10 10000/60000 Training loss: 0.163690
Epoch: 10 20000/60000 Training loss: 0.051211
Epoch: 10 30000/60000 Training loss: 0.075040
Epoch: 10 40000/60000 Training loss: 0.040032
Epoch: 10 50000/60000 Training loss: 0.098717
Training loss: 0.051182
Test loss: 0.027347; Test accuracy: 9906/10000 (99.1%)

Epoch: 11 0/60000 Training loss: 0.031289
Epoch: 11 10000/60000 Training loss: 0.069956
Epoch: 11 20000/60000 Training loss: 0.027105
Epoch: 11 30000/60000 Training loss: 0.020305
Epoch: 11 40000/60000 Training loss: 0.008686
Epoch: 11 50000/60000 Training loss: 0.043733
Training loss: 0.048340
Test loss: 0.027812; Test accuracy: 9909/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.103117
Epoch: 12 10000/60000 Training loss: 0.039247
Epoch: 12 20000/60000 Training loss: 0.093061
Epoch: 12 30000/60000 Training loss: 0.013011
Epoch: 12 40000/60000 Training loss: 0.022488
Epoch: 12 50000/60000 Training loss: 0.040961
Training loss: 0.045870
Test loss: 0.024416; Test accuracy: 9911/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.054803
Epoch: 13 10000/60000 Training loss: 0.027200
Epoch: 13 20000/60000 Training loss: 0.029522
Epoch: 13 30000/60000 Training loss: 0.058244
Epoch: 13 40000/60000 Training loss: 0.043223
Epoch: 13 50000/60000 Training loss: 0.039627
Training loss: 0.042698
Test loss: 0.023108; Test accuracy: 9920/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.018194
Epoch: 14 10000/60000 Training loss: 0.019026
Epoch: 14 20000/60000 Training loss: 0.039174
Epoch: 14 30000/60000 Training loss: 0.017353
Epoch: 14 40000/60000 Training loss: 0.022487
Epoch: 14 50000/60000 Training loss: 0.028704
Training loss: 0.040117
Test loss: 0.023387; Test accuracy: 9917/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.067818
Epoch: 15 10000/60000 Training loss: 0.007105
Epoch: 15 20000/60000 Training loss: 0.049498
Epoch: 15 30000/60000 Training loss: 0.068428
Epoch: 15 40000/60000 Training loss: 0.058119
Epoch: 15 50000/60000 Training loss: 0.046689
Training loss: 0.039017
Test loss: 0.022569; Test accuracy: 9924/10000 (99.2%)

Epoch: 16 0/60000 Training loss: 0.018227
Epoch: 16 10000/60000 Training loss: 0.004561
Epoch: 16 20000/60000 Training loss: 0.057929
Epoch: 16 30000/60000 Training loss: 0.036021
Epoch: 16 40000/60000 Training loss: 0.071442
Epoch: 16 50000/60000 Training loss: 0.020250
Training loss: 0.037840
Test loss: 0.021891; Test accuracy: 9925/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.039758
Epoch: 17 10000/60000 Training loss: 0.012322
Epoch: 17 20000/60000 Training loss: 0.088783
Epoch: 17 30000/60000 Training loss: 0.039686
Epoch: 17 40000/60000 Training loss: 0.153391
Epoch: 17 50000/60000 Training loss: 0.068337
Training loss: 0.035789
Test loss: 0.021473; Test accuracy: 9926/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.007731
Epoch: 18 10000/60000 Training loss: 0.011523
Epoch: 18 20000/60000 Training loss: 0.024643
Epoch: 18 30000/60000 Training loss: 0.010137
Epoch: 18 40000/60000 Training loss: 0.026117
Epoch: 18 50000/60000 Training loss: 0.006456
Training loss: 0.034626
Test loss: 0.020488; Test accuracy: 9925/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.012872
Epoch: 19 10000/60000 Training loss: 0.043499
Epoch: 19 20000/60000 Training loss: 0.010132
Epoch: 19 30000/60000 Training loss: 0.007664
Epoch: 19 40000/60000 Training loss: 0.009428
Epoch: 19 50000/60000 Training loss: 0.021586
Training loss: 0.031851
Test loss: 0.020968; Test accuracy: 9922/10000 (99.2%)

[I 2022-11-04 03:31:19,634] Trial 56 finished with value: 0.020487599074840546 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.15400498902728843, 'fc1_neurons': 120, 'optimizer': 'Adam', 'learning_rate': 5.4770045840495305e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.18604397442344886, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 1.9607713777273046e-05}
Epoch: 0 0/60000 Training loss: 2.300381
Epoch: 0 10000/60000 Training loss: 1.875017
Epoch: 0 20000/60000 Training loss: 1.309858
Epoch: 0 30000/60000 Training loss: 1.076502
Epoch: 0 40000/60000 Training loss: 0.944502
Epoch: 0 50000/60000 Training loss: 0.785405
Training loss: 1.235539
Test loss: 0.393173; Test accuracy: 9194/10000 (91.9%)

Epoch: 1 0/60000 Training loss: 0.671738
Epoch: 1 10000/60000 Training loss: 0.599514
Epoch: 1 20000/60000 Training loss: 0.595924
Epoch: 1 30000/60000 Training loss: 0.523625
Epoch: 1 40000/60000 Training loss: 0.471627
Epoch: 1 50000/60000 Training loss: 0.549576
Training loss: 0.538578
Test loss: 0.223390; Test accuracy: 9429/10000 (94.3%)

Epoch: 2 0/60000 Training loss: 0.373743
Epoch: 2 10000/60000 Training loss: 0.647460
Epoch: 2 20000/60000 Training loss: 0.261824
Epoch: 2 30000/60000 Training loss: 0.591857
Epoch: 2 40000/60000 Training loss: 0.321804
Epoch: 2 50000/60000 Training loss: 0.401752
Training loss: 0.388478
Test loss: 0.164087; Test accuracy: 9544/10000 (95.4%)

Epoch: 3 0/60000 Training loss: 0.305682
Epoch: 3 10000/60000 Training loss: 0.371874
Epoch: 3 20000/60000 Training loss: 0.344953
Epoch: 3 30000/60000 Training loss: 0.306405
Epoch: 3 40000/60000 Training loss: 0.295949
Epoch: 3 50000/60000 Training loss: 0.296873
Training loss: 0.313165
Test loss: 0.134890; Test accuracy: 9611/10000 (96.1%)

Epoch: 4 0/60000 Training loss: 0.307382
Epoch: 4 10000/60000 Training loss: 0.280617
Epoch: 4 20000/60000 Training loss: 0.175151
Epoch: 4 30000/60000 Training loss: 0.257523
Epoch: 4 40000/60000 Training loss: 0.171753
Epoch: 4 50000/60000 Training loss: 0.232122
Training loss: 0.268837
Test loss: 0.112787; Test accuracy: 9670/10000 (96.7%)

Epoch: 5 0/60000 Training loss: 0.160165
Epoch: 5 10000/60000 Training loss: 0.272646
Epoch: 5 20000/60000 Training loss: 0.322784
Epoch: 5 30000/60000 Training loss: 0.133651
Epoch: 5 40000/60000 Training loss: 0.158997
Epoch: 5 50000/60000 Training loss: 0.219924
Training loss: 0.235022
Test loss: 0.100352; Test accuracy: 9715/10000 (97.1%)

Epoch: 6 0/60000 Training loss: 0.217117
Epoch: 6 10000/60000 Training loss: 0.171630
Epoch: 6 20000/60000 Training loss: 0.228668
Epoch: 6 30000/60000 Training loss: 0.295119
Epoch: 6 40000/60000 Training loss: 0.120096
Epoch: 6 50000/60000 Training loss: 0.279768
Training loss: 0.214874
Test loss: 0.089615; Test accuracy: 9737/10000 (97.4%)

Epoch: 7 0/60000 Training loss: 0.258872
Epoch: 7 10000/60000 Training loss: 0.173485
Epoch: 7 20000/60000 Training loss: 0.191209
Epoch: 7 30000/60000 Training loss: 0.148372
Epoch: 7 40000/60000 Training loss: 0.125880
Epoch: 7 50000/60000 Training loss: 0.071930
Training loss: 0.192413
Test loss: 0.080262; Test accuracy: 9765/10000 (97.6%)

Epoch: 8 0/60000 Training loss: 0.331480
Epoch: 8 10000/60000 Training loss: 0.084806
Epoch: 8 20000/60000 Training loss: 0.172352
Epoch: 8 30000/60000 Training loss: 0.219988
Epoch: 8 40000/60000 Training loss: 0.235492
Epoch: 8 50000/60000 Training loss: 0.228642
Training loss: 0.177735
Test loss: 0.073474; Test accuracy: 9780/10000 (97.8%)

Epoch: 9 0/60000 Training loss: 0.082171
Epoch: 9 10000/60000 Training loss: 0.157870
Epoch: 9 20000/60000 Training loss: 0.321470
Epoch: 9 30000/60000 Training loss: 0.172087
Epoch: 9 40000/60000 Training loss: 0.066603
Epoch: 9 50000/60000 Training loss: 0.173096
Training loss: 0.164898
Test loss: 0.069389; Test accuracy: 9796/10000 (98.0%)

Epoch: 10 0/60000 Training loss: 0.160202
Epoch: 10 10000/60000 Training loss: 0.116230
Epoch: 10 20000/60000 Training loss: 0.159169
Epoch: 10 30000/60000 Training loss: 0.186062
Epoch: 10 40000/60000 Training loss: 0.156777
Epoch: 10 50000/60000 Training loss: 0.120779
Training loss: 0.156712
Test loss: 0.063928; Test accuracy: 9816/10000 (98.2%)

Epoch: 11 0/60000 Training loss: 0.081317
Epoch: 11 10000/60000 Training loss: 0.126896
Epoch: 11 20000/60000 Training loss: 0.112272
Epoch: 11 30000/60000 Training loss: 0.094589
Epoch: 11 40000/60000 Training loss: 0.140684
Epoch: 11 50000/60000 Training loss: 0.124801
Training loss: 0.147173
Test loss: 0.060264; Test accuracy: 9824/10000 (98.2%)

Epoch: 12 0/60000 Training loss: 0.228998
Epoch: 12 10000/60000 Training loss: 0.137370
Epoch: 12 20000/60000 Training loss: 0.184670
Epoch: 12 30000/60000 Training loss: 0.052335
Epoch: 12 40000/60000 Training loss: 0.089163
Epoch: 12 50000/60000 Training loss: 0.097943
Training loss: 0.139844
Test loss: 0.055946; Test accuracy: 9840/10000 (98.4%)

Epoch: 13 0/60000 Training loss: 0.121222
Epoch: 13 10000/60000 Training loss: 0.144989
Epoch: 13 20000/60000 Training loss: 0.071617
Epoch: 13 30000/60000 Training loss: 0.175697
Epoch: 13 40000/60000 Training loss: 0.080194
Epoch: 13 50000/60000 Training loss: 0.091808
Training loss: 0.130138
Test loss: 0.052599; Test accuracy: 9846/10000 (98.5%)

Epoch: 14 0/60000 Training loss: 0.126796
Epoch: 14 10000/60000 Training loss: 0.152898
Epoch: 14 20000/60000 Training loss: 0.110518
Epoch: 14 30000/60000 Training loss: 0.076385
Epoch: 14 40000/60000 Training loss: 0.076538
Epoch: 14 50000/60000 Training loss: 0.083239
Training loss: 0.124235
Test loss: 0.049937; Test accuracy: 9843/10000 (98.4%)

Epoch: 15 0/60000 Training loss: 0.098679
Epoch: 15 10000/60000 Training loss: 0.089399
Epoch: 15 20000/60000 Training loss: 0.047271
Epoch: 15 30000/60000 Training loss: 0.102767
Epoch: 15 40000/60000 Training loss: 0.099708
Epoch: 15 50000/60000 Training loss: 0.063071
Training loss: 0.117135
Test loss: 0.049241; Test accuracy: 9850/10000 (98.5%)

Epoch: 16 0/60000 Training loss: 0.210283
Epoch: 16 10000/60000 Training loss: 0.095400
Epoch: 16 20000/60000 Training loss: 0.189334
Epoch: 16 30000/60000 Training loss: 0.143780
Epoch: 16 40000/60000 Training loss: 0.120091
Epoch: 16 50000/60000 Training loss: 0.230654
Training loss: 0.116019
Test loss: 0.046759; Test accuracy: 9855/10000 (98.5%)

Epoch: 17 0/60000 Training loss: 0.094726
Epoch: 17 10000/60000 Training loss: 0.079474
Epoch: 17 20000/60000 Training loss: 0.149341
Epoch: 17 30000/60000 Training loss: 0.147778
Epoch: 17 40000/60000 Training loss: 0.271874
Epoch: 17 50000/60000 Training loss: 0.191399
Training loss: 0.109584
Test loss: 0.044465; Test accuracy: 9863/10000 (98.6%)

Epoch: 18 0/60000 Training loss: 0.080028
Epoch: 18 10000/60000 Training loss: 0.108934
Epoch: 18 20000/60000 Training loss: 0.060055
Epoch: 18 30000/60000 Training loss: 0.095993
Epoch: 18 40000/60000 Training loss: 0.115566
Epoch: 18 50000/60000 Training loss: 0.078925
Training loss: 0.105422
Test loss: 0.043555; Test accuracy: 9867/10000 (98.7%)

Epoch: 19 0/60000 Training loss: 0.073283
Epoch: 19 10000/60000 Training loss: 0.112425
Epoch: 19 20000/60000 Training loss: 0.111398
Epoch: 19 30000/60000 Training loss: 0.165601
Epoch: 19 40000/60000 Training loss: 0.060945
Epoch: 19 50000/60000 Training loss: 0.111235
Training loss: 0.104413
Test loss: 0.040733; Test accuracy: 9870/10000 (98.7%)

[I 2022-11-04 03:36:00,543] Trial 57 finished with value: 0.04073319584131241 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.18604397442344886, 'fc1_neurons': 60, 'optimizer': 'Adam', 'learning_rate': 1.9607713777273046e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 16, 'conv2_drop': 0.16465582893631792, 'fc1_neurons': 130, 'optimizer': 'SGD', 'learning_rate': 8.152905954962754e-05}
Epoch: 0 0/60000 Training loss: 2.316642
Epoch: 0 10000/60000 Training loss: 2.314390
Epoch: 0 20000/60000 Training loss: 2.299216
Epoch: 0 30000/60000 Training loss: 2.286612
Epoch: 0 40000/60000 Training loss: 2.291817
Epoch: 0 50000/60000 Training loss: 2.299844
Training loss: 2.302556
Test loss: 2.289477; Test accuracy: 1287/10000 (12.9%)

Epoch: 1 0/60000 Training loss: 2.314977
Epoch: 1 10000/60000 Training loss: 2.268759
Epoch: 1 20000/60000 Training loss: 2.290435
Epoch: 1 30000/60000 Training loss: 2.294792
Epoch: 1 40000/60000 Training loss: 2.282365
Epoch: 1 50000/60000 Training loss: 2.278308
Training loss: 2.284760
Test loss: 2.272450; Test accuracy: 2311/10000 (23.1%)

Epoch: 2 0/60000 Training loss: 2.274926
Epoch: 2 10000/60000 Training loss: 2.276857
Epoch: 2 20000/60000 Training loss: 2.277179
Epoch: 2 30000/60000 Training loss: 2.262691
Epoch: 2 40000/60000 Training loss: 2.264630
Epoch: 2 50000/60000 Training loss: 2.280128
Training loss: 2.269061
Test loss: 2.253596; Test accuracy: 3580/10000 (35.8%)

Epoch: 3 0/60000 Training loss: 2.248556
Epoch: 3 10000/60000 Training loss: 2.252752
Epoch: 3 20000/60000 Training loss: 2.245331
Epoch: 3 30000/60000 Training loss: 2.239826
Epoch: 3 40000/60000 Training loss: 2.222470
Epoch: 3 50000/60000 Training loss: 2.249456
Training loss: 2.249740
Test loss: 2.231411; Test accuracy: 4233/10000 (42.3%)

Epoch: 4 0/60000 Training loss: 2.234989
Epoch: 4 10000/60000 Training loss: 2.254641
Epoch: 4 20000/60000 Training loss: 2.225554
Epoch: 4 30000/60000 Training loss: 2.204525
Epoch: 4 40000/60000 Training loss: 2.218643
Epoch: 4 50000/60000 Training loss: 2.220361
Training loss: 2.229874
Test loss: 2.205765; Test accuracy: 4449/10000 (44.5%)

Epoch: 5 0/60000 Training loss: 2.202717
Epoch: 5 10000/60000 Training loss: 2.219971
Epoch: 5 20000/60000 Training loss: 2.167216
Epoch: 5 30000/60000 Training loss: 2.188318
Epoch: 5 40000/60000 Training loss: 2.218788
Epoch: 5 50000/60000 Training loss: 2.212201
Training loss: 2.206591
Test loss: 2.175899; Test accuracy: 4641/10000 (46.4%)

Epoch: 6 0/60000 Training loss: 2.162328
Epoch: 6 10000/60000 Training loss: 2.176474
Epoch: 6 20000/60000 Training loss: 2.157986
Epoch: 6 30000/60000 Training loss: 2.193632
Epoch: 6 40000/60000 Training loss: 2.167064
Epoch: 6 50000/60000 Training loss: 2.153996
Training loss: 2.179489
Test loss: 2.140842; Test accuracy: 4816/10000 (48.2%)

Epoch: 7 0/60000 Training loss: 2.211523
Epoch: 7 10000/60000 Training loss: 2.170877
Epoch: 7 20000/60000 Training loss: 2.146275
Epoch: 7 30000/60000 Training loss: 2.119991
Epoch: 7 40000/60000 Training loss: 2.099919
Epoch: 7 50000/60000 Training loss: 2.141250
Training loss: 2.148699
Test loss: 2.099788; Test accuracy: 4995/10000 (49.9%)

Epoch: 8 0/60000 Training loss: 2.118224
Epoch: 8 10000/60000 Training loss: 2.141144
Epoch: 8 20000/60000 Training loss: 2.113908
Epoch: 8 30000/60000 Training loss: 2.120494
Epoch: 8 40000/60000 Training loss: 2.114466
Epoch: 8 50000/60000 Training loss: 2.098996
Training loss: 2.113173
Test loss: 2.052098; Test accuracy: 5254/10000 (52.5%)

Epoch: 9 0/60000 Training loss: 2.077750
Epoch: 9 10000/60000 Training loss: 2.055093
Epoch: 9 20000/60000 Training loss: 2.083602
Epoch: 9 30000/60000 Training loss: 2.040682
Epoch: 9 40000/60000 Training loss: 2.063554
Epoch: 9 50000/60000 Training loss: 2.021337
Training loss: 2.070991
Test loss: 1.996914; Test accuracy: 5571/10000 (55.7%)

Epoch: 10 0/60000 Training loss: 2.027407
Epoch: 10 10000/60000 Training loss: 1.991120
Epoch: 10 20000/60000 Training loss: 2.056131
Epoch: 10 30000/60000 Training loss: 2.057804
Epoch: 10 40000/60000 Training loss: 2.003462
Epoch: 10 50000/60000 Training loss: 2.079477
Training loss: 2.025596
Test loss: 1.934511; Test accuracy: 5872/10000 (58.7%)

Epoch: 11 0/60000 Training loss: 2.010030
Epoch: 11 10000/60000 Training loss: 1.956442
Epoch: 11 20000/60000 Training loss: 2.069157
Epoch: 11 30000/60000 Training loss: 1.896003
Epoch: 11 40000/60000 Training loss: 2.046603
Epoch: 11 50000/60000 Training loss: 1.905829
Training loss: 1.971262
Test loss: 1.864253; Test accuracy: 6219/10000 (62.2%)

Epoch: 12 0/60000 Training loss: 1.988670
Epoch: 12 10000/60000 Training loss: 1.909046
Epoch: 12 20000/60000 Training loss: 1.952931
Epoch: 12 30000/60000 Training loss: 1.846204
Epoch: 12 40000/60000 Training loss: 1.921959
Epoch: 12 50000/60000 Training loss: 1.853460
Training loss: 1.914656
Test loss: 1.787641; Test accuracy: 6507/10000 (65.1%)

Epoch: 13 0/60000 Training loss: 1.889343
Epoch: 13 10000/60000 Training loss: 1.879087
Epoch: 13 20000/60000 Training loss: 1.871703
Epoch: 13 30000/60000 Training loss: 1.815247
Epoch: 13 40000/60000 Training loss: 1.784749
Epoch: 13 50000/60000 Training loss: 1.870683
Training loss: 1.852876
Test loss: 1.705360; Test accuracy: 6742/10000 (67.4%)

Epoch: 14 0/60000 Training loss: 1.813103
Epoch: 14 10000/60000 Training loss: 1.932026
Epoch: 14 20000/60000 Training loss: 1.701015
Epoch: 14 30000/60000 Training loss: 1.726906
Epoch: 14 40000/60000 Training loss: 1.719326
Epoch: 14 50000/60000 Training loss: 1.851541
Training loss: 1.790069
Test loss: 1.619707; Test accuracy: 6989/10000 (69.9%)

Epoch: 15 0/60000 Training loss: 1.835197
Epoch: 15 10000/60000 Training loss: 1.717732
Epoch: 15 20000/60000 Training loss: 1.703470
Epoch: 15 30000/60000 Training loss: 1.750008
Epoch: 15 40000/60000 Training loss: 1.786206
Epoch: 15 50000/60000 Training loss: 1.730075
Training loss: 1.723318
Test loss: 1.532249; Test accuracy: 7186/10000 (71.9%)

Epoch: 16 0/60000 Training loss: 1.564205
Epoch: 16 10000/60000 Training loss: 1.743149
Epoch: 16 20000/60000 Training loss: 1.671305
Epoch: 16 30000/60000 Training loss: 1.568564
Epoch: 16 40000/60000 Training loss: 1.617204
Epoch: 16 50000/60000 Training loss: 1.564679
Training loss: 1.653538
Test loss: 1.443414; Test accuracy: 7367/10000 (73.7%)

Epoch: 17 0/60000 Training loss: 1.700421
Epoch: 17 10000/60000 Training loss: 1.584089
Epoch: 17 20000/60000 Training loss: 1.606418
Epoch: 17 30000/60000 Training loss: 1.621910
Epoch: 17 40000/60000 Training loss: 1.581091
Epoch: 17 50000/60000 Training loss: 1.629566
Training loss: 1.590294
Test loss: 1.357152; Test accuracy: 7554/10000 (75.5%)

Epoch: 18 0/60000 Training loss: 1.483747
Epoch: 18 10000/60000 Training loss: 1.502055
Epoch: 18 20000/60000 Training loss: 1.513436
Epoch: 18 30000/60000 Training loss: 1.614494
Epoch: 18 40000/60000 Training loss: 1.528288
Epoch: 18 50000/60000 Training loss: 1.487040
Training loss: 1.517571
Test loss: 1.273844; Test accuracy: 7680/10000 (76.8%)

Epoch: 19 0/60000 Training loss: 1.519310
Epoch: 19 10000/60000 Training loss: 1.475584
Epoch: 19 20000/60000 Training loss: 1.624028
Epoch: 19 30000/60000 Training loss: 1.427217
Epoch: 19 40000/60000 Training loss: 1.465744
Epoch: 19 50000/60000 Training loss: 1.577683
Training loss: 1.457355
Test loss: 1.195519; Test accuracy: 7782/10000 (77.8%)

[I 2022-11-04 03:40:37,980] Trial 58 finished with value: 1.1955187320709229 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 16, 'conv2_drop': 0.16465582893631792, 'fc1_neurons': 130, 'optimizer': 'SGD', 'learning_rate': 8.152905954962754e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.19165101855921463, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00019610079661717345}
Epoch: 0 0/60000 Training loss: 2.290833
Epoch: 0 10000/60000 Training loss: 0.436522
Epoch: 0 20000/60000 Training loss: 0.204113
Epoch: 0 30000/60000 Training loss: 0.266241
Epoch: 0 40000/60000 Training loss: 0.155639
Epoch: 0 50000/60000 Training loss: 0.099529
Training loss: 0.353934
Test loss: 0.071900; Test accuracy: 9789/10000 (97.9%)

Epoch: 1 0/60000 Training loss: 0.199561
Epoch: 1 10000/60000 Training loss: 0.153955
Epoch: 1 20000/60000 Training loss: 0.167085
Epoch: 1 30000/60000 Training loss: 0.100463
Epoch: 1 40000/60000 Training loss: 0.152382
Epoch: 1 50000/60000 Training loss: 0.073167
Training loss: 0.105342
Test loss: 0.044995; Test accuracy: 9856/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.064625
Epoch: 2 10000/60000 Training loss: 0.087708
Epoch: 2 20000/60000 Training loss: 0.080775
Epoch: 2 30000/60000 Training loss: 0.029303
Epoch: 2 40000/60000 Training loss: 0.048108
Epoch: 2 50000/60000 Training loss: 0.032145
Training loss: 0.075487
Test loss: 0.036979; Test accuracy: 9881/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.041604
Epoch: 3 10000/60000 Training loss: 0.028997
Epoch: 3 20000/60000 Training loss: 0.060252
Epoch: 3 30000/60000 Training loss: 0.116625
Epoch: 3 40000/60000 Training loss: 0.006991
Epoch: 3 50000/60000 Training loss: 0.067088
Training loss: 0.059330
Test loss: 0.029108; Test accuracy: 9906/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.120704
Epoch: 4 10000/60000 Training loss: 0.024254
Epoch: 4 20000/60000 Training loss: 0.056587
Epoch: 4 30000/60000 Training loss: 0.029306
Epoch: 4 40000/60000 Training loss: 0.040896
Epoch: 4 50000/60000 Training loss: 0.084351
Training loss: 0.052552
Test loss: 0.027192; Test accuracy: 9911/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.031093
Epoch: 5 10000/60000 Training loss: 0.009399
Epoch: 5 20000/60000 Training loss: 0.004835
Epoch: 5 30000/60000 Training loss: 0.043056
Epoch: 5 40000/60000 Training loss: 0.107828
Epoch: 5 50000/60000 Training loss: 0.058176
Training loss: 0.044812
Test loss: 0.024411; Test accuracy: 9922/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.017546
Epoch: 6 10000/60000 Training loss: 0.095018
Epoch: 6 20000/60000 Training loss: 0.061809
Epoch: 6 30000/60000 Training loss: 0.037480
Epoch: 6 40000/60000 Training loss: 0.044846
Epoch: 6 50000/60000 Training loss: 0.053611
Training loss: 0.039817
Test loss: 0.024330; Test accuracy: 9923/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.005444
Epoch: 7 10000/60000 Training loss: 0.035396
Epoch: 7 20000/60000 Training loss: 0.033853
Epoch: 7 30000/60000 Training loss: 0.023835
Epoch: 7 40000/60000 Training loss: 0.032692
Epoch: 7 50000/60000 Training loss: 0.021577
Training loss: 0.036022
Test loss: 0.021247; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.032848
Epoch: 8 10000/60000 Training loss: 0.044032
Epoch: 8 20000/60000 Training loss: 0.016538
Epoch: 8 30000/60000 Training loss: 0.005762
Epoch: 8 40000/60000 Training loss: 0.023200
Epoch: 8 50000/60000 Training loss: 0.040624
Training loss: 0.031223
Test loss: 0.023274; Test accuracy: 9928/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.018549
Epoch: 9 10000/60000 Training loss: 0.015315
Epoch: 9 20000/60000 Training loss: 0.022532
Epoch: 9 30000/60000 Training loss: 0.069643
Epoch: 9 40000/60000 Training loss: 0.024362
Epoch: 9 50000/60000 Training loss: 0.080863
Training loss: 0.029231
Test loss: 0.021585; Test accuracy: 9930/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.015831
Epoch: 10 10000/60000 Training loss: 0.044863
Epoch: 10 20000/60000 Training loss: 0.088814
Epoch: 10 30000/60000 Training loss: 0.020030
Epoch: 10 40000/60000 Training loss: 0.008034
Epoch: 10 50000/60000 Training loss: 0.007151
Training loss: 0.027005
Test loss: 0.022192; Test accuracy: 9927/10000 (99.3%)

[I 2022-11-04 03:43:12,526] Trial 59 finished with value: 0.021247200667858124 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.19165101855921463, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00019610079661717345}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18144906307363984, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00010263314053293932}
Epoch: 0 0/60000 Training loss: 2.317083
Epoch: 0 10000/60000 Training loss: 0.584483
Epoch: 0 20000/60000 Training loss: 0.368981
Epoch: 0 30000/60000 Training loss: 0.297125
Epoch: 0 40000/60000 Training loss: 0.253701
Epoch: 0 50000/60000 Training loss: 0.203651
Training loss: 0.420475
Test loss: 0.090382; Test accuracy: 9726/10000 (97.3%)

Epoch: 1 0/60000 Training loss: 0.244761
Epoch: 1 10000/60000 Training loss: 0.144901
Epoch: 1 20000/60000 Training loss: 0.085493
Epoch: 1 30000/60000 Training loss: 0.097104
Epoch: 1 40000/60000 Training loss: 0.034261
Epoch: 1 50000/60000 Training loss: 0.067027
Training loss: 0.127453
Test loss: 0.056083; Test accuracy: 9818/10000 (98.2%)

Epoch: 2 0/60000 Training loss: 0.078550
Epoch: 2 10000/60000 Training loss: 0.140773
Epoch: 2 20000/60000 Training loss: 0.117085
Epoch: 2 30000/60000 Training loss: 0.046750
Epoch: 2 40000/60000 Training loss: 0.092100
Epoch: 2 50000/60000 Training loss: 0.131404
Training loss: 0.089423
Test loss: 0.041156; Test accuracy: 9859/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.100756
Epoch: 3 10000/60000 Training loss: 0.048961
Epoch: 3 20000/60000 Training loss: 0.110138
Epoch: 3 30000/60000 Training loss: 0.074720
Epoch: 3 40000/60000 Training loss: 0.062672
Epoch: 3 50000/60000 Training loss: 0.123213
Training loss: 0.071981
Test loss: 0.036031; Test accuracy: 9874/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.027952
Epoch: 4 10000/60000 Training loss: 0.071484
Epoch: 4 20000/60000 Training loss: 0.032232
Epoch: 4 30000/60000 Training loss: 0.044131
Epoch: 4 40000/60000 Training loss: 0.066555
Epoch: 4 50000/60000 Training loss: 0.123121
Training loss: 0.059400
Test loss: 0.030220; Test accuracy: 9899/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.024309
Epoch: 5 10000/60000 Training loss: 0.107134
Epoch: 5 20000/60000 Training loss: 0.056617
Epoch: 5 30000/60000 Training loss: 0.038621
Epoch: 5 40000/60000 Training loss: 0.010973
Epoch: 5 50000/60000 Training loss: 0.156910
Training loss: 0.054341
Test loss: 0.028165; Test accuracy: 9902/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.012759
Epoch: 6 10000/60000 Training loss: 0.018470
Epoch: 6 20000/60000 Training loss: 0.068664
Epoch: 6 30000/60000 Training loss: 0.044187
Epoch: 6 40000/60000 Training loss: 0.032245
Epoch: 6 50000/60000 Training loss: 0.043400
Training loss: 0.046525
Test loss: 0.026229; Test accuracy: 9911/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.007971
Epoch: 7 10000/60000 Training loss: 0.075826
Epoch: 7 20000/60000 Training loss: 0.053938
Epoch: 7 30000/60000 Training loss: 0.072493
Epoch: 7 40000/60000 Training loss: 0.031580
Epoch: 7 50000/60000 Training loss: 0.029425
Training loss: 0.042679
Test loss: 0.026838; Test accuracy: 9909/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.093433
Epoch: 8 10000/60000 Training loss: 0.012674
Epoch: 8 20000/60000 Training loss: 0.042012
Epoch: 8 30000/60000 Training loss: 0.057231
Epoch: 8 40000/60000 Training loss: 0.016625
Epoch: 8 50000/60000 Training loss: 0.020091
Training loss: 0.039642
Test loss: 0.022505; Test accuracy: 9920/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.056166
Epoch: 9 10000/60000 Training loss: 0.003515
Epoch: 9 20000/60000 Training loss: 0.021323
Epoch: 9 30000/60000 Training loss: 0.055849
Epoch: 9 40000/60000 Training loss: 0.015391
Epoch: 9 50000/60000 Training loss: 0.029820
Training loss: 0.034509
Test loss: 0.024107; Test accuracy: 9919/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.006020
Epoch: 10 10000/60000 Training loss: 0.015279
Epoch: 10 20000/60000 Training loss: 0.033035
Epoch: 10 30000/60000 Training loss: 0.015672
Epoch: 10 40000/60000 Training loss: 0.020504
Epoch: 10 50000/60000 Training loss: 0.055554
Training loss: 0.031801
Test loss: 0.020968; Test accuracy: 9927/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.005618
Epoch: 11 10000/60000 Training loss: 0.035868
Epoch: 11 20000/60000 Training loss: 0.017154
Epoch: 11 30000/60000 Training loss: 0.006153
Epoch: 11 40000/60000 Training loss: 0.036422
Epoch: 11 50000/60000 Training loss: 0.058831
Training loss: 0.029132
Test loss: 0.019564; Test accuracy: 9932/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.006072
Epoch: 12 10000/60000 Training loss: 0.007503
Epoch: 12 20000/60000 Training loss: 0.042743
Epoch: 12 30000/60000 Training loss: 0.032071
Epoch: 12 40000/60000 Training loss: 0.008804
Epoch: 12 50000/60000 Training loss: 0.028864
Training loss: 0.027622
Test loss: 0.020035; Test accuracy: 9925/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.021339
Epoch: 13 10000/60000 Training loss: 0.021464
Epoch: 13 20000/60000 Training loss: 0.010019
Epoch: 13 30000/60000 Training loss: 0.025056
Epoch: 13 40000/60000 Training loss: 0.007206
Epoch: 13 50000/60000 Training loss: 0.051081
Training loss: 0.025310
Test loss: 0.018397; Test accuracy: 9937/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.001935
Epoch: 14 10000/60000 Training loss: 0.004081
Epoch: 14 20000/60000 Training loss: 0.003149
Epoch: 14 30000/60000 Training loss: 0.022056
Epoch: 14 40000/60000 Training loss: 0.004107
Epoch: 14 50000/60000 Training loss: 0.024109
Training loss: 0.023393
Test loss: 0.017601; Test accuracy: 9945/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.004609
Epoch: 15 10000/60000 Training loss: 0.005797
Epoch: 15 20000/60000 Training loss: 0.004789
Epoch: 15 30000/60000 Training loss: 0.010395
Epoch: 15 40000/60000 Training loss: 0.020773
Epoch: 15 50000/60000 Training loss: 0.017820
Training loss: 0.021402
Test loss: 0.019218; Test accuracy: 9936/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.006644
Epoch: 16 10000/60000 Training loss: 0.002321
Epoch: 16 20000/60000 Training loss: 0.024339
Epoch: 16 30000/60000 Training loss: 0.027148
Epoch: 16 40000/60000 Training loss: 0.028833
Epoch: 16 50000/60000 Training loss: 0.014668
Training loss: 0.020071
Test loss: 0.018883; Test accuracy: 9933/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.004932
Epoch: 17 10000/60000 Training loss: 0.040778
Epoch: 17 20000/60000 Training loss: 0.030712
Epoch: 17 30000/60000 Training loss: 0.027644
Epoch: 17 40000/60000 Training loss: 0.036935
Epoch: 17 50000/60000 Training loss: 0.022810
Training loss: 0.018138
Test loss: 0.017655; Test accuracy: 9942/10000 (99.4%)

[I 2022-11-04 03:47:25,016] Trial 60 finished with value: 0.017601357772946358 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18144906307363984, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00010263314053293932}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18132928248954236, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00010231980792408968}
Epoch: 0 0/60000 Training loss: 2.308255
Epoch: 0 10000/60000 Training loss: 0.703636
Epoch: 0 20000/60000 Training loss: 0.389517
Epoch: 0 30000/60000 Training loss: 0.197985
Epoch: 0 40000/60000 Training loss: 0.114797
Epoch: 0 50000/60000 Training loss: 0.306272
Training loss: 0.429328
Test loss: 0.093634; Test accuracy: 9722/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.210588
Epoch: 1 10000/60000 Training loss: 0.173576
Epoch: 1 20000/60000 Training loss: 0.106883
Epoch: 1 30000/60000 Training loss: 0.145779
Epoch: 1 40000/60000 Training loss: 0.119524
Epoch: 1 50000/60000 Training loss: 0.132477
Training loss: 0.130171
Test loss: 0.057577; Test accuracy: 9816/10000 (98.2%)

Epoch: 2 0/60000 Training loss: 0.112579
Epoch: 2 10000/60000 Training loss: 0.118223
Epoch: 2 20000/60000 Training loss: 0.094067
Epoch: 2 30000/60000 Training loss: 0.057835
Epoch: 2 40000/60000 Training loss: 0.096023
Epoch: 2 50000/60000 Training loss: 0.067759
Training loss: 0.093122
Test loss: 0.041900; Test accuracy: 9863/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.088633
Epoch: 3 10000/60000 Training loss: 0.083380
Epoch: 3 20000/60000 Training loss: 0.044550
Epoch: 3 30000/60000 Training loss: 0.104910
Epoch: 3 40000/60000 Training loss: 0.089774
Epoch: 3 50000/60000 Training loss: 0.041477
Training loss: 0.074523
Test loss: 0.035605; Test accuracy: 9886/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.033298
Epoch: 4 10000/60000 Training loss: 0.074676
Epoch: 4 20000/60000 Training loss: 0.054548
Epoch: 4 30000/60000 Training loss: 0.039124
Epoch: 4 40000/60000 Training loss: 0.079547
Epoch: 4 50000/60000 Training loss: 0.109476
Training loss: 0.063963
Test loss: 0.031179; Test accuracy: 9899/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.032943
Epoch: 5 10000/60000 Training loss: 0.067365
Epoch: 5 20000/60000 Training loss: 0.049515
Epoch: 5 30000/60000 Training loss: 0.102533
Epoch: 5 40000/60000 Training loss: 0.060067
Epoch: 5 50000/60000 Training loss: 0.017386
Training loss: 0.052926
Test loss: 0.030863; Test accuracy: 9894/10000 (98.9%)

Epoch: 6 0/60000 Training loss: 0.027126
Epoch: 6 10000/60000 Training loss: 0.120105
Epoch: 6 20000/60000 Training loss: 0.039520
Epoch: 6 30000/60000 Training loss: 0.084743
Epoch: 6 40000/60000 Training loss: 0.022685
Epoch: 6 50000/60000 Training loss: 0.026300
Training loss: 0.046724
Test loss: 0.027250; Test accuracy: 9902/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.010194
Epoch: 7 10000/60000 Training loss: 0.032736
Epoch: 7 20000/60000 Training loss: 0.120159
Epoch: 7 30000/60000 Training loss: 0.043305
Epoch: 7 40000/60000 Training loss: 0.009855
Epoch: 7 50000/60000 Training loss: 0.023983
Training loss: 0.042519
Test loss: 0.023549; Test accuracy: 9912/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.080962
Epoch: 8 10000/60000 Training loss: 0.005877
Epoch: 8 20000/60000 Training loss: 0.006780
Epoch: 8 30000/60000 Training loss: 0.015097
Epoch: 8 40000/60000 Training loss: 0.029801
Epoch: 8 50000/60000 Training loss: 0.076110
Training loss: 0.038907
Test loss: 0.022164; Test accuracy: 9926/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.075279
Epoch: 9 10000/60000 Training loss: 0.030334
Epoch: 9 20000/60000 Training loss: 0.072642
Epoch: 9 30000/60000 Training loss: 0.055498
Epoch: 9 40000/60000 Training loss: 0.023716
Epoch: 9 50000/60000 Training loss: 0.046011
Training loss: 0.034805
Test loss: 0.020654; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.024982
Epoch: 10 10000/60000 Training loss: 0.066841
Epoch: 10 20000/60000 Training loss: 0.062833
Epoch: 10 30000/60000 Training loss: 0.048688
Epoch: 10 40000/60000 Training loss: 0.018234
Epoch: 10 50000/60000 Training loss: 0.062070
Training loss: 0.032295
Test loss: 0.022563; Test accuracy: 9924/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.017583
Epoch: 11 10000/60000 Training loss: 0.053639
Epoch: 11 20000/60000 Training loss: 0.002220
Epoch: 11 30000/60000 Training loss: 0.010605
Epoch: 11 40000/60000 Training loss: 0.007487
Epoch: 11 50000/60000 Training loss: 0.008548
Training loss: 0.029866
Test loss: 0.022120; Test accuracy: 9920/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.010191
Epoch: 12 10000/60000 Training loss: 0.018647
Epoch: 12 20000/60000 Training loss: 0.011440
Epoch: 12 30000/60000 Training loss: 0.011644
Epoch: 12 40000/60000 Training loss: 0.015948
Epoch: 12 50000/60000 Training loss: 0.065266
Training loss: 0.027226
Test loss: 0.019226; Test accuracy: 9937/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.012281
Epoch: 13 10000/60000 Training loss: 0.006612
Epoch: 13 20000/60000 Training loss: 0.020466
Epoch: 13 30000/60000 Training loss: 0.004924
Epoch: 13 40000/60000 Training loss: 0.002218
Epoch: 13 50000/60000 Training loss: 0.006586
Training loss: 0.025888
Test loss: 0.018025; Test accuracy: 9935/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.008628
Epoch: 14 10000/60000 Training loss: 0.019569
Epoch: 14 20000/60000 Training loss: 0.011627
Epoch: 14 30000/60000 Training loss: 0.022481
Epoch: 14 40000/60000 Training loss: 0.005838
Epoch: 14 50000/60000 Training loss: 0.014658
Training loss: 0.023568
Test loss: 0.018908; Test accuracy: 9940/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.026388
Epoch: 15 10000/60000 Training loss: 0.016883
Epoch: 15 20000/60000 Training loss: 0.005309
Epoch: 15 30000/60000 Training loss: 0.013709
Epoch: 15 40000/60000 Training loss: 0.024109
Epoch: 15 50000/60000 Training loss: 0.154341
Training loss: 0.022038
Test loss: 0.021820; Test accuracy: 9931/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.009055
Epoch: 16 10000/60000 Training loss: 0.013888
Epoch: 16 20000/60000 Training loss: 0.016900
Epoch: 16 30000/60000 Training loss: 0.037176
Epoch: 16 40000/60000 Training loss: 0.002831
Epoch: 16 50000/60000 Training loss: 0.005496
Training loss: 0.020326
Test loss: 0.019452; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 03:51:22,929] Trial 61 finished with value: 0.018025200814008713 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18132928248954236, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00010231980792408968}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18149238924786817, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 9.971325104100295e-05}
Epoch: 0 0/60000 Training loss: 2.290201
Epoch: 0 10000/60000 Training loss: 0.484784
Epoch: 0 20000/60000 Training loss: 0.482106
Epoch: 0 30000/60000 Training loss: 0.275100
Epoch: 0 40000/60000 Training loss: 0.183698
Epoch: 0 50000/60000 Training loss: 0.217408
Training loss: 0.431135
Test loss: 0.094478; Test accuracy: 9718/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.179299
Epoch: 1 10000/60000 Training loss: 0.223616
Epoch: 1 20000/60000 Training loss: 0.180512
Epoch: 1 30000/60000 Training loss: 0.211904
Epoch: 1 40000/60000 Training loss: 0.096861
Epoch: 1 50000/60000 Training loss: 0.111263
Training loss: 0.131692
Test loss: 0.054536; Test accuracy: 9828/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.139581
Epoch: 2 10000/60000 Training loss: 0.062241
Epoch: 2 20000/60000 Training loss: 0.097731
Epoch: 2 30000/60000 Training loss: 0.070311
Epoch: 2 40000/60000 Training loss: 0.068769
Epoch: 2 50000/60000 Training loss: 0.131887
Training loss: 0.094307
Test loss: 0.048249; Test accuracy: 9850/10000 (98.5%)

Epoch: 3 0/60000 Training loss: 0.106517
Epoch: 3 10000/60000 Training loss: 0.082051
Epoch: 3 20000/60000 Training loss: 0.181296
Epoch: 3 30000/60000 Training loss: 0.039882
Epoch: 3 40000/60000 Training loss: 0.018673
Epoch: 3 50000/60000 Training loss: 0.046375
Training loss: 0.074415
Test loss: 0.035098; Test accuracy: 9888/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.050023
Epoch: 4 10000/60000 Training loss: 0.017323
Epoch: 4 20000/60000 Training loss: 0.092629
Epoch: 4 30000/60000 Training loss: 0.045662
Epoch: 4 40000/60000 Training loss: 0.118504
Epoch: 4 50000/60000 Training loss: 0.069309
Training loss: 0.062389
Test loss: 0.029385; Test accuracy: 9900/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.053971
Epoch: 5 10000/60000 Training loss: 0.095597
Epoch: 5 20000/60000 Training loss: 0.039486
Epoch: 5 30000/60000 Training loss: 0.119620
Epoch: 5 40000/60000 Training loss: 0.053410
Epoch: 5 50000/60000 Training loss: 0.110558
Training loss: 0.055960
Test loss: 0.030382; Test accuracy: 9902/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.087611
Epoch: 6 10000/60000 Training loss: 0.044840
Epoch: 6 20000/60000 Training loss: 0.025047
Epoch: 6 30000/60000 Training loss: 0.042540
Epoch: 6 40000/60000 Training loss: 0.025472
Epoch: 6 50000/60000 Training loss: 0.030472
Training loss: 0.048153
Test loss: 0.025989; Test accuracy: 9909/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.079727
Epoch: 7 10000/60000 Training loss: 0.055367
Epoch: 7 20000/60000 Training loss: 0.048586
Epoch: 7 30000/60000 Training loss: 0.040721
Epoch: 7 40000/60000 Training loss: 0.022189
Epoch: 7 50000/60000 Training loss: 0.028956
Training loss: 0.042867
Test loss: 0.022487; Test accuracy: 9921/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.027207
Epoch: 8 10000/60000 Training loss: 0.010373
Epoch: 8 20000/60000 Training loss: 0.038625
Epoch: 8 30000/60000 Training loss: 0.021640
Epoch: 8 40000/60000 Training loss: 0.059987
Epoch: 8 50000/60000 Training loss: 0.042612
Training loss: 0.037628
Test loss: 0.022721; Test accuracy: 9924/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.039406
Epoch: 9 10000/60000 Training loss: 0.011375
Epoch: 9 20000/60000 Training loss: 0.035518
Epoch: 9 30000/60000 Training loss: 0.057998
Epoch: 9 40000/60000 Training loss: 0.067963
Epoch: 9 50000/60000 Training loss: 0.044887
Training loss: 0.035837
Test loss: 0.024349; Test accuracy: 9913/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.022214
Epoch: 10 10000/60000 Training loss: 0.028615
Epoch: 10 20000/60000 Training loss: 0.014322
Epoch: 10 30000/60000 Training loss: 0.026768
Epoch: 10 40000/60000 Training loss: 0.014524
Epoch: 10 50000/60000 Training loss: 0.078872
Training loss: 0.032546
Test loss: 0.021441; Test accuracy: 9924/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.004171
Epoch: 11 10000/60000 Training loss: 0.024072
Epoch: 11 20000/60000 Training loss: 0.044519
Epoch: 11 30000/60000 Training loss: 0.022452
Epoch: 11 40000/60000 Training loss: 0.009933
Epoch: 11 50000/60000 Training loss: 0.019110
Training loss: 0.030318
Test loss: 0.020774; Test accuracy: 9928/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.020001
Epoch: 12 10000/60000 Training loss: 0.009873
Epoch: 12 20000/60000 Training loss: 0.010402
Epoch: 12 30000/60000 Training loss: 0.077157
Epoch: 12 40000/60000 Training loss: 0.008874
Epoch: 12 50000/60000 Training loss: 0.014178
Training loss: 0.027408
Test loss: 0.019780; Test accuracy: 9930/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.018216
Epoch: 13 10000/60000 Training loss: 0.030507
Epoch: 13 20000/60000 Training loss: 0.013091
Epoch: 13 30000/60000 Training loss: 0.002521
Epoch: 13 40000/60000 Training loss: 0.022288
Epoch: 13 50000/60000 Training loss: 0.046120
Training loss: 0.026083
Test loss: 0.019849; Test accuracy: 9933/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.002226
Epoch: 14 10000/60000 Training loss: 0.002540
Epoch: 14 20000/60000 Training loss: 0.018172
Epoch: 14 30000/60000 Training loss: 0.017592
Epoch: 14 40000/60000 Training loss: 0.006330
Epoch: 14 50000/60000 Training loss: 0.030938
Training loss: 0.024125
Test loss: 0.018613; Test accuracy: 9932/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.020776
Epoch: 15 10000/60000 Training loss: 0.033242
Epoch: 15 20000/60000 Training loss: 0.024647
Epoch: 15 30000/60000 Training loss: 0.004893
Epoch: 15 40000/60000 Training loss: 0.011414
Epoch: 15 50000/60000 Training loss: 0.003921
Training loss: 0.022443
Test loss: 0.019724; Test accuracy: 9932/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.038286
Epoch: 16 10000/60000 Training loss: 0.003289
Epoch: 16 20000/60000 Training loss: 0.036119
Epoch: 16 30000/60000 Training loss: 0.027282
Epoch: 16 40000/60000 Training loss: 0.051704
Epoch: 16 50000/60000 Training loss: 0.047649
Training loss: 0.021470
Test loss: 0.018890; Test accuracy: 9929/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.005135
Epoch: 17 10000/60000 Training loss: 0.041762
Epoch: 17 20000/60000 Training loss: 0.032183
Epoch: 17 30000/60000 Training loss: 0.028535
Epoch: 17 40000/60000 Training loss: 0.010073
Epoch: 17 50000/60000 Training loss: 0.024620
Training loss: 0.020051
Test loss: 0.018941; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 03:55:35,105] Trial 62 finished with value: 0.018613144755363464 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18149238924786817, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 9.971325104100295e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.17192690438572952, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 7.002838764373947e-05}
Epoch: 0 0/60000 Training loss: 2.312281
Epoch: 0 10000/60000 Training loss: 0.688760
Epoch: 0 20000/60000 Training loss: 0.348983
Epoch: 0 30000/60000 Training loss: 0.338747
Epoch: 0 40000/60000 Training loss: 0.230246
Epoch: 0 50000/60000 Training loss: 0.259052
Training loss: 0.464463
Test loss: 0.110207; Test accuracy: 9658/10000 (96.6%)

Epoch: 1 0/60000 Training loss: 0.191920
Epoch: 1 10000/60000 Training loss: 0.255988
Epoch: 1 20000/60000 Training loss: 0.093657
Epoch: 1 30000/60000 Training loss: 0.157531
Epoch: 1 40000/60000 Training loss: 0.064973
Epoch: 1 50000/60000 Training loss: 0.196953
Training loss: 0.143220
Test loss: 0.066630; Test accuracy: 9800/10000 (98.0%)

Epoch: 2 0/60000 Training loss: 0.148193
Epoch: 2 10000/60000 Training loss: 0.108809
Epoch: 2 20000/60000 Training loss: 0.201153
Epoch: 2 30000/60000 Training loss: 0.105151
Epoch: 2 40000/60000 Training loss: 0.100314
Epoch: 2 50000/60000 Training loss: 0.074862
Training loss: 0.100935
Test loss: 0.050089; Test accuracy: 9844/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.068979
Epoch: 3 10000/60000 Training loss: 0.063499
Epoch: 3 20000/60000 Training loss: 0.253684
Epoch: 3 30000/60000 Training loss: 0.106635
Epoch: 3 40000/60000 Training loss: 0.063904
Epoch: 3 50000/60000 Training loss: 0.034158
Training loss: 0.081195
Test loss: 0.038275; Test accuracy: 9877/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.071863
Epoch: 4 10000/60000 Training loss: 0.049839
Epoch: 4 20000/60000 Training loss: 0.065225
Epoch: 4 30000/60000 Training loss: 0.113264
Epoch: 4 40000/60000 Training loss: 0.073479
Epoch: 4 50000/60000 Training loss: 0.030971
Training loss: 0.068367
Test loss: 0.034922; Test accuracy: 9881/10000 (98.8%)

Epoch: 5 0/60000 Training loss: 0.025726
Epoch: 5 10000/60000 Training loss: 0.094629
Epoch: 5 20000/60000 Training loss: 0.114608
Epoch: 5 30000/60000 Training loss: 0.034530
Epoch: 5 40000/60000 Training loss: 0.054404
Epoch: 5 50000/60000 Training loss: 0.133224
Training loss: 0.058779
Test loss: 0.033339; Test accuracy: 9887/10000 (98.9%)

Epoch: 6 0/60000 Training loss: 0.076403
Epoch: 6 10000/60000 Training loss: 0.009040
Epoch: 6 20000/60000 Training loss: 0.067425
Epoch: 6 30000/60000 Training loss: 0.007532
Epoch: 6 40000/60000 Training loss: 0.032705
Epoch: 6 50000/60000 Training loss: 0.070984
Training loss: 0.053375
Test loss: 0.029852; Test accuracy: 9898/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.056842
Epoch: 7 10000/60000 Training loss: 0.052046
Epoch: 7 20000/60000 Training loss: 0.019945
Epoch: 7 30000/60000 Training loss: 0.031431
Epoch: 7 40000/60000 Training loss: 0.036490
Epoch: 7 50000/60000 Training loss: 0.017505
Training loss: 0.047028
Test loss: 0.029097; Test accuracy: 9906/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.017848
Epoch: 8 10000/60000 Training loss: 0.037214
Epoch: 8 20000/60000 Training loss: 0.053757
Epoch: 8 30000/60000 Training loss: 0.037796
Epoch: 8 40000/60000 Training loss: 0.015261
Epoch: 8 50000/60000 Training loss: 0.017517
Training loss: 0.043181
Test loss: 0.024660; Test accuracy: 9917/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.005109
Epoch: 9 10000/60000 Training loss: 0.028087
Epoch: 9 20000/60000 Training loss: 0.015338
Epoch: 9 30000/60000 Training loss: 0.038102
Epoch: 9 40000/60000 Training loss: 0.034570
Epoch: 9 50000/60000 Training loss: 0.010930
Training loss: 0.039661
Test loss: 0.023832; Test accuracy: 9922/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.029868
Epoch: 10 10000/60000 Training loss: 0.038119
Epoch: 10 20000/60000 Training loss: 0.024449
Epoch: 10 30000/60000 Training loss: 0.048870
Epoch: 10 40000/60000 Training loss: 0.013581
Epoch: 10 50000/60000 Training loss: 0.062421
Training loss: 0.035284
Test loss: 0.023535; Test accuracy: 9923/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.005928
Epoch: 11 10000/60000 Training loss: 0.021341
Epoch: 11 20000/60000 Training loss: 0.043826
Epoch: 11 30000/60000 Training loss: 0.011753
Epoch: 11 40000/60000 Training loss: 0.006883
Epoch: 11 50000/60000 Training loss: 0.006335
Training loss: 0.032913
Test loss: 0.023630; Test accuracy: 9915/10000 (99.1%)

Epoch: 12 0/60000 Training loss: 0.008630
Epoch: 12 10000/60000 Training loss: 0.013282
Epoch: 12 20000/60000 Training loss: 0.027685
Epoch: 12 30000/60000 Training loss: 0.007468
Epoch: 12 40000/60000 Training loss: 0.042144
Epoch: 12 50000/60000 Training loss: 0.022325
Training loss: 0.030829
Test loss: 0.022269; Test accuracy: 9927/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.038612
Epoch: 13 10000/60000 Training loss: 0.101595
Epoch: 13 20000/60000 Training loss: 0.005432
Epoch: 13 30000/60000 Training loss: 0.038637
Epoch: 13 40000/60000 Training loss: 0.065154
Epoch: 13 50000/60000 Training loss: 0.005511
Training loss: 0.028313
Test loss: 0.022293; Test accuracy: 9918/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.016670
Epoch: 14 10000/60000 Training loss: 0.011324
Epoch: 14 20000/60000 Training loss: 0.034857
Epoch: 14 30000/60000 Training loss: 0.009451
Epoch: 14 40000/60000 Training loss: 0.032214
Epoch: 14 50000/60000 Training loss: 0.046361
Training loss: 0.025882
Test loss: 0.022523; Test accuracy: 9926/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.027188
Epoch: 15 10000/60000 Training loss: 0.003927
Epoch: 15 20000/60000 Training loss: 0.001773
Epoch: 15 30000/60000 Training loss: 0.013599
Epoch: 15 40000/60000 Training loss: 0.018866
Epoch: 15 50000/60000 Training loss: 0.025270
Training loss: 0.023985
Test loss: 0.020037; Test accuracy: 9933/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.020366
Epoch: 16 10000/60000 Training loss: 0.073854
Epoch: 16 20000/60000 Training loss: 0.018503
Epoch: 16 30000/60000 Training loss: 0.017070
Epoch: 16 40000/60000 Training loss: 0.020044
Epoch: 16 50000/60000 Training loss: 0.074696
Training loss: 0.022799
Test loss: 0.019987; Test accuracy: 9932/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.031137
Epoch: 17 10000/60000 Training loss: 0.007547
Epoch: 17 20000/60000 Training loss: 0.037423
Epoch: 17 30000/60000 Training loss: 0.009744
Epoch: 17 40000/60000 Training loss: 0.007137
Epoch: 17 50000/60000 Training loss: 0.019393
Training loss: 0.021459
Test loss: 0.018337; Test accuracy: 9941/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.006034
Epoch: 18 10000/60000 Training loss: 0.002505
Epoch: 18 20000/60000 Training loss: 0.010737
Epoch: 18 30000/60000 Training loss: 0.002079
Epoch: 18 40000/60000 Training loss: 0.001850
Epoch: 18 50000/60000 Training loss: 0.017905
Training loss: 0.020295
Test loss: 0.020574; Test accuracy: 9928/10000 (99.3%)

Epoch: 19 0/60000 Training loss: 0.035131
Epoch: 19 10000/60000 Training loss: 0.004931
Epoch: 19 20000/60000 Training loss: 0.022370
Epoch: 19 30000/60000 Training loss: 0.007832
Epoch: 19 40000/60000 Training loss: 0.001937
Epoch: 19 50000/60000 Training loss: 0.053961
Training loss: 0.019194
Test loss: 0.019978; Test accuracy: 9935/10000 (99.3%)

[I 2022-11-04 04:00:15,113] Trial 63 finished with value: 0.018337402492761612 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.17192690438572952, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 7.002838764373947e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 112, 'conv2_drop': 0.1951832071590206, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 4.326478927370049e-05}
Epoch: 0 0/60000 Training loss: 2.319941
Epoch: 0 10000/60000 Training loss: 1.034907
Epoch: 0 20000/60000 Training loss: 0.824091
Epoch: 0 30000/60000 Training loss: 0.358844
Epoch: 0 40000/60000 Training loss: 0.415101
Epoch: 0 50000/60000 Training loss: 0.313384
Training loss: 0.671525
Test loss: 0.174293; Test accuracy: 9505/10000 (95.0%)

Epoch: 1 0/60000 Training loss: 0.250261
Epoch: 1 10000/60000 Training loss: 0.189486
Epoch: 1 20000/60000 Training loss: 0.225468
Epoch: 1 30000/60000 Training loss: 0.235843
Epoch: 1 40000/60000 Training loss: 0.293254
Epoch: 1 50000/60000 Training loss: 0.138174
Training loss: 0.209251
Test loss: 0.100581; Test accuracy: 9689/10000 (96.9%)

Epoch: 2 0/60000 Training loss: 0.137095
Epoch: 2 10000/60000 Training loss: 0.133514
Epoch: 2 20000/60000 Training loss: 0.147714
Epoch: 2 30000/60000 Training loss: 0.263177
Epoch: 2 40000/60000 Training loss: 0.129447
Epoch: 2 50000/60000 Training loss: 0.119349
Training loss: 0.142253
Test loss: 0.072232; Test accuracy: 9772/10000 (97.7%)

Epoch: 3 0/60000 Training loss: 0.274792
Epoch: 3 10000/60000 Training loss: 0.073372
Epoch: 3 20000/60000 Training loss: 0.104252
Epoch: 3 30000/60000 Training loss: 0.059656
Epoch: 3 40000/60000 Training loss: 0.193168
Epoch: 3 50000/60000 Training loss: 0.100785
Training loss: 0.113723
Test loss: 0.060925; Test accuracy: 9811/10000 (98.1%)

Epoch: 4 0/60000 Training loss: 0.151413
Epoch: 4 10000/60000 Training loss: 0.091897
Epoch: 4 20000/60000 Training loss: 0.093523
Epoch: 4 30000/60000 Training loss: 0.112612
Epoch: 4 40000/60000 Training loss: 0.041708
Epoch: 4 50000/60000 Training loss: 0.120331
Training loss: 0.094264
Test loss: 0.049840; Test accuracy: 9846/10000 (98.5%)

Epoch: 5 0/60000 Training loss: 0.107432
Epoch: 5 10000/60000 Training loss: 0.105424
Epoch: 5 20000/60000 Training loss: 0.050808
Epoch: 5 30000/60000 Training loss: 0.035036
Epoch: 5 40000/60000 Training loss: 0.037355
Epoch: 5 50000/60000 Training loss: 0.090100
Training loss: 0.084137
Test loss: 0.044402; Test accuracy: 9856/10000 (98.6%)

Epoch: 6 0/60000 Training loss: 0.054270
Epoch: 6 10000/60000 Training loss: 0.088580
Epoch: 6 20000/60000 Training loss: 0.126034
Epoch: 6 30000/60000 Training loss: 0.072707
Epoch: 6 40000/60000 Training loss: 0.092160
Epoch: 6 50000/60000 Training loss: 0.032339
Training loss: 0.073040
Test loss: 0.039919; Test accuracy: 9874/10000 (98.7%)

Epoch: 7 0/60000 Training loss: 0.055293
Epoch: 7 10000/60000 Training loss: 0.030080
Epoch: 7 20000/60000 Training loss: 0.038571
Epoch: 7 30000/60000 Training loss: 0.160268
Epoch: 7 40000/60000 Training loss: 0.074017
Epoch: 7 50000/60000 Training loss: 0.115267
Training loss: 0.065370
Test loss: 0.034486; Test accuracy: 9890/10000 (98.9%)

Epoch: 8 0/60000 Training loss: 0.039609
Epoch: 8 10000/60000 Training loss: 0.013501
Epoch: 8 20000/60000 Training loss: 0.062405
Epoch: 8 30000/60000 Training loss: 0.043702
Epoch: 8 40000/60000 Training loss: 0.108319
Epoch: 8 50000/60000 Training loss: 0.090795
Training loss: 0.060811
Test loss: 0.033415; Test accuracy: 9892/10000 (98.9%)

Epoch: 9 0/60000 Training loss: 0.039100
Epoch: 9 10000/60000 Training loss: 0.059947
Epoch: 9 20000/60000 Training loss: 0.030975
Epoch: 9 30000/60000 Training loss: 0.076202
Epoch: 9 40000/60000 Training loss: 0.076208
Epoch: 9 50000/60000 Training loss: 0.039181
Training loss: 0.056211
Test loss: 0.031600; Test accuracy: 9901/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.033528
Epoch: 10 10000/60000 Training loss: 0.111560
Epoch: 10 20000/60000 Training loss: 0.034834
Epoch: 10 30000/60000 Training loss: 0.022987
Epoch: 10 40000/60000 Training loss: 0.137443
Epoch: 10 50000/60000 Training loss: 0.016702
Training loss: 0.052685
Test loss: 0.029647; Test accuracy: 9898/10000 (99.0%)

Epoch: 11 0/60000 Training loss: 0.071313
Epoch: 11 10000/60000 Training loss: 0.059655
Epoch: 11 20000/60000 Training loss: 0.053185
Epoch: 11 30000/60000 Training loss: 0.109191
Epoch: 11 40000/60000 Training loss: 0.067975
Epoch: 11 50000/60000 Training loss: 0.017710
Training loss: 0.048894
Test loss: 0.027905; Test accuracy: 9903/10000 (99.0%)

Epoch: 12 0/60000 Training loss: 0.035824
Epoch: 12 10000/60000 Training loss: 0.041171
Epoch: 12 20000/60000 Training loss: 0.015593
Epoch: 12 30000/60000 Training loss: 0.044414
Epoch: 12 40000/60000 Training loss: 0.018620
Epoch: 12 50000/60000 Training loss: 0.034019
Training loss: 0.045883
Test loss: 0.027494; Test accuracy: 9910/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.015960
Epoch: 13 10000/60000 Training loss: 0.103896
Epoch: 13 20000/60000 Training loss: 0.053402
Epoch: 13 30000/60000 Training loss: 0.010776
Epoch: 13 40000/60000 Training loss: 0.022434
Epoch: 13 50000/60000 Training loss: 0.018284
Training loss: 0.042665
Test loss: 0.026817; Test accuracy: 9909/10000 (99.1%)

Epoch: 14 0/60000 Training loss: 0.034940
Epoch: 14 10000/60000 Training loss: 0.098035
Epoch: 14 20000/60000 Training loss: 0.077313
Epoch: 14 30000/60000 Training loss: 0.025411
Epoch: 14 40000/60000 Training loss: 0.042362
Epoch: 14 50000/60000 Training loss: 0.018513
Training loss: 0.040010
Test loss: 0.024106; Test accuracy: 9919/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.084314
Epoch: 15 10000/60000 Training loss: 0.007362
Epoch: 15 20000/60000 Training loss: 0.062684
Epoch: 15 30000/60000 Training loss: 0.024037
Epoch: 15 40000/60000 Training loss: 0.015812
Epoch: 15 50000/60000 Training loss: 0.030227
Training loss: 0.038419
Test loss: 0.025675; Test accuracy: 9913/10000 (99.1%)

Epoch: 16 0/60000 Training loss: 0.047189
Epoch: 16 10000/60000 Training loss: 0.031928
Epoch: 16 20000/60000 Training loss: 0.123282
Epoch: 16 30000/60000 Training loss: 0.026036
Epoch: 16 40000/60000 Training loss: 0.013218
Epoch: 16 50000/60000 Training loss: 0.008103
Training loss: 0.035254
Test loss: 0.024907; Test accuracy: 9917/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.012024
Epoch: 17 10000/60000 Training loss: 0.016716
Epoch: 17 20000/60000 Training loss: 0.039080
Epoch: 17 30000/60000 Training loss: 0.151027
Epoch: 17 40000/60000 Training loss: 0.031821
Epoch: 17 50000/60000 Training loss: 0.015500
Training loss: 0.034103
Test loss: 0.024289; Test accuracy: 9915/10000 (99.1%)

[I 2022-11-04 04:04:26,624] Trial 64 finished with value: 0.02410619519650936 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 112, 'conv2_drop': 0.1951832071590206, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 4.326478927370049e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.1779900029582938, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00014494647182161755}
Epoch: 0 0/60000 Training loss: 2.322242
Epoch: 0 10000/60000 Training loss: 0.635003
Epoch: 0 20000/60000 Training loss: 0.324654
Epoch: 0 30000/60000 Training loss: 0.170194
Epoch: 0 40000/60000 Training loss: 0.308343
Epoch: 0 50000/60000 Training loss: 0.104316
Training loss: 0.376779
Test loss: 0.078179; Test accuracy: 9756/10000 (97.6%)

Epoch: 1 0/60000 Training loss: 0.180374
Epoch: 1 10000/60000 Training loss: 0.084250
Epoch: 1 20000/60000 Training loss: 0.069821
Epoch: 1 30000/60000 Training loss: 0.085623
Epoch: 1 40000/60000 Training loss: 0.254954
Epoch: 1 50000/60000 Training loss: 0.116578
Training loss: 0.115600
Test loss: 0.049482; Test accuracy: 9829/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.121850
Epoch: 2 10000/60000 Training loss: 0.057221
Epoch: 2 20000/60000 Training loss: 0.131522
Epoch: 2 30000/60000 Training loss: 0.158909
Epoch: 2 40000/60000 Training loss: 0.133795
Epoch: 2 50000/60000 Training loss: 0.056401
Training loss: 0.083869
Test loss: 0.036284; Test accuracy: 9878/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.141009
Epoch: 3 10000/60000 Training loss: 0.103994
Epoch: 3 20000/60000 Training loss: 0.052529
Epoch: 3 30000/60000 Training loss: 0.033290
Epoch: 3 40000/60000 Training loss: 0.066344
Epoch: 3 50000/60000 Training loss: 0.058290
Training loss: 0.067612
Test loss: 0.029386; Test accuracy: 9910/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.056860
Epoch: 4 10000/60000 Training loss: 0.097724
Epoch: 4 20000/60000 Training loss: 0.079079
Epoch: 4 30000/60000 Training loss: 0.069917
Epoch: 4 40000/60000 Training loss: 0.016864
Epoch: 4 50000/60000 Training loss: 0.067104
Training loss: 0.055938
Test loss: 0.028528; Test accuracy: 9907/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.085397
Epoch: 5 10000/60000 Training loss: 0.043983
Epoch: 5 20000/60000 Training loss: 0.014006
Epoch: 5 30000/60000 Training loss: 0.043447
Epoch: 5 40000/60000 Training loss: 0.051926
Epoch: 5 50000/60000 Training loss: 0.071163
Training loss: 0.049164
Test loss: 0.026206; Test accuracy: 9909/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.039718
Epoch: 6 10000/60000 Training loss: 0.086016
Epoch: 6 20000/60000 Training loss: 0.023734
Epoch: 6 30000/60000 Training loss: 0.047907
Epoch: 6 40000/60000 Training loss: 0.010249
Epoch: 6 50000/60000 Training loss: 0.069757
Training loss: 0.043927
Test loss: 0.024135; Test accuracy: 9916/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.017156
Epoch: 7 10000/60000 Training loss: 0.051865
Epoch: 7 20000/60000 Training loss: 0.006531
Epoch: 7 30000/60000 Training loss: 0.117153
Epoch: 7 40000/60000 Training loss: 0.033323
Epoch: 7 50000/60000 Training loss: 0.059902
Training loss: 0.038784
Test loss: 0.023223; Test accuracy: 9918/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.007904
Epoch: 8 10000/60000 Training loss: 0.007627
Epoch: 8 20000/60000 Training loss: 0.034448
Epoch: 8 30000/60000 Training loss: 0.016898
Epoch: 8 40000/60000 Training loss: 0.268019
Epoch: 8 50000/60000 Training loss: 0.015776
Training loss: 0.034323
Test loss: 0.022595; Test accuracy: 9925/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.012532
Epoch: 9 10000/60000 Training loss: 0.037382
Epoch: 9 20000/60000 Training loss: 0.014615
Epoch: 9 30000/60000 Training loss: 0.044504
Epoch: 9 40000/60000 Training loss: 0.015074
Epoch: 9 50000/60000 Training loss: 0.036088
Training loss: 0.030697
Test loss: 0.020071; Test accuracy: 9928/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.008778
Epoch: 10 10000/60000 Training loss: 0.025371
Epoch: 10 20000/60000 Training loss: 0.006556
Epoch: 10 30000/60000 Training loss: 0.007484
Epoch: 10 40000/60000 Training loss: 0.013307
Epoch: 10 50000/60000 Training loss: 0.023108
Training loss: 0.027341
Test loss: 0.018241; Test accuracy: 9942/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.012519
Epoch: 11 10000/60000 Training loss: 0.002735
Epoch: 11 20000/60000 Training loss: 0.011516
Epoch: 11 30000/60000 Training loss: 0.014197
Epoch: 11 40000/60000 Training loss: 0.049796
Epoch: 11 50000/60000 Training loss: 0.003177
Training loss: 0.026196
Test loss: 0.019183; Test accuracy: 9940/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.003066
Epoch: 12 10000/60000 Training loss: 0.046086
Epoch: 12 20000/60000 Training loss: 0.007900
Epoch: 12 30000/60000 Training loss: 0.017221
Epoch: 12 40000/60000 Training loss: 0.026990
Epoch: 12 50000/60000 Training loss: 0.018491
Training loss: 0.023209
Test loss: 0.019322; Test accuracy: 9937/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.017878
Epoch: 13 10000/60000 Training loss: 0.014229
Epoch: 13 20000/60000 Training loss: 0.023152
Epoch: 13 30000/60000 Training loss: 0.018676
Epoch: 13 40000/60000 Training loss: 0.003328
Epoch: 13 50000/60000 Training loss: 0.019161
Training loss: 0.021371
Test loss: 0.019750; Test accuracy: 9935/10000 (99.3%)

[I 2022-11-04 04:07:42,514] Trial 65 finished with value: 0.018241185694932938 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.1779900029582938, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00014494647182161755}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.18437325108077482, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 5.9732146640675294e-05}
Epoch: 0 0/60000 Training loss: 2.355076
Epoch: 0 10000/60000 Training loss: 0.817884
Epoch: 0 20000/60000 Training loss: 0.389673
Epoch: 0 30000/60000 Training loss: 0.430776
Epoch: 0 40000/60000 Training loss: 0.281283
Epoch: 0 50000/60000 Training loss: 0.193536
Training loss: 0.560810
Test loss: 0.133411; Test accuracy: 9602/10000 (96.0%)

Epoch: 1 0/60000 Training loss: 0.268198
Epoch: 1 10000/60000 Training loss: 0.181774
Epoch: 1 20000/60000 Training loss: 0.128549
Epoch: 1 30000/60000 Training loss: 0.197594
Epoch: 1 40000/60000 Training loss: 0.101461
Epoch: 1 50000/60000 Training loss: 0.187036
Training loss: 0.172947
Test loss: 0.078923; Test accuracy: 9754/10000 (97.5%)

Epoch: 2 0/60000 Training loss: 0.135976
Epoch: 2 10000/60000 Training loss: 0.265128
Epoch: 2 20000/60000 Training loss: 0.093799
Epoch: 2 30000/60000 Training loss: 0.112525
Epoch: 2 40000/60000 Training loss: 0.041650
Epoch: 2 50000/60000 Training loss: 0.058700
Training loss: 0.121041
Test loss: 0.057893; Test accuracy: 9819/10000 (98.2%)

Epoch: 3 0/60000 Training loss: 0.069759
Epoch: 3 10000/60000 Training loss: 0.062846
Epoch: 3 20000/60000 Training loss: 0.040525
Epoch: 3 30000/60000 Training loss: 0.108281
Epoch: 3 40000/60000 Training loss: 0.163657
Epoch: 3 50000/60000 Training loss: 0.076402
Training loss: 0.097211
Test loss: 0.048325; Test accuracy: 9845/10000 (98.4%)

Epoch: 4 0/60000 Training loss: 0.096304
Epoch: 4 10000/60000 Training loss: 0.061243
Epoch: 4 20000/60000 Training loss: 0.072908
Epoch: 4 30000/60000 Training loss: 0.101484
Epoch: 4 40000/60000 Training loss: 0.050343
Epoch: 4 50000/60000 Training loss: 0.098155
Training loss: 0.084231
Test loss: 0.041710; Test accuracy: 9864/10000 (98.6%)

Epoch: 5 0/60000 Training loss: 0.050310
Epoch: 5 10000/60000 Training loss: 0.081042
Epoch: 5 20000/60000 Training loss: 0.020913
Epoch: 5 30000/60000 Training loss: 0.070832
Epoch: 5 40000/60000 Training loss: 0.092835
Epoch: 5 50000/60000 Training loss: 0.043684
Training loss: 0.072535
Test loss: 0.036677; Test accuracy: 9878/10000 (98.8%)

Epoch: 6 0/60000 Training loss: 0.040285
Epoch: 6 10000/60000 Training loss: 0.079257
Epoch: 6 20000/60000 Training loss: 0.021177
Epoch: 6 30000/60000 Training loss: 0.044323
Epoch: 6 40000/60000 Training loss: 0.028322
Epoch: 6 50000/60000 Training loss: 0.023470
Training loss: 0.063804
Test loss: 0.033767; Test accuracy: 9885/10000 (98.8%)

Epoch: 7 0/60000 Training loss: 0.069101
Epoch: 7 10000/60000 Training loss: 0.021137
Epoch: 7 20000/60000 Training loss: 0.030399
Epoch: 7 30000/60000 Training loss: 0.020481
Epoch: 7 40000/60000 Training loss: 0.123090
Epoch: 7 50000/60000 Training loss: 0.033975
Training loss: 0.057305
Test loss: 0.029949; Test accuracy: 9899/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.112046
Epoch: 8 10000/60000 Training loss: 0.070907
Epoch: 8 20000/60000 Training loss: 0.056154
Epoch: 8 30000/60000 Training loss: 0.022491
Epoch: 8 40000/60000 Training loss: 0.015458
Epoch: 8 50000/60000 Training loss: 0.040456
Training loss: 0.053005
Test loss: 0.028681; Test accuracy: 9908/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.021902
Epoch: 9 10000/60000 Training loss: 0.057996
Epoch: 9 20000/60000 Training loss: 0.024169
Epoch: 9 30000/60000 Training loss: 0.012618
Epoch: 9 40000/60000 Training loss: 0.126765
Epoch: 9 50000/60000 Training loss: 0.081707
Training loss: 0.048039
Test loss: 0.027619; Test accuracy: 9909/10000 (99.1%)

Epoch: 10 0/60000 Training loss: 0.036870
Epoch: 10 10000/60000 Training loss: 0.095910
Epoch: 10 20000/60000 Training loss: 0.052924
Epoch: 10 30000/60000 Training loss: 0.031843
Epoch: 10 40000/60000 Training loss: 0.074853
Epoch: 10 50000/60000 Training loss: 0.049522
Training loss: 0.044151
Test loss: 0.024479; Test accuracy: 9918/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.004951
Epoch: 11 10000/60000 Training loss: 0.155122
Epoch: 11 20000/60000 Training loss: 0.013942
Epoch: 11 30000/60000 Training loss: 0.061498
Epoch: 11 40000/60000 Training loss: 0.035545
Epoch: 11 50000/60000 Training loss: 0.033482
Training loss: 0.040965
Test loss: 0.024662; Test accuracy: 9920/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.056005
Epoch: 12 10000/60000 Training loss: 0.049248
Epoch: 12 20000/60000 Training loss: 0.035236
Epoch: 12 30000/60000 Training loss: 0.035035
Epoch: 12 40000/60000 Training loss: 0.050149
Epoch: 12 50000/60000 Training loss: 0.058605
Training loss: 0.037746
Test loss: 0.024158; Test accuracy: 9921/10000 (99.2%)

Epoch: 13 0/60000 Training loss: 0.012951
Epoch: 13 10000/60000 Training loss: 0.034846
Epoch: 13 20000/60000 Training loss: 0.017710
Epoch: 13 30000/60000 Training loss: 0.043248
Epoch: 13 40000/60000 Training loss: 0.022995
Epoch: 13 50000/60000 Training loss: 0.024376
Training loss: 0.035306
Test loss: 0.023749; Test accuracy: 9923/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.073980
Epoch: 14 10000/60000 Training loss: 0.006671
Epoch: 14 20000/60000 Training loss: 0.024806
Epoch: 14 30000/60000 Training loss: 0.105422
Epoch: 14 40000/60000 Training loss: 0.070800
Epoch: 14 50000/60000 Training loss: 0.011081
Training loss: 0.033726
Test loss: 0.023011; Test accuracy: 9925/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.065516
Epoch: 15 10000/60000 Training loss: 0.045581
Epoch: 15 20000/60000 Training loss: 0.004934
Epoch: 15 30000/60000 Training loss: 0.033107
Epoch: 15 40000/60000 Training loss: 0.042711
Epoch: 15 50000/60000 Training loss: 0.084702
Training loss: 0.032226
Test loss: 0.022371; Test accuracy: 9929/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.030374
Epoch: 16 10000/60000 Training loss: 0.029103
Epoch: 16 20000/60000 Training loss: 0.073912
Epoch: 16 30000/60000 Training loss: 0.009222
Epoch: 16 40000/60000 Training loss: 0.022655
Epoch: 16 50000/60000 Training loss: 0.033591
Training loss: 0.029960
Test loss: 0.022045; Test accuracy: 9923/10000 (99.2%)

Epoch: 17 0/60000 Training loss: 0.003614
Epoch: 17 10000/60000 Training loss: 0.009639
Epoch: 17 20000/60000 Training loss: 0.047283
Epoch: 17 30000/60000 Training loss: 0.029746
Epoch: 17 40000/60000 Training loss: 0.037473
Epoch: 17 50000/60000 Training loss: 0.044013
Training loss: 0.028258
Test loss: 0.020290; Test accuracy: 9929/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.007065
Epoch: 18 10000/60000 Training loss: 0.037982
Epoch: 18 20000/60000 Training loss: 0.012669
Epoch: 18 30000/60000 Training loss: 0.008427
Epoch: 18 40000/60000 Training loss: 0.003473
Epoch: 18 50000/60000 Training loss: 0.039119
Training loss: 0.026573
Test loss: 0.020731; Test accuracy: 9923/10000 (99.2%)

Epoch: 19 0/60000 Training loss: 0.005984
Epoch: 19 10000/60000 Training loss: 0.005298
Epoch: 19 20000/60000 Training loss: 0.002115
Epoch: 19 30000/60000 Training loss: 0.023912
Epoch: 19 40000/60000 Training loss: 0.006749
Epoch: 19 50000/60000 Training loss: 0.057075
Training loss: 0.024490
Test loss: 0.020091; Test accuracy: 9933/10000 (99.3%)

[I 2022-11-04 04:12:22,583] Trial 66 finished with value: 0.0200906153768301 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.18437325108077482, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 5.9732146640675294e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.15800599921605465, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.00010904472974817589}
Epoch: 0 0/60000 Training loss: 2.314735
Epoch: 0 10000/60000 Training loss: 0.537054
Epoch: 0 20000/60000 Training loss: 0.437767
Epoch: 0 30000/60000 Training loss: 0.193537
Epoch: 0 40000/60000 Training loss: 0.146520
Epoch: 0 50000/60000 Training loss: 0.084677
Training loss: 0.400438
Test loss: 0.086353; Test accuracy: 9749/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.216807
Epoch: 1 10000/60000 Training loss: 0.188584
Epoch: 1 20000/60000 Training loss: 0.163140
Epoch: 1 30000/60000 Training loss: 0.209025
Epoch: 1 40000/60000 Training loss: 0.081358
Epoch: 1 50000/60000 Training loss: 0.154537
Training loss: 0.115702
Test loss: 0.053713; Test accuracy: 9819/10000 (98.2%)

Epoch: 2 0/60000 Training loss: 0.054715
Epoch: 2 10000/60000 Training loss: 0.133614
Epoch: 2 20000/60000 Training loss: 0.072580
Epoch: 2 30000/60000 Training loss: 0.071323
Epoch: 2 40000/60000 Training loss: 0.088546
Epoch: 2 50000/60000 Training loss: 0.069347
Training loss: 0.082225
Test loss: 0.038444; Test accuracy: 9863/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.056961
Epoch: 3 10000/60000 Training loss: 0.062620
Epoch: 3 20000/60000 Training loss: 0.052543
Epoch: 3 30000/60000 Training loss: 0.224010
Epoch: 3 40000/60000 Training loss: 0.087560
Epoch: 3 50000/60000 Training loss: 0.014481
Training loss: 0.065058
Test loss: 0.030953; Test accuracy: 9895/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.028419
Epoch: 4 10000/60000 Training loss: 0.073315
Epoch: 4 20000/60000 Training loss: 0.040272
Epoch: 4 30000/60000 Training loss: 0.034972
Epoch: 4 40000/60000 Training loss: 0.073977
Epoch: 4 50000/60000 Training loss: 0.007982
Training loss: 0.054354
Test loss: 0.028931; Test accuracy: 9909/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.031694
Epoch: 5 10000/60000 Training loss: 0.066963
Epoch: 5 20000/60000 Training loss: 0.029378
Epoch: 5 30000/60000 Training loss: 0.068249
Epoch: 5 40000/60000 Training loss: 0.013343
Epoch: 5 50000/60000 Training loss: 0.043142
Training loss: 0.046206
Test loss: 0.026238; Test accuracy: 9912/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.042580
Epoch: 6 10000/60000 Training loss: 0.016902
Epoch: 6 20000/60000 Training loss: 0.111187
Epoch: 6 30000/60000 Training loss: 0.021851
Epoch: 6 40000/60000 Training loss: 0.041027
Epoch: 6 50000/60000 Training loss: 0.039734
Training loss: 0.040206
Test loss: 0.024111; Test accuracy: 9915/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.053182
Epoch: 7 10000/60000 Training loss: 0.002057
Epoch: 7 20000/60000 Training loss: 0.083726
Epoch: 7 30000/60000 Training loss: 0.005548
Epoch: 7 40000/60000 Training loss: 0.029708
Epoch: 7 50000/60000 Training loss: 0.014299
Training loss: 0.036691
Test loss: 0.023113; Test accuracy: 9928/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.070064
Epoch: 8 10000/60000 Training loss: 0.032397
Epoch: 8 20000/60000 Training loss: 0.042758
Epoch: 8 30000/60000 Training loss: 0.039118
Epoch: 8 40000/60000 Training loss: 0.010885
Epoch: 8 50000/60000 Training loss: 0.002716
Training loss: 0.033362
Test loss: 0.022934; Test accuracy: 9919/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.037927
Epoch: 9 10000/60000 Training loss: 0.015276
Epoch: 9 20000/60000 Training loss: 0.044427
Epoch: 9 30000/60000 Training loss: 0.130207
Epoch: 9 40000/60000 Training loss: 0.004637
Epoch: 9 50000/60000 Training loss: 0.032683
Training loss: 0.030174
Test loss: 0.022470; Test accuracy: 9920/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.009863
Epoch: 10 10000/60000 Training loss: 0.033054
Epoch: 10 20000/60000 Training loss: 0.026684
Epoch: 10 30000/60000 Training loss: 0.030814
Epoch: 10 40000/60000 Training loss: 0.021505
Epoch: 10 50000/60000 Training loss: 0.035948
Training loss: 0.026729
Test loss: 0.019962; Test accuracy: 9934/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.026411
Epoch: 11 10000/60000 Training loss: 0.014568
Epoch: 11 20000/60000 Training loss: 0.043726
Epoch: 11 30000/60000 Training loss: 0.010897
Epoch: 11 40000/60000 Training loss: 0.008962
Epoch: 11 50000/60000 Training loss: 0.022572
Training loss: 0.024310
Test loss: 0.020761; Test accuracy: 9927/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.036171
Epoch: 12 10000/60000 Training loss: 0.003836
Epoch: 12 20000/60000 Training loss: 0.034929
Epoch: 12 30000/60000 Training loss: 0.006400
Epoch: 12 40000/60000 Training loss: 0.015127
Epoch: 12 50000/60000 Training loss: 0.012348
Training loss: 0.023398
Test loss: 0.020568; Test accuracy: 9930/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.012602
Epoch: 13 10000/60000 Training loss: 0.013257
Epoch: 13 20000/60000 Training loss: 0.007475
Epoch: 13 30000/60000 Training loss: 0.147495
Epoch: 13 40000/60000 Training loss: 0.033995
Epoch: 13 50000/60000 Training loss: 0.060988
Training loss: 0.020776
Test loss: 0.018596; Test accuracy: 9934/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.024579
Epoch: 14 10000/60000 Training loss: 0.018065
Epoch: 14 20000/60000 Training loss: 0.029875
Epoch: 14 30000/60000 Training loss: 0.008682
Epoch: 14 40000/60000 Training loss: 0.021496
Epoch: 14 50000/60000 Training loss: 0.012770
Training loss: 0.020268
Test loss: 0.018990; Test accuracy: 9937/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.006318
Epoch: 15 10000/60000 Training loss: 0.020880
Epoch: 15 20000/60000 Training loss: 0.005278
Epoch: 15 30000/60000 Training loss: 0.004772
Epoch: 15 40000/60000 Training loss: 0.006959
Epoch: 15 50000/60000 Training loss: 0.005156
Training loss: 0.017439
Test loss: 0.018282; Test accuracy: 9939/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.004568
Epoch: 16 10000/60000 Training loss: 0.002006
Epoch: 16 20000/60000 Training loss: 0.008654
Epoch: 16 30000/60000 Training loss: 0.024362
Epoch: 16 40000/60000 Training loss: 0.010684
Epoch: 16 50000/60000 Training loss: 0.000874
Training loss: 0.016857
Test loss: 0.021713; Test accuracy: 9931/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.007678
Epoch: 17 10000/60000 Training loss: 0.002462
Epoch: 17 20000/60000 Training loss: 0.003248
Epoch: 17 30000/60000 Training loss: 0.014403
Epoch: 17 40000/60000 Training loss: 0.009128
Epoch: 17 50000/60000 Training loss: 0.004286
Training loss: 0.015048
Test loss: 0.019346; Test accuracy: 9932/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.005205
Epoch: 18 10000/60000 Training loss: 0.007443
Epoch: 18 20000/60000 Training loss: 0.005516
Epoch: 18 30000/60000 Training loss: 0.011501
Epoch: 18 40000/60000 Training loss: 0.009029
Epoch: 18 50000/60000 Training loss: 0.023926
Training loss: 0.015408
Test loss: 0.017872; Test accuracy: 9943/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.004284
Epoch: 19 10000/60000 Training loss: 0.002690
Epoch: 19 20000/60000 Training loss: 0.039242
Epoch: 19 30000/60000 Training loss: 0.006397
Epoch: 19 40000/60000 Training loss: 0.001252
Epoch: 19 50000/60000 Training loss: 0.011970
Training loss: 0.014196
Test loss: 0.019258; Test accuracy: 9939/10000 (99.4%)

[I 2022-11-04 04:17:02,747] Trial 67 finished with value: 0.017872003838419914 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.15800599921605465, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.00010904472974817589}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.15790420785448692, 'fc1_neurons': 200, 'optimizer': 'Adam', 'learning_rate': 0.00012237259492083085}
Epoch: 0 0/60000 Training loss: 2.343779
Epoch: 0 10000/60000 Training loss: 0.677573
Epoch: 0 20000/60000 Training loss: 0.222722
Epoch: 0 30000/60000 Training loss: 0.135078
Epoch: 0 40000/60000 Training loss: 0.108963
Epoch: 0 50000/60000 Training loss: 0.127831
Training loss: 0.406447
Test loss: 0.087728; Test accuracy: 9727/10000 (97.3%)

Epoch: 1 0/60000 Training loss: 0.163789
Epoch: 1 10000/60000 Training loss: 0.162141
Epoch: 1 20000/60000 Training loss: 0.122067
Epoch: 1 30000/60000 Training loss: 0.075572
Epoch: 1 40000/60000 Training loss: 0.132738
Epoch: 1 50000/60000 Training loss: 0.150906
Training loss: 0.120299
Test loss: 0.050103; Test accuracy: 9835/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.025871
Epoch: 2 10000/60000 Training loss: 0.100571
Epoch: 2 20000/60000 Training loss: 0.087214
Epoch: 2 30000/60000 Training loss: 0.200036
Epoch: 2 40000/60000 Training loss: 0.042558
Epoch: 2 50000/60000 Training loss: 0.227784
Training loss: 0.083959
Test loss: 0.038780; Test accuracy: 9879/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.071580
Epoch: 3 10000/60000 Training loss: 0.079875
Epoch: 3 20000/60000 Training loss: 0.050243
Epoch: 3 30000/60000 Training loss: 0.039394
Epoch: 3 40000/60000 Training loss: 0.024906
Epoch: 3 50000/60000 Training loss: 0.016078
Training loss: 0.067382
Test loss: 0.032019; Test accuracy: 9896/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.027132
Epoch: 4 10000/60000 Training loss: 0.053541
Epoch: 4 20000/60000 Training loss: 0.047059
Epoch: 4 30000/60000 Training loss: 0.059267
Epoch: 4 40000/60000 Training loss: 0.021275
Epoch: 4 50000/60000 Training loss: 0.119521
Training loss: 0.055273
Test loss: 0.030110; Test accuracy: 9901/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.037806
Epoch: 5 10000/60000 Training loss: 0.069855
Epoch: 5 20000/60000 Training loss: 0.090682
Epoch: 5 30000/60000 Training loss: 0.017339
Epoch: 5 40000/60000 Training loss: 0.022626
Epoch: 5 50000/60000 Training loss: 0.020921
Training loss: 0.048545
Test loss: 0.026468; Test accuracy: 9912/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.044449
Epoch: 6 10000/60000 Training loss: 0.071982
Epoch: 6 20000/60000 Training loss: 0.036771
Epoch: 6 30000/60000 Training loss: 0.060573
Epoch: 6 40000/60000 Training loss: 0.008411
Epoch: 6 50000/60000 Training loss: 0.006390
Training loss: 0.042518
Test loss: 0.022900; Test accuracy: 9923/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.046035
Epoch: 7 10000/60000 Training loss: 0.034379
Epoch: 7 20000/60000 Training loss: 0.059519
Epoch: 7 30000/60000 Training loss: 0.035744
Epoch: 7 40000/60000 Training loss: 0.028457
Epoch: 7 50000/60000 Training loss: 0.015338
Training loss: 0.037706
Test loss: 0.024156; Test accuracy: 9918/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.016374
Epoch: 8 10000/60000 Training loss: 0.161861
Epoch: 8 20000/60000 Training loss: 0.018972
Epoch: 8 30000/60000 Training loss: 0.006120
Epoch: 8 40000/60000 Training loss: 0.070120
Epoch: 8 50000/60000 Training loss: 0.007861
Training loss: 0.034289
Test loss: 0.022689; Test accuracy: 9927/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.043537
Epoch: 9 10000/60000 Training loss: 0.003443
Epoch: 9 20000/60000 Training loss: 0.011996
Epoch: 9 30000/60000 Training loss: 0.010700
Epoch: 9 40000/60000 Training loss: 0.033720
Epoch: 9 50000/60000 Training loss: 0.011626
Training loss: 0.030747
Test loss: 0.022205; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.007033
Epoch: 10 10000/60000 Training loss: 0.048492
Epoch: 10 20000/60000 Training loss: 0.029210
Epoch: 10 30000/60000 Training loss: 0.007017
Epoch: 10 40000/60000 Training loss: 0.015485
Epoch: 10 50000/60000 Training loss: 0.029365
Training loss: 0.028387
Test loss: 0.019102; Test accuracy: 9940/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.007092
Epoch: 11 10000/60000 Training loss: 0.017967
Epoch: 11 20000/60000 Training loss: 0.025248
Epoch: 11 30000/60000 Training loss: 0.012054
Epoch: 11 40000/60000 Training loss: 0.065393
Epoch: 11 50000/60000 Training loss: 0.032508
Training loss: 0.025358
Test loss: 0.019370; Test accuracy: 9936/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.015297
Epoch: 12 10000/60000 Training loss: 0.019620
Epoch: 12 20000/60000 Training loss: 0.005038
Epoch: 12 30000/60000 Training loss: 0.013959
Epoch: 12 40000/60000 Training loss: 0.006149
Epoch: 12 50000/60000 Training loss: 0.002765
Training loss: 0.024522
Test loss: 0.019065; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.009434
Epoch: 13 10000/60000 Training loss: 0.008444
Epoch: 13 20000/60000 Training loss: 0.002987
Epoch: 13 30000/60000 Training loss: 0.005522
Epoch: 13 40000/60000 Training loss: 0.024325
Epoch: 13 50000/60000 Training loss: 0.051939
Training loss: 0.022262
Test loss: 0.019041; Test accuracy: 9940/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.015282
Epoch: 14 10000/60000 Training loss: 0.002479
Epoch: 14 20000/60000 Training loss: 0.033871
Epoch: 14 30000/60000 Training loss: 0.024211
Epoch: 14 40000/60000 Training loss: 0.022471
Epoch: 14 50000/60000 Training loss: 0.037719
Training loss: 0.018982
Test loss: 0.018774; Test accuracy: 9941/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.021459
Epoch: 15 10000/60000 Training loss: 0.005365
Epoch: 15 20000/60000 Training loss: 0.014777
Epoch: 15 30000/60000 Training loss: 0.074439
Epoch: 15 40000/60000 Training loss: 0.004940
Epoch: 15 50000/60000 Training loss: 0.015201
Training loss: 0.019042
Test loss: 0.018612; Test accuracy: 9935/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.033057
Epoch: 16 10000/60000 Training loss: 0.009314
Epoch: 16 20000/60000 Training loss: 0.014286
Epoch: 16 30000/60000 Training loss: 0.034747
Epoch: 16 40000/60000 Training loss: 0.001905
Epoch: 16 50000/60000 Training loss: 0.033131
Training loss: 0.017162
Test loss: 0.018455; Test accuracy: 9944/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.011211
Epoch: 17 10000/60000 Training loss: 0.093075
Epoch: 17 20000/60000 Training loss: 0.010537
Epoch: 17 30000/60000 Training loss: 0.010230
Epoch: 17 40000/60000 Training loss: 0.011112
Epoch: 17 50000/60000 Training loss: 0.001400
Training loss: 0.016516
Test loss: 0.019316; Test accuracy: 9938/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.002583
Epoch: 18 10000/60000 Training loss: 0.008519
Epoch: 18 20000/60000 Training loss: 0.015213
Epoch: 18 30000/60000 Training loss: 0.003670
Epoch: 18 40000/60000 Training loss: 0.001456
Epoch: 18 50000/60000 Training loss: 0.005972
Training loss: 0.015504
Test loss: 0.018055; Test accuracy: 9948/10000 (99.5%)

Epoch: 19 0/60000 Training loss: 0.004938
Epoch: 19 10000/60000 Training loss: 0.003899
Epoch: 19 20000/60000 Training loss: 0.011773
Epoch: 19 30000/60000 Training loss: 0.001068
Epoch: 19 40000/60000 Training loss: 0.016377
Epoch: 19 50000/60000 Training loss: 0.006014
Training loss: 0.014539
Test loss: 0.021669; Test accuracy: 9932/10000 (99.3%)

[I 2022-11-04 04:21:43,575] Trial 68 finished with value: 0.018055249005556107 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.15790420785448692, 'fc1_neurons': 200, 'optimizer': 'Adam', 'learning_rate': 0.00012237259492083085}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 128, 'conv2_drop': 0.14799375993193434, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 8.092340362029411e-05}
Epoch: 0 0/60000 Training loss: 2.321647
Epoch: 0 10000/60000 Training loss: 0.545103
Epoch: 0 20000/60000 Training loss: 0.484250
Epoch: 0 30000/60000 Training loss: 0.366181
Epoch: 0 40000/60000 Training loss: 0.171557
Epoch: 0 50000/60000 Training loss: 0.181498
Training loss: 0.437281
Test loss: 0.101113; Test accuracy: 9685/10000 (96.8%)

Epoch: 1 0/60000 Training loss: 0.158950
Epoch: 1 10000/60000 Training loss: 0.147958
Epoch: 1 20000/60000 Training loss: 0.174329
Epoch: 1 30000/60000 Training loss: 0.121912
Epoch: 1 40000/60000 Training loss: 0.133937
Epoch: 1 50000/60000 Training loss: 0.125746
Training loss: 0.127908
Test loss: 0.060390; Test accuracy: 9808/10000 (98.1%)

Epoch: 2 0/60000 Training loss: 0.083359
Epoch: 2 10000/60000 Training loss: 0.068231
Epoch: 2 20000/60000 Training loss: 0.077117
Epoch: 2 30000/60000 Training loss: 0.136284
Epoch: 2 40000/60000 Training loss: 0.075878
Epoch: 2 50000/60000 Training loss: 0.027350
Training loss: 0.090435
Test loss: 0.043785; Test accuracy: 9858/10000 (98.6%)

Epoch: 3 0/60000 Training loss: 0.106316
Epoch: 3 10000/60000 Training loss: 0.058729
Epoch: 3 20000/60000 Training loss: 0.011423
Epoch: 3 30000/60000 Training loss: 0.100147
Epoch: 3 40000/60000 Training loss: 0.074356
Epoch: 3 50000/60000 Training loss: 0.032194
Training loss: 0.070517
Test loss: 0.037174; Test accuracy: 9881/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.090249
Epoch: 4 10000/60000 Training loss: 0.023460
Epoch: 4 20000/60000 Training loss: 0.085249
Epoch: 4 30000/60000 Training loss: 0.088266
Epoch: 4 40000/60000 Training loss: 0.085549
Epoch: 4 50000/60000 Training loss: 0.056589
Training loss: 0.060238
Test loss: 0.032337; Test accuracy: 9903/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.058954
Epoch: 5 10000/60000 Training loss: 0.083475
Epoch: 5 20000/60000 Training loss: 0.054249
Epoch: 5 30000/60000 Training loss: 0.073183
Epoch: 5 40000/60000 Training loss: 0.054002
Epoch: 5 50000/60000 Training loss: 0.139577
Training loss: 0.051719
Test loss: 0.030532; Test accuracy: 9899/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.049137
Epoch: 6 10000/60000 Training loss: 0.042809
Epoch: 6 20000/60000 Training loss: 0.041658
Epoch: 6 30000/60000 Training loss: 0.035832
Epoch: 6 40000/60000 Training loss: 0.066234
Epoch: 6 50000/60000 Training loss: 0.047649
Training loss: 0.045428
Test loss: 0.027743; Test accuracy: 9910/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.009642
Epoch: 7 10000/60000 Training loss: 0.023027
Epoch: 7 20000/60000 Training loss: 0.061238
Epoch: 7 30000/60000 Training loss: 0.007321
Epoch: 7 40000/60000 Training loss: 0.040518
Epoch: 7 50000/60000 Training loss: 0.049294
Training loss: 0.041749
Test loss: 0.024559; Test accuracy: 9923/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.054294
Epoch: 8 10000/60000 Training loss: 0.095263
Epoch: 8 20000/60000 Training loss: 0.031840
Epoch: 8 30000/60000 Training loss: 0.051222
Epoch: 8 40000/60000 Training loss: 0.022695
Epoch: 8 50000/60000 Training loss: 0.024699
Training loss: 0.037140
Test loss: 0.023740; Test accuracy: 9923/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.005660
Epoch: 9 10000/60000 Training loss: 0.016172
Epoch: 9 20000/60000 Training loss: 0.076625
Epoch: 9 30000/60000 Training loss: 0.009301
Epoch: 9 40000/60000 Training loss: 0.013889
Epoch: 9 50000/60000 Training loss: 0.051016
Training loss: 0.034114
Test loss: 0.023419; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.005557
Epoch: 10 10000/60000 Training loss: 0.037955
Epoch: 10 20000/60000 Training loss: 0.042544
Epoch: 10 30000/60000 Training loss: 0.012647
Epoch: 10 40000/60000 Training loss: 0.003182
Epoch: 10 50000/60000 Training loss: 0.014583
Training loss: 0.029452
Test loss: 0.024333; Test accuracy: 9919/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.053358
Epoch: 11 10000/60000 Training loss: 0.024416
Epoch: 11 20000/60000 Training loss: 0.002234
Epoch: 11 30000/60000 Training loss: 0.017536
Epoch: 11 40000/60000 Training loss: 0.003875
Epoch: 11 50000/60000 Training loss: 0.042750
Training loss: 0.027776
Test loss: 0.023251; Test accuracy: 9929/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.004857
Epoch: 12 10000/60000 Training loss: 0.010314
Epoch: 12 20000/60000 Training loss: 0.012378
Epoch: 12 30000/60000 Training loss: 0.022444
Epoch: 12 40000/60000 Training loss: 0.059487
Epoch: 12 50000/60000 Training loss: 0.005541
Training loss: 0.026762
Test loss: 0.019927; Test accuracy: 9933/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.006089
Epoch: 13 10000/60000 Training loss: 0.017725
Epoch: 13 20000/60000 Training loss: 0.003553
Epoch: 13 30000/60000 Training loss: 0.022755
Epoch: 13 40000/60000 Training loss: 0.030567
Epoch: 13 50000/60000 Training loss: 0.059719
Training loss: 0.023395
Test loss: 0.020439; Test accuracy: 9933/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.012583
Epoch: 14 10000/60000 Training loss: 0.038992
Epoch: 14 20000/60000 Training loss: 0.041649
Epoch: 14 30000/60000 Training loss: 0.003291
Epoch: 14 40000/60000 Training loss: 0.014445
Epoch: 14 50000/60000 Training loss: 0.041211
Training loss: 0.022202
Test loss: 0.018282; Test accuracy: 9934/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.021447
Epoch: 15 10000/60000 Training loss: 0.013705
Epoch: 15 20000/60000 Training loss: 0.005491
Epoch: 15 30000/60000 Training loss: 0.006586
Epoch: 15 40000/60000 Training loss: 0.002162
Epoch: 15 50000/60000 Training loss: 0.016304
Training loss: 0.021593
Test loss: 0.018817; Test accuracy: 9939/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.000843
Epoch: 16 10000/60000 Training loss: 0.010986
Epoch: 16 20000/60000 Training loss: 0.004352
Epoch: 16 30000/60000 Training loss: 0.020778
Epoch: 16 40000/60000 Training loss: 0.007966
Epoch: 16 50000/60000 Training loss: 0.030640
Training loss: 0.019243
Test loss: 0.019493; Test accuracy: 9939/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.029162
Epoch: 17 10000/60000 Training loss: 0.001286
Epoch: 17 20000/60000 Training loss: 0.001047
Epoch: 17 30000/60000 Training loss: 0.005805
Epoch: 17 40000/60000 Training loss: 0.005132
Epoch: 17 50000/60000 Training loss: 0.013975
Training loss: 0.017258
Test loss: 0.020236; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 04:25:55,587] Trial 69 finished with value: 0.01828196458518505 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 128, 'conv2_drop': 0.14799375993193434, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 8.092340362029411e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.1705646051005542, 'fc1_neurons': 200, 'optimizer': 'SGD', 'learning_rate': 0.00015408006097327806}
Epoch: 0 0/60000 Training loss: 2.329400
Epoch: 0 10000/60000 Training loss: 2.340358
Epoch: 0 20000/60000 Training loss: 2.276098
Epoch: 0 30000/60000 Training loss: 2.284738
Epoch: 0 40000/60000 Training loss: 2.271687
Epoch: 0 50000/60000 Training loss: 2.235663
Training loss: 2.280337
Test loss: 2.235224; Test accuracy: 2988/10000 (29.9%)

Epoch: 1 0/60000 Training loss: 2.271597
Epoch: 1 10000/60000 Training loss: 2.216499
Epoch: 1 20000/60000 Training loss: 2.224617
Epoch: 1 30000/60000 Training loss: 2.234268
Epoch: 1 40000/60000 Training loss: 2.206512
Epoch: 1 50000/60000 Training loss: 2.179591
Training loss: 2.213896
Test loss: 2.159292; Test accuracy: 5849/10000 (58.5%)

Epoch: 2 0/60000 Training loss: 2.177440
Epoch: 2 10000/60000 Training loss: 2.166634
Epoch: 2 20000/60000 Training loss: 2.144513
Epoch: 2 30000/60000 Training loss: 2.121920
Epoch: 2 40000/60000 Training loss: 2.145014
Epoch: 2 50000/60000 Training loss: 2.076724
Training loss: 2.135831
Test loss: 2.058933; Test accuracy: 6941/10000 (69.4%)

Epoch: 3 0/60000 Training loss: 2.115511
Epoch: 3 10000/60000 Training loss: 2.109914
Epoch: 3 20000/60000 Training loss: 2.032508
Epoch: 3 30000/60000 Training loss: 2.028549
Epoch: 3 40000/60000 Training loss: 2.015421
Epoch: 3 50000/60000 Training loss: 1.978038
Training loss: 2.032566
Test loss: 1.923015; Test accuracy: 7449/10000 (74.5%)

Epoch: 4 0/60000 Training loss: 2.020649
Epoch: 4 10000/60000 Training loss: 1.943372
Epoch: 4 20000/60000 Training loss: 1.876005
Epoch: 4 30000/60000 Training loss: 1.938397
Epoch: 4 40000/60000 Training loss: 1.809497
Epoch: 4 50000/60000 Training loss: 1.776097
Training loss: 1.897784
Test loss: 1.748843; Test accuracy: 7667/10000 (76.7%)

Epoch: 5 0/60000 Training loss: 1.719277
Epoch: 5 10000/60000 Training loss: 1.757445
Epoch: 5 20000/60000 Training loss: 1.752730
Epoch: 5 30000/60000 Training loss: 1.729574
Epoch: 5 40000/60000 Training loss: 1.698107
Epoch: 5 50000/60000 Training loss: 1.650870
Training loss: 1.727999
Test loss: 1.541803; Test accuracy: 7757/10000 (77.6%)

Epoch: 6 0/60000 Training loss: 1.649698
Epoch: 6 10000/60000 Training loss: 1.543804
Epoch: 6 20000/60000 Training loss: 1.516230
Epoch: 6 30000/60000 Training loss: 1.486124
Epoch: 6 40000/60000 Training loss: 1.531734
Epoch: 6 50000/60000 Training loss: 1.474755
Training loss: 1.546483
Test loss: 1.323459; Test accuracy: 7978/10000 (79.8%)

Epoch: 7 0/60000 Training loss: 1.405182
Epoch: 7 10000/60000 Training loss: 1.371929
Epoch: 7 20000/60000 Training loss: 1.360597
Epoch: 7 30000/60000 Training loss: 1.294762
Epoch: 7 40000/60000 Training loss: 1.330024
Epoch: 7 50000/60000 Training loss: 1.346449
Training loss: 1.360185
Test loss: 1.119671; Test accuracy: 8213/10000 (82.1%)

Epoch: 8 0/60000 Training loss: 1.216864
Epoch: 8 10000/60000 Training loss: 1.250701
Epoch: 8 20000/60000 Training loss: 1.231681
Epoch: 8 30000/60000 Training loss: 1.132274
Epoch: 8 40000/60000 Training loss: 1.184184
Epoch: 8 50000/60000 Training loss: 1.117934
Training loss: 1.201527
Test loss: 0.949996; Test accuracy: 8410/10000 (84.1%)

Epoch: 9 0/60000 Training loss: 1.185089
Epoch: 9 10000/60000 Training loss: 1.151962
Epoch: 9 20000/60000 Training loss: 1.144682
Epoch: 9 30000/60000 Training loss: 1.018778
Epoch: 9 40000/60000 Training loss: 1.020806
Epoch: 9 50000/60000 Training loss: 1.103902
Training loss: 1.061332
Test loss: 0.816023; Test accuracy: 8566/10000 (85.7%)

Epoch: 10 0/60000 Training loss: 1.023848
Epoch: 10 10000/60000 Training loss: 1.066661
Epoch: 10 20000/60000 Training loss: 0.890532
Epoch: 10 30000/60000 Training loss: 0.971481
Epoch: 10 40000/60000 Training loss: 0.806247
Epoch: 10 50000/60000 Training loss: 0.878446
Training loss: 0.954058
Test loss: 0.713073; Test accuracy: 8669/10000 (86.7%)

Epoch: 11 0/60000 Training loss: 0.740574
Epoch: 11 10000/60000 Training loss: 0.976860
Epoch: 11 20000/60000 Training loss: 0.798693
Epoch: 11 30000/60000 Training loss: 0.808005
Epoch: 11 40000/60000 Training loss: 0.819253
Epoch: 11 50000/60000 Training loss: 0.742064
Training loss: 0.865752
Test loss: 0.635152; Test accuracy: 8760/10000 (87.6%)

Epoch: 12 0/60000 Training loss: 0.799840
Epoch: 12 10000/60000 Training loss: 0.912431
Epoch: 12 20000/60000 Training loss: 0.824012
Epoch: 12 30000/60000 Training loss: 0.768956
Epoch: 12 40000/60000 Training loss: 0.659761
Epoch: 12 50000/60000 Training loss: 0.832317
Training loss: 0.796135
Test loss: 0.575491; Test accuracy: 8809/10000 (88.1%)

Epoch: 13 0/60000 Training loss: 0.689752
Epoch: 13 10000/60000 Training loss: 0.805816
Epoch: 13 20000/60000 Training loss: 0.701818
Epoch: 13 30000/60000 Training loss: 0.810144
Epoch: 13 40000/60000 Training loss: 0.745880
Epoch: 13 50000/60000 Training loss: 0.525706
Training loss: 0.741519
Test loss: 0.528741; Test accuracy: 8861/10000 (88.6%)

Epoch: 14 0/60000 Training loss: 0.755970
Epoch: 14 10000/60000 Training loss: 0.693254
Epoch: 14 20000/60000 Training loss: 0.849878
Epoch: 14 30000/60000 Training loss: 0.724710
Epoch: 14 40000/60000 Training loss: 0.688944
Epoch: 14 50000/60000 Training loss: 0.647326
Training loss: 0.696787
Test loss: 0.491167; Test accuracy: 8902/10000 (89.0%)

Epoch: 15 0/60000 Training loss: 0.680543
Epoch: 15 10000/60000 Training loss: 0.633910
Epoch: 15 20000/60000 Training loss: 0.704737
Epoch: 15 30000/60000 Training loss: 0.556507
Epoch: 15 40000/60000 Training loss: 0.646063
Epoch: 15 50000/60000 Training loss: 0.623790
Training loss: 0.658757
Test loss: 0.461046; Test accuracy: 8938/10000 (89.4%)

Epoch: 16 0/60000 Training loss: 0.627973
Epoch: 16 10000/60000 Training loss: 0.660027
Epoch: 16 20000/60000 Training loss: 0.656327
Epoch: 16 30000/60000 Training loss: 0.592162
Epoch: 16 40000/60000 Training loss: 0.580710
Epoch: 16 50000/60000 Training loss: 0.600240
Training loss: 0.624584
Test loss: 0.435932; Test accuracy: 8969/10000 (89.7%)

Epoch: 17 0/60000 Training loss: 0.541308
Epoch: 17 10000/60000 Training loss: 0.622979
Epoch: 17 20000/60000 Training loss: 0.611169
Epoch: 17 30000/60000 Training loss: 0.614239
Epoch: 17 40000/60000 Training loss: 0.620086
Epoch: 17 50000/60000 Training loss: 0.545799
Training loss: 0.599598
Test loss: 0.414322; Test accuracy: 9003/10000 (90.0%)

Epoch: 18 0/60000 Training loss: 0.590645
Epoch: 18 10000/60000 Training loss: 0.438149
Epoch: 18 20000/60000 Training loss: 0.455615
Epoch: 18 30000/60000 Training loss: 0.492336
Epoch: 18 40000/60000 Training loss: 0.389538
Epoch: 18 50000/60000 Training loss: 0.533316
Training loss: 0.571952
Test loss: 0.395528; Test accuracy: 9026/10000 (90.3%)

Epoch: 19 0/60000 Training loss: 0.629112
Epoch: 19 10000/60000 Training loss: 0.536685
Epoch: 19 20000/60000 Training loss: 0.649914
Epoch: 19 30000/60000 Training loss: 0.395363
Epoch: 19 40000/60000 Training loss: 0.637173
Epoch: 19 50000/60000 Training loss: 0.483514
Training loss: 0.551883
Test loss: 0.379463; Test accuracy: 9056/10000 (90.6%)

[I 2022-11-04 04:30:34,900] Trial 70 finished with value: 0.3794633746147156 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 112, 'conv2_drop': 0.1705646051005542, 'fc1_neurons': 200, 'optimizer': 'SGD', 'learning_rate': 0.00015408006097327806}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.1671074237419309, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00010867153234352736}
Epoch: 0 0/60000 Training loss: 2.320973
Epoch: 0 10000/60000 Training loss: 0.558310
Epoch: 0 20000/60000 Training loss: 0.331319
Epoch: 0 30000/60000 Training loss: 0.315057
Epoch: 0 40000/60000 Training loss: 0.121257
Epoch: 0 50000/60000 Training loss: 0.118649
Training loss: 0.388152
Test loss: 0.084050; Test accuracy: 9755/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.074774
Epoch: 1 10000/60000 Training loss: 0.109574
Epoch: 1 20000/60000 Training loss: 0.045557
Epoch: 1 30000/60000 Training loss: 0.035122
Epoch: 1 40000/60000 Training loss: 0.126758
Epoch: 1 50000/60000 Training loss: 0.065366
Training loss: 0.111496
Test loss: 0.048987; Test accuracy: 9850/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.096771
Epoch: 2 10000/60000 Training loss: 0.043431
Epoch: 2 20000/60000 Training loss: 0.141485
Epoch: 2 30000/60000 Training loss: 0.060005
Epoch: 2 40000/60000 Training loss: 0.048152
Epoch: 2 50000/60000 Training loss: 0.102822
Training loss: 0.077810
Test loss: 0.038014; Test accuracy: 9867/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.018419
Epoch: 3 10000/60000 Training loss: 0.060923
Epoch: 3 20000/60000 Training loss: 0.032206
Epoch: 3 30000/60000 Training loss: 0.080047
Epoch: 3 40000/60000 Training loss: 0.071929
Epoch: 3 50000/60000 Training loss: 0.032235
Training loss: 0.062462
Test loss: 0.034459; Test accuracy: 9882/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.057659
Epoch: 4 10000/60000 Training loss: 0.060137
Epoch: 4 20000/60000 Training loss: 0.043227
Epoch: 4 30000/60000 Training loss: 0.059737
Epoch: 4 40000/60000 Training loss: 0.012448
Epoch: 4 50000/60000 Training loss: 0.024509
Training loss: 0.052379
Test loss: 0.030969; Test accuracy: 9899/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.062212
Epoch: 5 10000/60000 Training loss: 0.054647
Epoch: 5 20000/60000 Training loss: 0.073525
Epoch: 5 30000/60000 Training loss: 0.010857
Epoch: 5 40000/60000 Training loss: 0.081807
Epoch: 5 50000/60000 Training loss: 0.056033
Training loss: 0.045578
Test loss: 0.024713; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.048633
Epoch: 6 10000/60000 Training loss: 0.009201
Epoch: 6 20000/60000 Training loss: 0.010318
Epoch: 6 30000/60000 Training loss: 0.078980
Epoch: 6 40000/60000 Training loss: 0.020053
Epoch: 6 50000/60000 Training loss: 0.050855
Training loss: 0.041979
Test loss: 0.023686; Test accuracy: 9921/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.061577
Epoch: 7 10000/60000 Training loss: 0.023655
Epoch: 7 20000/60000 Training loss: 0.002989
Epoch: 7 30000/60000 Training loss: 0.034390
Epoch: 7 40000/60000 Training loss: 0.029360
Epoch: 7 50000/60000 Training loss: 0.006554
Training loss: 0.036683
Test loss: 0.022925; Test accuracy: 9924/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.033996
Epoch: 8 10000/60000 Training loss: 0.022676
Epoch: 8 20000/60000 Training loss: 0.079399
Epoch: 8 30000/60000 Training loss: 0.016353
Epoch: 8 40000/60000 Training loss: 0.009729
Epoch: 8 50000/60000 Training loss: 0.032665
Training loss: 0.031953
Test loss: 0.020937; Test accuracy: 9931/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.009417
Epoch: 9 10000/60000 Training loss: 0.033947
Epoch: 9 20000/60000 Training loss: 0.030205
Epoch: 9 30000/60000 Training loss: 0.036612
Epoch: 9 40000/60000 Training loss: 0.075523
Epoch: 9 50000/60000 Training loss: 0.034629
Training loss: 0.029209
Test loss: 0.021786; Test accuracy: 9920/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.030082
Epoch: 10 10000/60000 Training loss: 0.061842
Epoch: 10 20000/60000 Training loss: 0.050049
Epoch: 10 30000/60000 Training loss: 0.062287
Epoch: 10 40000/60000 Training loss: 0.028904
Epoch: 10 50000/60000 Training loss: 0.011045
Training loss: 0.027066
Test loss: 0.020580; Test accuracy: 9922/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.017072
Epoch: 11 10000/60000 Training loss: 0.007468
Epoch: 11 20000/60000 Training loss: 0.005237
Epoch: 11 30000/60000 Training loss: 0.005502
Epoch: 11 40000/60000 Training loss: 0.080285
Epoch: 11 50000/60000 Training loss: 0.016551
Training loss: 0.025109
Test loss: 0.019972; Test accuracy: 9937/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.054146
Epoch: 12 10000/60000 Training loss: 0.061328
Epoch: 12 20000/60000 Training loss: 0.001330
Epoch: 12 30000/60000 Training loss: 0.032082
Epoch: 12 40000/60000 Training loss: 0.004256
Epoch: 12 50000/60000 Training loss: 0.003420
Training loss: 0.022008
Test loss: 0.018968; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.008648
Epoch: 13 10000/60000 Training loss: 0.002500
Epoch: 13 20000/60000 Training loss: 0.048975
Epoch: 13 30000/60000 Training loss: 0.004902
Epoch: 13 40000/60000 Training loss: 0.033004
Epoch: 13 50000/60000 Training loss: 0.008001
Training loss: 0.019792
Test loss: 0.021187; Test accuracy: 9930/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.011338
Epoch: 14 10000/60000 Training loss: 0.022990
Epoch: 14 20000/60000 Training loss: 0.009411
Epoch: 14 30000/60000 Training loss: 0.006038
Epoch: 14 40000/60000 Training loss: 0.004319
Epoch: 14 50000/60000 Training loss: 0.018835
Training loss: 0.018834
Test loss: 0.019858; Test accuracy: 9935/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.079982
Epoch: 15 10000/60000 Training loss: 0.026020
Epoch: 15 20000/60000 Training loss: 0.002116
Epoch: 15 30000/60000 Training loss: 0.004385
Epoch: 15 40000/60000 Training loss: 0.001598
Epoch: 15 50000/60000 Training loss: 0.007287
Training loss: 0.018810
Test loss: 0.018974; Test accuracy: 9937/10000 (99.4%)

[I 2022-11-04 04:34:18,684] Trial 71 finished with value: 0.018968330696225166 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.1671074237419309, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00010867153234352736}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.16084783389383214, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.00010272038273092293}
Epoch: 0 0/60000 Training loss: 2.326114
Epoch: 0 10000/60000 Training loss: 0.508476
Epoch: 0 20000/60000 Training loss: 0.203429
Epoch: 0 30000/60000 Training loss: 0.342569
Epoch: 0 40000/60000 Training loss: 0.255592
Epoch: 0 50000/60000 Training loss: 0.241996
Training loss: 0.410792
Test loss: 0.089633; Test accuracy: 9717/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.115277
Epoch: 1 10000/60000 Training loss: 0.262113
Epoch: 1 20000/60000 Training loss: 0.144168
Epoch: 1 30000/60000 Training loss: 0.133873
Epoch: 1 40000/60000 Training loss: 0.142323
Epoch: 1 50000/60000 Training loss: 0.073969
Training loss: 0.124278
Test loss: 0.052732; Test accuracy: 9836/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.058623
Epoch: 2 10000/60000 Training loss: 0.037158
Epoch: 2 20000/60000 Training loss: 0.048520
Epoch: 2 30000/60000 Training loss: 0.064551
Epoch: 2 40000/60000 Training loss: 0.015215
Epoch: 2 50000/60000 Training loss: 0.060098
Training loss: 0.086060
Test loss: 0.041482; Test accuracy: 9870/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.041169
Epoch: 3 10000/60000 Training loss: 0.069002
Epoch: 3 20000/60000 Training loss: 0.120220
Epoch: 3 30000/60000 Training loss: 0.067333
Epoch: 3 40000/60000 Training loss: 0.036448
Epoch: 3 50000/60000 Training loss: 0.050388
Training loss: 0.069150
Test loss: 0.033608; Test accuracy: 9887/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.049413
Epoch: 4 10000/60000 Training loss: 0.045106
Epoch: 4 20000/60000 Training loss: 0.046012
Epoch: 4 30000/60000 Training loss: 0.026999
Epoch: 4 40000/60000 Training loss: 0.076171
Epoch: 4 50000/60000 Training loss: 0.054830
Training loss: 0.058589
Test loss: 0.030410; Test accuracy: 9901/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.034175
Epoch: 5 10000/60000 Training loss: 0.055515
Epoch: 5 20000/60000 Training loss: 0.037358
Epoch: 5 30000/60000 Training loss: 0.099151
Epoch: 5 40000/60000 Training loss: 0.034379
Epoch: 5 50000/60000 Training loss: 0.046483
Training loss: 0.050764
Test loss: 0.026347; Test accuracy: 9915/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.084966
Epoch: 6 10000/60000 Training loss: 0.031869
Epoch: 6 20000/60000 Training loss: 0.024898
Epoch: 6 30000/60000 Training loss: 0.030749
Epoch: 6 40000/60000 Training loss: 0.015971
Epoch: 6 50000/60000 Training loss: 0.035956
Training loss: 0.045443
Test loss: 0.025974; Test accuracy: 9904/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.041081
Epoch: 7 10000/60000 Training loss: 0.052926
Epoch: 7 20000/60000 Training loss: 0.028703
Epoch: 7 30000/60000 Training loss: 0.021969
Epoch: 7 40000/60000 Training loss: 0.096742
Epoch: 7 50000/60000 Training loss: 0.022722
Training loss: 0.039365
Test loss: 0.024043; Test accuracy: 9917/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.003546
Epoch: 8 10000/60000 Training loss: 0.028699
Epoch: 8 20000/60000 Training loss: 0.100175
Epoch: 8 30000/60000 Training loss: 0.010044
Epoch: 8 40000/60000 Training loss: 0.008294
Epoch: 8 50000/60000 Training loss: 0.026985
Training loss: 0.036479
Test loss: 0.022243; Test accuracy: 9923/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.033517
Epoch: 9 10000/60000 Training loss: 0.025241
Epoch: 9 20000/60000 Training loss: 0.010554
Epoch: 9 30000/60000 Training loss: 0.013476
Epoch: 9 40000/60000 Training loss: 0.080228
Epoch: 9 50000/60000 Training loss: 0.045958
Training loss: 0.032630
Test loss: 0.020993; Test accuracy: 9928/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.014195
Epoch: 10 10000/60000 Training loss: 0.026745
Epoch: 10 20000/60000 Training loss: 0.020416
Epoch: 10 30000/60000 Training loss: 0.006765
Epoch: 10 40000/60000 Training loss: 0.014306
Epoch: 10 50000/60000 Training loss: 0.004687
Training loss: 0.030428
Test loss: 0.021754; Test accuracy: 9921/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.019957
Epoch: 11 10000/60000 Training loss: 0.067843
Epoch: 11 20000/60000 Training loss: 0.038536
Epoch: 11 30000/60000 Training loss: 0.027028
Epoch: 11 40000/60000 Training loss: 0.028621
Epoch: 11 50000/60000 Training loss: 0.007566
Training loss: 0.027297
Test loss: 0.019061; Test accuracy: 9930/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.016448
Epoch: 12 10000/60000 Training loss: 0.020009
Epoch: 12 20000/60000 Training loss: 0.013053
Epoch: 12 30000/60000 Training loss: 0.007872
Epoch: 12 40000/60000 Training loss: 0.008777
Epoch: 12 50000/60000 Training loss: 0.037727
Training loss: 0.025836
Test loss: 0.019035; Test accuracy: 9936/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.013790
Epoch: 13 10000/60000 Training loss: 0.042983
Epoch: 13 20000/60000 Training loss: 0.033649
Epoch: 13 30000/60000 Training loss: 0.013609
Epoch: 13 40000/60000 Training loss: 0.010624
Epoch: 13 50000/60000 Training loss: 0.011071
Training loss: 0.023524
Test loss: 0.019796; Test accuracy: 9938/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.001738
Epoch: 14 10000/60000 Training loss: 0.007111
Epoch: 14 20000/60000 Training loss: 0.020328
Epoch: 14 30000/60000 Training loss: 0.113938
Epoch: 14 40000/60000 Training loss: 0.004179
Epoch: 14 50000/60000 Training loss: 0.010850
Training loss: 0.021263
Test loss: 0.018793; Test accuracy: 9934/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.029947
Epoch: 15 10000/60000 Training loss: 0.024150
Epoch: 15 20000/60000 Training loss: 0.002472
Epoch: 15 30000/60000 Training loss: 0.003280
Epoch: 15 40000/60000 Training loss: 0.014537
Epoch: 15 50000/60000 Training loss: 0.010494
Training loss: 0.020160
Test loss: 0.018434; Test accuracy: 9940/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.012919
Epoch: 16 10000/60000 Training loss: 0.005324
Epoch: 16 20000/60000 Training loss: 0.017628
Epoch: 16 30000/60000 Training loss: 0.011424
Epoch: 16 40000/60000 Training loss: 0.031777
Epoch: 16 50000/60000 Training loss: 0.010659
Training loss: 0.019467
Test loss: 0.017594; Test accuracy: 9941/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.008965
Epoch: 17 10000/60000 Training loss: 0.027458
Epoch: 17 20000/60000 Training loss: 0.029124
Epoch: 17 30000/60000 Training loss: 0.014217
Epoch: 17 40000/60000 Training loss: 0.034554
Epoch: 17 50000/60000 Training loss: 0.001707
Training loss: 0.017180
Test loss: 0.018876; Test accuracy: 9941/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.001449
Epoch: 18 10000/60000 Training loss: 0.067297
Epoch: 18 20000/60000 Training loss: 0.001586
Epoch: 18 30000/60000 Training loss: 0.019096
Epoch: 18 40000/60000 Training loss: 0.009629
Epoch: 18 50000/60000 Training loss: 0.066870
Training loss: 0.015953
Test loss: 0.017885; Test accuracy: 9939/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.001444
Epoch: 19 10000/60000 Training loss: 0.007852
Epoch: 19 20000/60000 Training loss: 0.014983
Epoch: 19 30000/60000 Training loss: 0.012280
Epoch: 19 40000/60000 Training loss: 0.070051
Epoch: 19 50000/60000 Training loss: 0.045492
Training loss: 0.015428
Test loss: 0.017729; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 04:38:59,334] Trial 72 finished with value: 0.0175944697111845 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.16084783389383214, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.00010272038273092293}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16055735419003173, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0003076867531025789}
Epoch: 0 0/60000 Training loss: 2.294015
Epoch: 0 10000/60000 Training loss: 0.229184
Epoch: 0 20000/60000 Training loss: 0.164283
Epoch: 0 30000/60000 Training loss: 0.126230
Epoch: 0 40000/60000 Training loss: 0.163301
Epoch: 0 50000/60000 Training loss: 0.060172
Training loss: 0.245798
Test loss: 0.053333; Test accuracy: 9833/10000 (98.3%)

Epoch: 1 0/60000 Training loss: 0.081459
Epoch: 1 10000/60000 Training loss: 0.050440
Epoch: 1 20000/60000 Training loss: 0.048589
Epoch: 1 30000/60000 Training loss: 0.176285
Epoch: 1 40000/60000 Training loss: 0.048371
Epoch: 1 50000/60000 Training loss: 0.035846
Training loss: 0.076102
Test loss: 0.031967; Test accuracy: 9894/10000 (98.9%)

Epoch: 2 0/60000 Training loss: 0.161586
Epoch: 2 10000/60000 Training loss: 0.013903
Epoch: 2 20000/60000 Training loss: 0.025982
Epoch: 2 30000/60000 Training loss: 0.102354
Epoch: 2 40000/60000 Training loss: 0.015592
Epoch: 2 50000/60000 Training loss: 0.057613
Training loss: 0.055220
Test loss: 0.029047; Test accuracy: 9904/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.026133
Epoch: 3 10000/60000 Training loss: 0.005541
Epoch: 3 20000/60000 Training loss: 0.009988
Epoch: 3 30000/60000 Training loss: 0.092343
Epoch: 3 40000/60000 Training loss: 0.067110
Epoch: 3 50000/60000 Training loss: 0.021853
Training loss: 0.043417
Test loss: 0.024273; Test accuracy: 9916/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.051731
Epoch: 4 10000/60000 Training loss: 0.057179
Epoch: 4 20000/60000 Training loss: 0.010952
Epoch: 4 30000/60000 Training loss: 0.019851
Epoch: 4 40000/60000 Training loss: 0.015576
Epoch: 4 50000/60000 Training loss: 0.002817
Training loss: 0.035247
Test loss: 0.021225; Test accuracy: 9928/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.005269
Epoch: 5 10000/60000 Training loss: 0.025936
Epoch: 5 20000/60000 Training loss: 0.036284
Epoch: 5 30000/60000 Training loss: 0.009417
Epoch: 5 40000/60000 Training loss: 0.058476
Epoch: 5 50000/60000 Training loss: 0.049823
Training loss: 0.031368
Test loss: 0.019992; Test accuracy: 9936/10000 (99.4%)

Epoch: 6 0/60000 Training loss: 0.024707
Epoch: 6 10000/60000 Training loss: 0.003147
Epoch: 6 20000/60000 Training loss: 0.007089
Epoch: 6 30000/60000 Training loss: 0.009422
Epoch: 6 40000/60000 Training loss: 0.015770
Epoch: 6 50000/60000 Training loss: 0.007220
Training loss: 0.026242
Test loss: 0.018992; Test accuracy: 9938/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.028745
Epoch: 7 10000/60000 Training loss: 0.012297
Epoch: 7 20000/60000 Training loss: 0.013414
Epoch: 7 30000/60000 Training loss: 0.005125
Epoch: 7 40000/60000 Training loss: 0.001108
Epoch: 7 50000/60000 Training loss: 0.036358
Training loss: 0.022229
Test loss: 0.017939; Test accuracy: 9940/10000 (99.4%)

Epoch: 8 0/60000 Training loss: 0.015110
Epoch: 8 10000/60000 Training loss: 0.056453
Epoch: 8 20000/60000 Training loss: 0.003579
Epoch: 8 30000/60000 Training loss: 0.029584
Epoch: 8 40000/60000 Training loss: 0.099428
Epoch: 8 50000/60000 Training loss: 0.001540
Training loss: 0.020980
Test loss: 0.018878; Test accuracy: 9939/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.027935
Epoch: 9 10000/60000 Training loss: 0.011450
Epoch: 9 20000/60000 Training loss: 0.009350
Epoch: 9 30000/60000 Training loss: 0.002626
Epoch: 9 40000/60000 Training loss: 0.010096
Epoch: 9 50000/60000 Training loss: 0.001306
Training loss: 0.018602
Test loss: 0.021821; Test accuracy: 9934/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.058434
Epoch: 10 10000/60000 Training loss: 0.003674
Epoch: 10 20000/60000 Training loss: 0.005148
Epoch: 10 30000/60000 Training loss: 0.006416
Epoch: 10 40000/60000 Training loss: 0.007005
Epoch: 10 50000/60000 Training loss: 0.001316
Training loss: 0.017753
Test loss: 0.021761; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 04:41:34,091] Trial 73 finished with value: 0.017939476296305656 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.16055735419003173, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0003076867531025789}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.16043844993135065, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.00031827991529664277}
Epoch: 0 0/60000 Training loss: 2.335199
Epoch: 0 10000/60000 Training loss: 0.300700
Epoch: 0 20000/60000 Training loss: 0.198871
Epoch: 0 30000/60000 Training loss: 0.108288
Epoch: 0 40000/60000 Training loss: 0.229691
Epoch: 0 50000/60000 Training loss: 0.103175
Training loss: 0.256290
Test loss: 0.050007; Test accuracy: 9851/10000 (98.5%)

Epoch: 1 0/60000 Training loss: 0.079020
Epoch: 1 10000/60000 Training loss: 0.238150
Epoch: 1 20000/60000 Training loss: 0.055444
Epoch: 1 30000/60000 Training loss: 0.044949
Epoch: 1 40000/60000 Training loss: 0.047253
Epoch: 1 50000/60000 Training loss: 0.032971
Training loss: 0.079515
Test loss: 0.037270; Test accuracy: 9884/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.032423
Epoch: 2 10000/60000 Training loss: 0.009296
Epoch: 2 20000/60000 Training loss: 0.135162
Epoch: 2 30000/60000 Training loss: 0.016443
Epoch: 2 40000/60000 Training loss: 0.113476
Epoch: 2 50000/60000 Training loss: 0.067509
Training loss: 0.057005
Test loss: 0.029220; Test accuracy: 9901/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.043053
Epoch: 3 10000/60000 Training loss: 0.005914
Epoch: 3 20000/60000 Training loss: 0.050414
Epoch: 3 30000/60000 Training loss: 0.103215
Epoch: 3 40000/60000 Training loss: 0.041699
Epoch: 3 50000/60000 Training loss: 0.023211
Training loss: 0.046206
Test loss: 0.029370; Test accuracy: 9903/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.004800
Epoch: 4 10000/60000 Training loss: 0.043871
Epoch: 4 20000/60000 Training loss: 0.071735
Epoch: 4 30000/60000 Training loss: 0.022846
Epoch: 4 40000/60000 Training loss: 0.023401
Epoch: 4 50000/60000 Training loss: 0.076003
Training loss: 0.038281
Test loss: 0.021801; Test accuracy: 9917/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.038263
Epoch: 5 10000/60000 Training loss: 0.033067
Epoch: 5 20000/60000 Training loss: 0.022456
Epoch: 5 30000/60000 Training loss: 0.016388
Epoch: 5 40000/60000 Training loss: 0.008126
Epoch: 5 50000/60000 Training loss: 0.013552
Training loss: 0.033138
Test loss: 0.022016; Test accuracy: 9929/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.015149
Epoch: 6 10000/60000 Training loss: 0.034767
Epoch: 6 20000/60000 Training loss: 0.019517
Epoch: 6 30000/60000 Training loss: 0.009544
Epoch: 6 40000/60000 Training loss: 0.068102
Epoch: 6 50000/60000 Training loss: 0.009744
Training loss: 0.029187
Test loss: 0.022347; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.010696
Epoch: 7 10000/60000 Training loss: 0.006600
Epoch: 7 20000/60000 Training loss: 0.003166
Epoch: 7 30000/60000 Training loss: 0.012899
Epoch: 7 40000/60000 Training loss: 0.024834
Epoch: 7 50000/60000 Training loss: 0.023817
Training loss: 0.026983
Test loss: 0.021377; Test accuracy: 9931/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.029120
Epoch: 8 10000/60000 Training loss: 0.029360
Epoch: 8 20000/60000 Training loss: 0.017974
Epoch: 8 30000/60000 Training loss: 0.055656
Epoch: 8 40000/60000 Training loss: 0.024833
Epoch: 8 50000/60000 Training loss: 0.004115
Training loss: 0.024279
Test loss: 0.017436; Test accuracy: 9940/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.005116
Epoch: 9 10000/60000 Training loss: 0.062888
Epoch: 9 20000/60000 Training loss: 0.019196
Epoch: 9 30000/60000 Training loss: 0.007832
Epoch: 9 40000/60000 Training loss: 0.010261
Epoch: 9 50000/60000 Training loss: 0.011349
Training loss: 0.021447
Test loss: 0.020539; Test accuracy: 9931/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.020235
Epoch: 10 10000/60000 Training loss: 0.006147
Epoch: 10 20000/60000 Training loss: 0.001702
Epoch: 10 30000/60000 Training loss: 0.035446
Epoch: 10 40000/60000 Training loss: 0.005969
Epoch: 10 50000/60000 Training loss: 0.006920
Training loss: 0.018735
Test loss: 0.020026; Test accuracy: 9938/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.002061
Epoch: 11 10000/60000 Training loss: 0.016248
Epoch: 11 20000/60000 Training loss: 0.039340
Epoch: 11 30000/60000 Training loss: 0.001812
Epoch: 11 40000/60000 Training loss: 0.005747
Epoch: 11 50000/60000 Training loss: 0.020148
Training loss: 0.017059
Test loss: 0.018894; Test accuracy: 9941/10000 (99.4%)

[I 2022-11-04 04:44:22,507] Trial 74 finished with value: 0.017435584217309952 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.16043844993135065, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.00031827991529664277}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.15436088680426432, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0004452734924088796}
Epoch: 0 0/60000 Training loss: 2.317117
Epoch: 0 10000/60000 Training loss: 0.340161
Epoch: 0 20000/60000 Training loss: 0.157035
Epoch: 0 30000/60000 Training loss: 0.241456
Epoch: 0 40000/60000 Training loss: 0.056134
Epoch: 0 50000/60000 Training loss: 0.101182
Training loss: 0.237604
Test loss: 0.047276; Test accuracy: 9837/10000 (98.4%)

Epoch: 1 0/60000 Training loss: 0.017292
Epoch: 1 10000/60000 Training loss: 0.080874
Epoch: 1 20000/60000 Training loss: 0.038035
Epoch: 1 30000/60000 Training loss: 0.101122
Epoch: 1 40000/60000 Training loss: 0.076333
Epoch: 1 50000/60000 Training loss: 0.053766
Training loss: 0.073315
Test loss: 0.033847; Test accuracy: 9882/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.072195
Epoch: 2 10000/60000 Training loss: 0.042828
Epoch: 2 20000/60000 Training loss: 0.036429
Epoch: 2 30000/60000 Training loss: 0.051136
Epoch: 2 40000/60000 Training loss: 0.004182
Epoch: 2 50000/60000 Training loss: 0.025752
Training loss: 0.054538
Test loss: 0.027172; Test accuracy: 9908/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.060290
Epoch: 3 10000/60000 Training loss: 0.023390
Epoch: 3 20000/60000 Training loss: 0.019611
Epoch: 3 30000/60000 Training loss: 0.015003
Epoch: 3 40000/60000 Training loss: 0.004042
Epoch: 3 50000/60000 Training loss: 0.019809
Training loss: 0.043827
Test loss: 0.024461; Test accuracy: 9922/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.038608
Epoch: 4 10000/60000 Training loss: 0.021264
Epoch: 4 20000/60000 Training loss: 0.030449
Epoch: 4 30000/60000 Training loss: 0.095570
Epoch: 4 40000/60000 Training loss: 0.016033
Epoch: 4 50000/60000 Training loss: 0.053962
Training loss: 0.037722
Test loss: 0.020038; Test accuracy: 9938/10000 (99.4%)

Epoch: 5 0/60000 Training loss: 0.096069
Epoch: 5 10000/60000 Training loss: 0.050178
Epoch: 5 20000/60000 Training loss: 0.016878
Epoch: 5 30000/60000 Training loss: 0.064238
Epoch: 5 40000/60000 Training loss: 0.022829
Epoch: 5 50000/60000 Training loss: 0.034708
Training loss: 0.030579
Test loss: 0.020475; Test accuracy: 9938/10000 (99.4%)

Epoch: 6 0/60000 Training loss: 0.005284
Epoch: 6 10000/60000 Training loss: 0.017636
Epoch: 6 20000/60000 Training loss: 0.006743
Epoch: 6 30000/60000 Training loss: 0.053442
Epoch: 6 40000/60000 Training loss: 0.008584
Epoch: 6 50000/60000 Training loss: 0.011630
Training loss: 0.028513
Test loss: 0.020507; Test accuracy: 9926/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.010005
Epoch: 7 10000/60000 Training loss: 0.002716
Epoch: 7 20000/60000 Training loss: 0.047685
Epoch: 7 30000/60000 Training loss: 0.004867
Epoch: 7 40000/60000 Training loss: 0.014377
Epoch: 7 50000/60000 Training loss: 0.007936
Training loss: 0.024608
Test loss: 0.022130; Test accuracy: 9930/10000 (99.3%)

[I 2022-11-04 04:46:15,037] Trial 75 finished with value: 0.020038248971104622 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 80, 'conv2_drop': 0.15436088680426432, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0004452734924088796}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 80, 'conv2_drop': 0.16037716099222302, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.0005845455754656542}
Epoch: 0 0/60000 Training loss: 2.314406
Epoch: 0 10000/60000 Training loss: 0.210157
Epoch: 0 20000/60000 Training loss: 0.091016
Epoch: 0 30000/60000 Training loss: 0.116647
Epoch: 0 40000/60000 Training loss: 0.193076
Epoch: 0 50000/60000 Training loss: 0.041777
Training loss: 0.197695
Test loss: 0.042329; Test accuracy: 9861/10000 (98.6%)

Epoch: 1 0/60000 Training loss: 0.062357
Epoch: 1 10000/60000 Training loss: 0.124287
Epoch: 1 20000/60000 Training loss: 0.121047
Epoch: 1 30000/60000 Training loss: 0.005843
Epoch: 1 40000/60000 Training loss: 0.117404
Epoch: 1 50000/60000 Training loss: 0.009058
Training loss: 0.066274
Test loss: 0.030208; Test accuracy: 9898/10000 (99.0%)

Epoch: 2 0/60000 Training loss: 0.014770
Epoch: 2 10000/60000 Training loss: 0.008992
Epoch: 2 20000/60000 Training loss: 0.046908
Epoch: 2 30000/60000 Training loss: 0.078128
Epoch: 2 40000/60000 Training loss: 0.055268
Epoch: 2 50000/60000 Training loss: 0.030698
Training loss: 0.048882
Test loss: 0.029048; Test accuracy: 9912/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.035929
Epoch: 3 10000/60000 Training loss: 0.003324
Epoch: 3 20000/60000 Training loss: 0.082414
Epoch: 3 30000/60000 Training loss: 0.026667
Epoch: 3 40000/60000 Training loss: 0.022297
Epoch: 3 50000/60000 Training loss: 0.012606
Training loss: 0.040715
Test loss: 0.030874; Test accuracy: 9896/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.017567
Epoch: 4 10000/60000 Training loss: 0.076421
Epoch: 4 20000/60000 Training loss: 0.005090
Epoch: 4 30000/60000 Training loss: 0.043164
Epoch: 4 40000/60000 Training loss: 0.056907
Epoch: 4 50000/60000 Training loss: 0.017640
Training loss: 0.033629
Test loss: 0.023466; Test accuracy: 9926/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.012560
Epoch: 5 10000/60000 Training loss: 0.041107
Epoch: 5 20000/60000 Training loss: 0.010861
Epoch: 5 30000/60000 Training loss: 0.086135
Epoch: 5 40000/60000 Training loss: 0.004168
Epoch: 5 50000/60000 Training loss: 0.017641
Training loss: 0.029694
Test loss: 0.026817; Test accuracy: 9915/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.049231
Epoch: 6 10000/60000 Training loss: 0.025654
Epoch: 6 20000/60000 Training loss: 0.040861
Epoch: 6 30000/60000 Training loss: 0.042073
Epoch: 6 40000/60000 Training loss: 0.009729
Epoch: 6 50000/60000 Training loss: 0.018126
Training loss: 0.027999
Test loss: 0.020765; Test accuracy: 9937/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.044457
Epoch: 7 10000/60000 Training loss: 0.009807
Epoch: 7 20000/60000 Training loss: 0.012725
Epoch: 7 30000/60000 Training loss: 0.004294
Epoch: 7 40000/60000 Training loss: 0.008876
Epoch: 7 50000/60000 Training loss: 0.000937
Training loss: 0.024112
Test loss: 0.022966; Test accuracy: 9931/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.017890
Epoch: 8 10000/60000 Training loss: 0.000756
Epoch: 8 20000/60000 Training loss: 0.042005
Epoch: 8 30000/60000 Training loss: 0.001971
Epoch: 8 40000/60000 Training loss: 0.003320
Epoch: 8 50000/60000 Training loss: 0.067774
Training loss: 0.020116
Test loss: 0.020375; Test accuracy: 9941/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.027767
Epoch: 9 10000/60000 Training loss: 0.006679
Epoch: 9 20000/60000 Training loss: 0.012997
Epoch: 9 30000/60000 Training loss: 0.004181
Epoch: 9 40000/60000 Training loss: 0.002434
Epoch: 9 50000/60000 Training loss: 0.005887
Training loss: 0.018732
Test loss: 0.025109; Test accuracy: 9927/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.020536
Epoch: 10 10000/60000 Training loss: 0.000372
Epoch: 10 20000/60000 Training loss: 0.001074
Epoch: 10 30000/60000 Training loss: 0.000562
Epoch: 10 40000/60000 Training loss: 0.000523
Epoch: 10 50000/60000 Training loss: 0.079006
Training loss: 0.016114
Test loss: 0.020668; Test accuracy: 9940/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.000609
Epoch: 11 10000/60000 Training loss: 0.002450
Epoch: 11 20000/60000 Training loss: 0.000422
Epoch: 11 30000/60000 Training loss: 0.000846
Epoch: 11 40000/60000 Training loss: 0.039188
Epoch: 11 50000/60000 Training loss: 0.055346
Training loss: 0.015983
Test loss: 0.022924; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 04:49:03,363] Trial 76 finished with value: 0.020374581217765808 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 80, 'conv2_drop': 0.16037716099222302, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.0005845455754656542}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.17445397083032096, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0002932998136322034}
Epoch: 0 0/60000 Training loss: 2.338374
Epoch: 0 10000/60000 Training loss: 0.257774
Epoch: 0 20000/60000 Training loss: 0.143663
Epoch: 0 30000/60000 Training loss: 0.224779
Epoch: 0 40000/60000 Training loss: 0.239802
Epoch: 0 50000/60000 Training loss: 0.101162
Training loss: 0.303162
Test loss: 0.058497; Test accuracy: 9811/10000 (98.1%)

Epoch: 1 0/60000 Training loss: 0.108176
Epoch: 1 10000/60000 Training loss: 0.081608
Epoch: 1 20000/60000 Training loss: 0.170810
Epoch: 1 30000/60000 Training loss: 0.150877
Epoch: 1 40000/60000 Training loss: 0.090224
Epoch: 1 50000/60000 Training loss: 0.136307
Training loss: 0.089879
Test loss: 0.037920; Test accuracy: 9879/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.130378
Epoch: 2 10000/60000 Training loss: 0.040449
Epoch: 2 20000/60000 Training loss: 0.033335
Epoch: 2 30000/60000 Training loss: 0.082406
Epoch: 2 40000/60000 Training loss: 0.150909
Epoch: 2 50000/60000 Training loss: 0.029276
Training loss: 0.065656
Test loss: 0.029938; Test accuracy: 9912/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.048990
Epoch: 3 10000/60000 Training loss: 0.035224
Epoch: 3 20000/60000 Training loss: 0.019151
Epoch: 3 30000/60000 Training loss: 0.083781
Epoch: 3 40000/60000 Training loss: 0.018366
Epoch: 3 50000/60000 Training loss: 0.038705
Training loss: 0.052583
Test loss: 0.029221; Test accuracy: 9897/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.117395
Epoch: 4 10000/60000 Training loss: 0.100876
Epoch: 4 20000/60000 Training loss: 0.037036
Epoch: 4 30000/60000 Training loss: 0.024897
Epoch: 4 40000/60000 Training loss: 0.048987
Epoch: 4 50000/60000 Training loss: 0.004709
Training loss: 0.043713
Test loss: 0.024902; Test accuracy: 9914/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.015575
Epoch: 5 10000/60000 Training loss: 0.014829
Epoch: 5 20000/60000 Training loss: 0.050250
Epoch: 5 30000/60000 Training loss: 0.067815
Epoch: 5 40000/60000 Training loss: 0.006369
Epoch: 5 50000/60000 Training loss: 0.019621
Training loss: 0.036945
Test loss: 0.021294; Test accuracy: 9930/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.015213
Epoch: 6 10000/60000 Training loss: 0.034951
Epoch: 6 20000/60000 Training loss: 0.039225
Epoch: 6 30000/60000 Training loss: 0.037072
Epoch: 6 40000/60000 Training loss: 0.015497
Epoch: 6 50000/60000 Training loss: 0.020543
Training loss: 0.033871
Test loss: 0.021057; Test accuracy: 9928/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.024837
Epoch: 7 10000/60000 Training loss: 0.008186
Epoch: 7 20000/60000 Training loss: 0.009333
Epoch: 7 30000/60000 Training loss: 0.014166
Epoch: 7 40000/60000 Training loss: 0.008142
Epoch: 7 50000/60000 Training loss: 0.029874
Training loss: 0.028436
Test loss: 0.019869; Test accuracy: 9936/10000 (99.4%)

Epoch: 8 0/60000 Training loss: 0.003240
Epoch: 8 10000/60000 Training loss: 0.012755
Epoch: 8 20000/60000 Training loss: 0.013100
Epoch: 8 30000/60000 Training loss: 0.032663
Epoch: 8 40000/60000 Training loss: 0.012194
Epoch: 8 50000/60000 Training loss: 0.002639
Training loss: 0.026621
Test loss: 0.022799; Test accuracy: 9932/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.011536
Epoch: 9 10000/60000 Training loss: 0.004825
Epoch: 9 20000/60000 Training loss: 0.041729
Epoch: 9 30000/60000 Training loss: 0.019346
Epoch: 9 40000/60000 Training loss: 0.006628
Epoch: 9 50000/60000 Training loss: 0.012227
Training loss: 0.024212
Test loss: 0.020238; Test accuracy: 9935/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.001144
Epoch: 10 10000/60000 Training loss: 0.009614
Epoch: 10 20000/60000 Training loss: 0.002528
Epoch: 10 30000/60000 Training loss: 0.010880
Epoch: 10 40000/60000 Training loss: 0.030891
Epoch: 10 50000/60000 Training loss: 0.019933
Training loss: 0.022337
Test loss: 0.018252; Test accuracy: 9939/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.006536
Epoch: 11 10000/60000 Training loss: 0.000759
Epoch: 11 20000/60000 Training loss: 0.006304
Epoch: 11 30000/60000 Training loss: 0.017620
Epoch: 11 40000/60000 Training loss: 0.004225
Epoch: 11 50000/60000 Training loss: 0.021244
Training loss: 0.021187
Test loss: 0.020553; Test accuracy: 9942/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.022728
Epoch: 12 10000/60000 Training loss: 0.008562
Epoch: 12 20000/60000 Training loss: 0.006220
Epoch: 12 30000/60000 Training loss: 0.009043
Epoch: 12 40000/60000 Training loss: 0.007171
Epoch: 12 50000/60000 Training loss: 0.011865
Training loss: 0.018238
Test loss: 0.019568; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.004655
Epoch: 13 10000/60000 Training loss: 0.048230
Epoch: 13 20000/60000 Training loss: 0.013806
Epoch: 13 30000/60000 Training loss: 0.013848
Epoch: 13 40000/60000 Training loss: 0.009400
Epoch: 13 50000/60000 Training loss: 0.057179
Training loss: 0.017616
Test loss: 0.020840; Test accuracy: 9939/10000 (99.4%)

[I 2022-11-04 04:52:27,622] Trial 77 finished with value: 0.018252473324537277 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.17445397083032096, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0002932998136322034}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.1488153633141125, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.000731850052986961}
Epoch: 0 0/60000 Training loss: 2.342446
Epoch: 0 10000/60000 Training loss: 0.162770
Epoch: 0 20000/60000 Training loss: 0.090096
Epoch: 0 30000/60000 Training loss: 0.199733
Epoch: 0 40000/60000 Training loss: 0.067237
Epoch: 0 50000/60000 Training loss: 0.266555
Training loss: 0.196969
Test loss: 0.039890; Test accuracy: 9874/10000 (98.7%)

Epoch: 1 0/60000 Training loss: 0.069124
Epoch: 1 10000/60000 Training loss: 0.076411
Epoch: 1 20000/60000 Training loss: 0.052397
Epoch: 1 30000/60000 Training loss: 0.014334
Epoch: 1 40000/60000 Training loss: 0.172626
Epoch: 1 50000/60000 Training loss: 0.009647
Training loss: 0.065980
Test loss: 0.033830; Test accuracy: 9895/10000 (98.9%)

Epoch: 2 0/60000 Training loss: 0.112893
Epoch: 2 10000/60000 Training loss: 0.008130
Epoch: 2 20000/60000 Training loss: 0.016589
Epoch: 2 30000/60000 Training loss: 0.030349
Epoch: 2 40000/60000 Training loss: 0.033684
Epoch: 2 50000/60000 Training loss: 0.012416
Training loss: 0.048161
Test loss: 0.029003; Test accuracy: 9896/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.059697
Epoch: 3 10000/60000 Training loss: 0.025127
Epoch: 3 20000/60000 Training loss: 0.005801
Epoch: 3 30000/60000 Training loss: 0.001945
Epoch: 3 40000/60000 Training loss: 0.017182
Epoch: 3 50000/60000 Training loss: 0.031478
Training loss: 0.041229
Test loss: 0.024975; Test accuracy: 9919/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.051290
Epoch: 4 10000/60000 Training loss: 0.035527
Epoch: 4 20000/60000 Training loss: 0.016152
Epoch: 4 30000/60000 Training loss: 0.006190
Epoch: 4 40000/60000 Training loss: 0.095384
Epoch: 4 50000/60000 Training loss: 0.141917
Training loss: 0.035026
Test loss: 0.024256; Test accuracy: 9931/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.009207
Epoch: 5 10000/60000 Training loss: 0.069589
Epoch: 5 20000/60000 Training loss: 0.006008
Epoch: 5 30000/60000 Training loss: 0.004625
Epoch: 5 40000/60000 Training loss: 0.002813
Epoch: 5 50000/60000 Training loss: 0.005874
Training loss: 0.030629
Test loss: 0.021630; Test accuracy: 9933/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.033907
Epoch: 6 10000/60000 Training loss: 0.019038
Epoch: 6 20000/60000 Training loss: 0.013341
Epoch: 6 30000/60000 Training loss: 0.001449
Epoch: 6 40000/60000 Training loss: 0.008597
Epoch: 6 50000/60000 Training loss: 0.050970
Training loss: 0.025950
Test loss: 0.020603; Test accuracy: 9942/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.014885
Epoch: 7 10000/60000 Training loss: 0.008727
Epoch: 7 20000/60000 Training loss: 0.002875
Epoch: 7 30000/60000 Training loss: 0.010003
Epoch: 7 40000/60000 Training loss: 0.009402
Epoch: 7 50000/60000 Training loss: 0.009230
Training loss: 0.023993
Test loss: 0.023651; Test accuracy: 9929/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.008619
Epoch: 8 10000/60000 Training loss: 0.006237
Epoch: 8 20000/60000 Training loss: 0.006712
Epoch: 8 30000/60000 Training loss: 0.024469
Epoch: 8 40000/60000 Training loss: 0.005125
Epoch: 8 50000/60000 Training loss: 0.006823
Training loss: 0.021350
Test loss: 0.025501; Test accuracy: 9927/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.006758
Epoch: 9 10000/60000 Training loss: 0.011313
Epoch: 9 20000/60000 Training loss: 0.024478
Epoch: 9 30000/60000 Training loss: 0.053898
Epoch: 9 40000/60000 Training loss: 0.082455
Epoch: 9 50000/60000 Training loss: 0.008218
Training loss: 0.020035
Test loss: 0.024778; Test accuracy: 9932/10000 (99.3%)

[I 2022-11-04 04:54:53,999] Trial 78 finished with value: 0.020603349432349205 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.1488153633141125, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.000731850052986961}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.13996356811303437, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.0003250278734429335}
Epoch: 0 0/60000 Training loss: 2.338097
Epoch: 0 10000/60000 Training loss: 0.185596
Epoch: 0 20000/60000 Training loss: 0.210128
Epoch: 0 30000/60000 Training loss: 0.214700
Epoch: 0 40000/60000 Training loss: 0.142346
Epoch: 0 50000/60000 Training loss: 0.172048
Training loss: 0.254435
Test loss: 0.055872; Test accuracy: 9814/10000 (98.1%)

Epoch: 1 0/60000 Training loss: 0.043720
Epoch: 1 10000/60000 Training loss: 0.052976
Epoch: 1 20000/60000 Training loss: 0.090472
Epoch: 1 30000/60000 Training loss: 0.059104
Epoch: 1 40000/60000 Training loss: 0.065440
Epoch: 1 50000/60000 Training loss: 0.052291
Training loss: 0.082458
Test loss: 0.031420; Test accuracy: 9898/10000 (99.0%)

Epoch: 2 0/60000 Training loss: 0.071926
Epoch: 2 10000/60000 Training loss: 0.016283
Epoch: 2 20000/60000 Training loss: 0.058359
Epoch: 2 30000/60000 Training loss: 0.025808
Epoch: 2 40000/60000 Training loss: 0.071809
Epoch: 2 50000/60000 Training loss: 0.120509
Training loss: 0.057939
Test loss: 0.028480; Test accuracy: 9903/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.019854
Epoch: 3 10000/60000 Training loss: 0.023087
Epoch: 3 20000/60000 Training loss: 0.006981
Epoch: 3 30000/60000 Training loss: 0.069452
Epoch: 3 40000/60000 Training loss: 0.059809
Epoch: 3 50000/60000 Training loss: 0.015912
Training loss: 0.046970
Test loss: 0.024322; Test accuracy: 9914/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.015544
Epoch: 4 10000/60000 Training loss: 0.023408
Epoch: 4 20000/60000 Training loss: 0.074028
Epoch: 4 30000/60000 Training loss: 0.069270
Epoch: 4 40000/60000 Training loss: 0.044074
Epoch: 4 50000/60000 Training loss: 0.012759
Training loss: 0.040070
Test loss: 0.022177; Test accuracy: 9923/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.064738
Epoch: 5 10000/60000 Training loss: 0.068115
Epoch: 5 20000/60000 Training loss: 0.010544
Epoch: 5 30000/60000 Training loss: 0.042936
Epoch: 5 40000/60000 Training loss: 0.025038
Epoch: 5 50000/60000 Training loss: 0.040792
Training loss: 0.033391
Test loss: 0.021120; Test accuracy: 9934/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.055726
Epoch: 6 10000/60000 Training loss: 0.002319
Epoch: 6 20000/60000 Training loss: 0.046932
Epoch: 6 30000/60000 Training loss: 0.027963
Epoch: 6 40000/60000 Training loss: 0.062327
Epoch: 6 50000/60000 Training loss: 0.017765
Training loss: 0.030771
Test loss: 0.021200; Test accuracy: 9936/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.016638
Epoch: 7 10000/60000 Training loss: 0.031222
Epoch: 7 20000/60000 Training loss: 0.040354
Epoch: 7 30000/60000 Training loss: 0.012655
Epoch: 7 40000/60000 Training loss: 0.063286
Epoch: 7 50000/60000 Training loss: 0.015981
Training loss: 0.025236
Test loss: 0.019594; Test accuracy: 9936/10000 (99.4%)

Epoch: 8 0/60000 Training loss: 0.034213
Epoch: 8 10000/60000 Training loss: 0.028575
Epoch: 8 20000/60000 Training loss: 0.003580
Epoch: 8 30000/60000 Training loss: 0.005743
Epoch: 8 40000/60000 Training loss: 0.015511
Epoch: 8 50000/60000 Training loss: 0.023115
Training loss: 0.022467
Test loss: 0.020729; Test accuracy: 9936/10000 (99.4%)

Epoch: 9 0/60000 Training loss: 0.041941
Epoch: 9 10000/60000 Training loss: 0.005817
Epoch: 9 20000/60000 Training loss: 0.020902
Epoch: 9 30000/60000 Training loss: 0.004212
Epoch: 9 40000/60000 Training loss: 0.013973
Epoch: 9 50000/60000 Training loss: 0.011677
Training loss: 0.022172
Test loss: 0.022109; Test accuracy: 9932/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.025852
Epoch: 10 10000/60000 Training loss: 0.008478
Epoch: 10 20000/60000 Training loss: 0.003658
Epoch: 10 30000/60000 Training loss: 0.021313
Epoch: 10 40000/60000 Training loss: 0.010464
Epoch: 10 50000/60000 Training loss: 0.001440
Training loss: 0.019021
Test loss: 0.021626; Test accuracy: 9932/10000 (99.3%)

[I 2022-11-04 04:57:39,139] Trial 79 finished with value: 0.019593626260757446 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 80, 'conv2_drop': 0.13996356811303437, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.0003250278734429335}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.15654862187342133, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.0002417174279935677}
Epoch: 0 0/60000 Training loss: 2.315320
Epoch: 0 10000/60000 Training loss: 0.295287
Epoch: 0 20000/60000 Training loss: 0.175173
Epoch: 0 30000/60000 Training loss: 0.089511
Epoch: 0 40000/60000 Training loss: 0.099371
Epoch: 0 50000/60000 Training loss: 0.104275
Training loss: 0.261609
Test loss: 0.052691; Test accuracy: 9829/10000 (98.3%)

Epoch: 1 0/60000 Training loss: 0.077959
Epoch: 1 10000/60000 Training loss: 0.086555
Epoch: 1 20000/60000 Training loss: 0.095755
Epoch: 1 30000/60000 Training loss: 0.055175
Epoch: 1 40000/60000 Training loss: 0.032959
Epoch: 1 50000/60000 Training loss: 0.162716
Training loss: 0.078833
Test loss: 0.037676; Test accuracy: 9878/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.025518
Epoch: 2 10000/60000 Training loss: 0.046443
Epoch: 2 20000/60000 Training loss: 0.019134
Epoch: 2 30000/60000 Training loss: 0.053470
Epoch: 2 40000/60000 Training loss: 0.038564
Epoch: 2 50000/60000 Training loss: 0.125641
Training loss: 0.057282
Test loss: 0.026377; Test accuracy: 9915/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.187210
Epoch: 3 10000/60000 Training loss: 0.093559
Epoch: 3 20000/60000 Training loss: 0.014542
Epoch: 3 30000/60000 Training loss: 0.037412
Epoch: 3 40000/60000 Training loss: 0.029575
Epoch: 3 50000/60000 Training loss: 0.040532
Training loss: 0.046682
Test loss: 0.026836; Test accuracy: 9911/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.054097
Epoch: 4 10000/60000 Training loss: 0.013356
Epoch: 4 20000/60000 Training loss: 0.019542
Epoch: 4 30000/60000 Training loss: 0.003258
Epoch: 4 40000/60000 Training loss: 0.015677
Epoch: 4 50000/60000 Training loss: 0.010546
Training loss: 0.038073
Test loss: 0.022845; Test accuracy: 9917/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.020822
Epoch: 5 10000/60000 Training loss: 0.019566
Epoch: 5 20000/60000 Training loss: 0.050749
Epoch: 5 30000/60000 Training loss: 0.019280
Epoch: 5 40000/60000 Training loss: 0.025471
Epoch: 5 50000/60000 Training loss: 0.040954
Training loss: 0.032174
Test loss: 0.020035; Test accuracy: 9922/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.037241
Epoch: 6 10000/60000 Training loss: 0.080663
Epoch: 6 20000/60000 Training loss: 0.078404
Epoch: 6 30000/60000 Training loss: 0.057348
Epoch: 6 40000/60000 Training loss: 0.011628
Epoch: 6 50000/60000 Training loss: 0.036618
Training loss: 0.028854
Test loss: 0.021453; Test accuracy: 9930/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.001941
Epoch: 7 10000/60000 Training loss: 0.016592
Epoch: 7 20000/60000 Training loss: 0.015665
Epoch: 7 30000/60000 Training loss: 0.016178
Epoch: 7 40000/60000 Training loss: 0.003558
Epoch: 7 50000/60000 Training loss: 0.084122
Training loss: 0.024432
Test loss: 0.023803; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.015366
Epoch: 8 10000/60000 Training loss: 0.019291
Epoch: 8 20000/60000 Training loss: 0.006498
Epoch: 8 30000/60000 Training loss: 0.037646
Epoch: 8 40000/60000 Training loss: 0.001855
Epoch: 8 50000/60000 Training loss: 0.012911
Training loss: 0.020983
Test loss: 0.019102; Test accuracy: 9935/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.030147
Epoch: 9 10000/60000 Training loss: 0.005359
Epoch: 9 20000/60000 Training loss: 0.003444
Epoch: 9 30000/60000 Training loss: 0.000939
Epoch: 9 40000/60000 Training loss: 0.022152
Epoch: 9 50000/60000 Training loss: 0.010619
Training loss: 0.020431
Test loss: 0.019070; Test accuracy: 9943/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.069479
Epoch: 10 10000/60000 Training loss: 0.008450
Epoch: 10 20000/60000 Training loss: 0.004556
Epoch: 10 30000/60000 Training loss: 0.002294
Epoch: 10 40000/60000 Training loss: 0.045914
Epoch: 10 50000/60000 Training loss: 0.007893
Training loss: 0.017926
Test loss: 0.019311; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.016263
Epoch: 11 10000/60000 Training loss: 0.001129
Epoch: 11 20000/60000 Training loss: 0.018535
Epoch: 11 30000/60000 Training loss: 0.022740
Epoch: 11 40000/60000 Training loss: 0.048252
Epoch: 11 50000/60000 Training loss: 0.000488
Training loss: 0.017091
Test loss: 0.019418; Test accuracy: 9935/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.029086
Epoch: 12 10000/60000 Training loss: 0.030795
Epoch: 12 20000/60000 Training loss: 0.101762
Epoch: 12 30000/60000 Training loss: 0.002693
Epoch: 12 40000/60000 Training loss: 0.014749
Epoch: 12 50000/60000 Training loss: 0.005860
Training loss: 0.014169
Test loss: 0.020924; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 05:00:47,622] Trial 80 finished with value: 0.019070489332079887 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 96, 'conv2_drop': 0.15654862187342133, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.0002417174279935677}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.16160721627763613, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0004227251028957367}
Epoch: 0 0/60000 Training loss: 2.286341
Epoch: 0 10000/60000 Training loss: 0.290255
Epoch: 0 20000/60000 Training loss: 0.240488
Epoch: 0 30000/60000 Training loss: 0.096869
Epoch: 0 40000/60000 Training loss: 0.105845
Epoch: 0 50000/60000 Training loss: 0.106595
Training loss: 0.234632
Test loss: 0.042529; Test accuracy: 9861/10000 (98.6%)

Epoch: 1 0/60000 Training loss: 0.162468
Epoch: 1 10000/60000 Training loss: 0.042460
Epoch: 1 20000/60000 Training loss: 0.036872
Epoch: 1 30000/60000 Training loss: 0.045572
Epoch: 1 40000/60000 Training loss: 0.044531
Epoch: 1 50000/60000 Training loss: 0.079437
Training loss: 0.074051
Test loss: 0.034214; Test accuracy: 9893/10000 (98.9%)

Epoch: 2 0/60000 Training loss: 0.018476
Epoch: 2 10000/60000 Training loss: 0.070864
Epoch: 2 20000/60000 Training loss: 0.057667
Epoch: 2 30000/60000 Training loss: 0.025319
Epoch: 2 40000/60000 Training loss: 0.089196
Epoch: 2 50000/60000 Training loss: 0.014733
Training loss: 0.052777
Test loss: 0.028601; Test accuracy: 9903/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.028727
Epoch: 3 10000/60000 Training loss: 0.082202
Epoch: 3 20000/60000 Training loss: 0.043321
Epoch: 3 30000/60000 Training loss: 0.037469
Epoch: 3 40000/60000 Training loss: 0.024010
Epoch: 3 50000/60000 Training loss: 0.041457
Training loss: 0.043072
Test loss: 0.025308; Test accuracy: 9920/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.120957
Epoch: 4 10000/60000 Training loss: 0.005446
Epoch: 4 20000/60000 Training loss: 0.032462
Epoch: 4 30000/60000 Training loss: 0.006992
Epoch: 4 40000/60000 Training loss: 0.024759
Epoch: 4 50000/60000 Training loss: 0.025233
Training loss: 0.036738
Test loss: 0.022139; Test accuracy: 9927/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.005329
Epoch: 5 10000/60000 Training loss: 0.025821
Epoch: 5 20000/60000 Training loss: 0.109008
Epoch: 5 30000/60000 Training loss: 0.008972
Epoch: 5 40000/60000 Training loss: 0.020140
Epoch: 5 50000/60000 Training loss: 0.005918
Training loss: 0.030433
Test loss: 0.019385; Test accuracy: 9932/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.010218
Epoch: 6 10000/60000 Training loss: 0.012557
Epoch: 6 20000/60000 Training loss: 0.016250
Epoch: 6 30000/60000 Training loss: 0.031907
Epoch: 6 40000/60000 Training loss: 0.010723
Epoch: 6 50000/60000 Training loss: 0.011774
Training loss: 0.026500
Test loss: 0.020683; Test accuracy: 9931/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.031403
Epoch: 7 10000/60000 Training loss: 0.085758
Epoch: 7 20000/60000 Training loss: 0.017897
Epoch: 7 30000/60000 Training loss: 0.009541
Epoch: 7 40000/60000 Training loss: 0.015178
Epoch: 7 50000/60000 Training loss: 0.001074
Training loss: 0.023504
Test loss: 0.022390; Test accuracy: 9930/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.004228
Epoch: 8 10000/60000 Training loss: 0.021030
Epoch: 8 20000/60000 Training loss: 0.016724
Epoch: 8 30000/60000 Training loss: 0.010482
Epoch: 8 40000/60000 Training loss: 0.013002
Epoch: 8 50000/60000 Training loss: 0.004050
Training loss: 0.021308
Test loss: 0.020188; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 05:02:53,898] Trial 81 finished with value: 0.019384846091270447 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.16160721627763613, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0004227251028957367}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.15114905854905014, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00034510239680282965}
Epoch: 0 0/60000 Training loss: 2.306057
Epoch: 0 10000/60000 Training loss: 0.262556
Epoch: 0 20000/60000 Training loss: 0.114340
Epoch: 0 30000/60000 Training loss: 0.104752
Epoch: 0 40000/60000 Training loss: 0.120191
Epoch: 0 50000/60000 Training loss: 0.138197
Training loss: 0.233262
Test loss: 0.047042; Test accuracy: 9847/10000 (98.5%)

Epoch: 1 0/60000 Training loss: 0.080627
Epoch: 1 10000/60000 Training loss: 0.024570
Epoch: 1 20000/60000 Training loss: 0.087064
Epoch: 1 30000/60000 Training loss: 0.105297
Epoch: 1 40000/60000 Training loss: 0.040896
Epoch: 1 50000/60000 Training loss: 0.055919
Training loss: 0.073352
Test loss: 0.030339; Test accuracy: 9893/10000 (98.9%)

Epoch: 2 0/60000 Training loss: 0.104225
Epoch: 2 10000/60000 Training loss: 0.082924
Epoch: 2 20000/60000 Training loss: 0.013564
Epoch: 2 30000/60000 Training loss: 0.060601
Epoch: 2 40000/60000 Training loss: 0.020681
Epoch: 2 50000/60000 Training loss: 0.031164
Training loss: 0.053337
Test loss: 0.027623; Test accuracy: 9911/10000 (99.1%)

Epoch: 3 0/60000 Training loss: 0.006543
Epoch: 3 10000/60000 Training loss: 0.004012
Epoch: 3 20000/60000 Training loss: 0.041421
Epoch: 3 30000/60000 Training loss: 0.022568
Epoch: 3 40000/60000 Training loss: 0.012115
Epoch: 3 50000/60000 Training loss: 0.090422
Training loss: 0.041007
Test loss: 0.024204; Test accuracy: 9926/10000 (99.3%)

Epoch: 4 0/60000 Training loss: 0.013734
Epoch: 4 10000/60000 Training loss: 0.054282
Epoch: 4 20000/60000 Training loss: 0.053254
Epoch: 4 30000/60000 Training loss: 0.067256
Epoch: 4 40000/60000 Training loss: 0.005771
Epoch: 4 50000/60000 Training loss: 0.020971
Training loss: 0.034691
Test loss: 0.022745; Test accuracy: 9924/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.021114
Epoch: 5 10000/60000 Training loss: 0.008239
Epoch: 5 20000/60000 Training loss: 0.030249
Epoch: 5 30000/60000 Training loss: 0.011566
Epoch: 5 40000/60000 Training loss: 0.081295
Epoch: 5 50000/60000 Training loss: 0.037601
Training loss: 0.028204
Test loss: 0.021693; Test accuracy: 9924/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.006815
Epoch: 6 10000/60000 Training loss: 0.027395
Epoch: 6 20000/60000 Training loss: 0.004058
Epoch: 6 30000/60000 Training loss: 0.058980
Epoch: 6 40000/60000 Training loss: 0.025081
Epoch: 6 50000/60000 Training loss: 0.044730
Training loss: 0.027628
Test loss: 0.020455; Test accuracy: 9934/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.007377
Epoch: 7 10000/60000 Training loss: 0.020380
Epoch: 7 20000/60000 Training loss: 0.007975
Epoch: 7 30000/60000 Training loss: 0.005661
Epoch: 7 40000/60000 Training loss: 0.018697
Epoch: 7 50000/60000 Training loss: 0.012827
Training loss: 0.023022
Test loss: 0.018834; Test accuracy: 9944/10000 (99.4%)

Epoch: 8 0/60000 Training loss: 0.056382
Epoch: 8 10000/60000 Training loss: 0.004838
Epoch: 8 20000/60000 Training loss: 0.002486
Epoch: 8 30000/60000 Training loss: 0.019643
Epoch: 8 40000/60000 Training loss: 0.010027
Epoch: 8 50000/60000 Training loss: 0.060795
Training loss: 0.019582
Test loss: 0.019320; Test accuracy: 9931/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.012449
Epoch: 9 10000/60000 Training loss: 0.024173
Epoch: 9 20000/60000 Training loss: 0.026375
Epoch: 9 30000/60000 Training loss: 0.009215
Epoch: 9 40000/60000 Training loss: 0.031817
Epoch: 9 50000/60000 Training loss: 0.003721
Training loss: 0.017884
Test loss: 0.027477; Test accuracy: 9923/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.018014
Epoch: 10 10000/60000 Training loss: 0.001087
Epoch: 10 20000/60000 Training loss: 0.018539
Epoch: 10 30000/60000 Training loss: 0.018124
Epoch: 10 40000/60000 Training loss: 0.005521
Epoch: 10 50000/60000 Training loss: 0.018110
Training loss: 0.016765
Test loss: 0.018837; Test accuracy: 9937/10000 (99.4%)

[I 2022-11-04 05:05:28,120] Trial 82 finished with value: 0.01883382350206375 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.15114905854905014, 'fc1_neurons': 190, 'optimizer': 'Adam', 'learning_rate': 0.00034510239680282965}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.17058735718969462, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00019186738682131657}
Epoch: 0 0/60000 Training loss: 2.316783
Epoch: 0 10000/60000 Training loss: 0.400092
Epoch: 0 20000/60000 Training loss: 0.319014
Epoch: 0 30000/60000 Training loss: 0.093855
Epoch: 0 40000/60000 Training loss: 0.158693
Epoch: 0 50000/60000 Training loss: 0.177423
Training loss: 0.326219
Test loss: 0.069040; Test accuracy: 9771/10000 (97.7%)

Epoch: 1 0/60000 Training loss: 0.160837
Epoch: 1 10000/60000 Training loss: 0.074872
Epoch: 1 20000/60000 Training loss: 0.037977
Epoch: 1 30000/60000 Training loss: 0.043886
Epoch: 1 40000/60000 Training loss: 0.072491
Epoch: 1 50000/60000 Training loss: 0.075487
Training loss: 0.100575
Test loss: 0.042220; Test accuracy: 9861/10000 (98.6%)

Epoch: 2 0/60000 Training loss: 0.079956
Epoch: 2 10000/60000 Training loss: 0.043433
Epoch: 2 20000/60000 Training loss: 0.166339
Epoch: 2 30000/60000 Training loss: 0.220195
Epoch: 2 40000/60000 Training loss: 0.069801
Epoch: 2 50000/60000 Training loss: 0.010245
Training loss: 0.069048
Test loss: 0.032029; Test accuracy: 9890/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.041578
Epoch: 3 10000/60000 Training loss: 0.042764
Epoch: 3 20000/60000 Training loss: 0.146692
Epoch: 3 30000/60000 Training loss: 0.031715
Epoch: 3 40000/60000 Training loss: 0.042479
Epoch: 3 50000/60000 Training loss: 0.097488
Training loss: 0.054578
Test loss: 0.026425; Test accuracy: 9906/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.053141
Epoch: 4 10000/60000 Training loss: 0.102904
Epoch: 4 20000/60000 Training loss: 0.093278
Epoch: 4 30000/60000 Training loss: 0.057338
Epoch: 4 40000/60000 Training loss: 0.107328
Epoch: 4 50000/60000 Training loss: 0.010915
Training loss: 0.046044
Test loss: 0.025684; Test accuracy: 9907/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.011923
Epoch: 5 10000/60000 Training loss: 0.005129
Epoch: 5 20000/60000 Training loss: 0.046702
Epoch: 5 30000/60000 Training loss: 0.026652
Epoch: 5 40000/60000 Training loss: 0.018122
Epoch: 5 50000/60000 Training loss: 0.006797
Training loss: 0.040160
Test loss: 0.024883; Test accuracy: 9916/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.027296
Epoch: 6 10000/60000 Training loss: 0.010893
Epoch: 6 20000/60000 Training loss: 0.048569
Epoch: 6 30000/60000 Training loss: 0.005341
Epoch: 6 40000/60000 Training loss: 0.064776
Epoch: 6 50000/60000 Training loss: 0.045777
Training loss: 0.035444
Test loss: 0.021092; Test accuracy: 9929/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.010445
Epoch: 7 10000/60000 Training loss: 0.001738
Epoch: 7 20000/60000 Training loss: 0.002699
Epoch: 7 30000/60000 Training loss: 0.018281
Epoch: 7 40000/60000 Training loss: 0.013882
Epoch: 7 50000/60000 Training loss: 0.003832
Training loss: 0.030966
Test loss: 0.021663; Test accuracy: 9919/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.015406
Epoch: 8 10000/60000 Training loss: 0.017856
Epoch: 8 20000/60000 Training loss: 0.011273
Epoch: 8 30000/60000 Training loss: 0.009433
Epoch: 8 40000/60000 Training loss: 0.013177
Epoch: 8 50000/60000 Training loss: 0.033077
Training loss: 0.027105
Test loss: 0.020844; Test accuracy: 9928/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.003147
Epoch: 9 10000/60000 Training loss: 0.024487
Epoch: 9 20000/60000 Training loss: 0.004496
Epoch: 9 30000/60000 Training loss: 0.006600
Epoch: 9 40000/60000 Training loss: 0.005070
Epoch: 9 50000/60000 Training loss: 0.012454
Training loss: 0.025385
Test loss: 0.020471; Test accuracy: 9937/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.004717
Epoch: 10 10000/60000 Training loss: 0.010974
Epoch: 10 20000/60000 Training loss: 0.011087
Epoch: 10 30000/60000 Training loss: 0.037513
Epoch: 10 40000/60000 Training loss: 0.001140
Epoch: 10 50000/60000 Training loss: 0.020684
Training loss: 0.022755
Test loss: 0.018057; Test accuracy: 9941/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.011492
Epoch: 11 10000/60000 Training loss: 0.022618
Epoch: 11 20000/60000 Training loss: 0.001758
Epoch: 11 30000/60000 Training loss: 0.004810
Epoch: 11 40000/60000 Training loss: 0.005129
Epoch: 11 50000/60000 Training loss: 0.001138
Training loss: 0.020778
Test loss: 0.018811; Test accuracy: 9944/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.009595
Epoch: 12 10000/60000 Training loss: 0.036284
Epoch: 12 20000/60000 Training loss: 0.090889
Epoch: 12 30000/60000 Training loss: 0.006279
Epoch: 12 40000/60000 Training loss: 0.005542
Epoch: 12 50000/60000 Training loss: 0.005218
Training loss: 0.019103
Test loss: 0.019313; Test accuracy: 9940/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.063320
Epoch: 13 10000/60000 Training loss: 0.003256
Epoch: 13 20000/60000 Training loss: 0.002968
Epoch: 13 30000/60000 Training loss: 0.003547
Epoch: 13 40000/60000 Training loss: 0.016098
Epoch: 13 50000/60000 Training loss: 0.002172
Training loss: 0.018376
Test loss: 0.018604; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 05:08:43,801] Trial 83 finished with value: 0.018057292327284813 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.17058735718969462, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00019186738682131657}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.1438482603073212, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.00023095560207427954}
Epoch: 0 0/60000 Training loss: 2.268421
Epoch: 0 10000/60000 Training loss: 0.306613
Epoch: 0 20000/60000 Training loss: 0.172674
Epoch: 0 30000/60000 Training loss: 0.099460
Epoch: 0 40000/60000 Training loss: 0.183622
Epoch: 0 50000/60000 Training loss: 0.080061
Training loss: 0.320354
Test loss: 0.066104; Test accuracy: 9794/10000 (97.9%)

Epoch: 1 0/60000 Training loss: 0.031338
Epoch: 1 10000/60000 Training loss: 0.139262
Epoch: 1 20000/60000 Training loss: 0.083688
Epoch: 1 30000/60000 Training loss: 0.077342
Epoch: 1 40000/60000 Training loss: 0.086754
Epoch: 1 50000/60000 Training loss: 0.056355
Training loss: 0.097897
Test loss: 0.040236; Test accuracy: 9876/10000 (98.8%)

Epoch: 2 0/60000 Training loss: 0.073419
Epoch: 2 10000/60000 Training loss: 0.055481
Epoch: 2 20000/60000 Training loss: 0.048139
Epoch: 2 30000/60000 Training loss: 0.142520
Epoch: 2 40000/60000 Training loss: 0.090653
Epoch: 2 50000/60000 Training loss: 0.084510
Training loss: 0.069049
Test loss: 0.032341; Test accuracy: 9896/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.087293
Epoch: 3 10000/60000 Training loss: 0.053579
Epoch: 3 20000/60000 Training loss: 0.016842
Epoch: 3 30000/60000 Training loss: 0.053279
Epoch: 3 40000/60000 Training loss: 0.030913
Epoch: 3 50000/60000 Training loss: 0.150413
Training loss: 0.055946
Test loss: 0.028420; Test accuracy: 9908/10000 (99.1%)

Epoch: 4 0/60000 Training loss: 0.062614
Epoch: 4 10000/60000 Training loss: 0.060272
Epoch: 4 20000/60000 Training loss: 0.033743
Epoch: 4 30000/60000 Training loss: 0.002856
Epoch: 4 40000/60000 Training loss: 0.011840
Epoch: 4 50000/60000 Training loss: 0.029253
Training loss: 0.046646
Test loss: 0.025263; Test accuracy: 9917/10000 (99.2%)

Epoch: 5 0/60000 Training loss: 0.027737
Epoch: 5 10000/60000 Training loss: 0.079674
Epoch: 5 20000/60000 Training loss: 0.011081
Epoch: 5 30000/60000 Training loss: 0.029346
Epoch: 5 40000/60000 Training loss: 0.099634
Epoch: 5 50000/60000 Training loss: 0.043123
Training loss: 0.040172
Test loss: 0.026424; Test accuracy: 9919/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.061807
Epoch: 6 10000/60000 Training loss: 0.018467
Epoch: 6 20000/60000 Training loss: 0.073778
Epoch: 6 30000/60000 Training loss: 0.028238
Epoch: 6 40000/60000 Training loss: 0.142055
Epoch: 6 50000/60000 Training loss: 0.011521
Training loss: 0.035962
Test loss: 0.022638; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.038542
Epoch: 7 10000/60000 Training loss: 0.026924
Epoch: 7 20000/60000 Training loss: 0.048002
Epoch: 7 30000/60000 Training loss: 0.004311
Epoch: 7 40000/60000 Training loss: 0.017410
Epoch: 7 50000/60000 Training loss: 0.010778
Training loss: 0.031116
Test loss: 0.020412; Test accuracy: 9935/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.015565
Epoch: 8 10000/60000 Training loss: 0.008943
Epoch: 8 20000/60000 Training loss: 0.009671
Epoch: 8 30000/60000 Training loss: 0.026640
Epoch: 8 40000/60000 Training loss: 0.029825
Epoch: 8 50000/60000 Training loss: 0.054579
Training loss: 0.028019
Test loss: 0.020884; Test accuracy: 9928/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.005474
Epoch: 9 10000/60000 Training loss: 0.002046
Epoch: 9 20000/60000 Training loss: 0.000610
Epoch: 9 30000/60000 Training loss: 0.013788
Epoch: 9 40000/60000 Training loss: 0.029575
Epoch: 9 50000/60000 Training loss: 0.007253
Training loss: 0.025113
Test loss: 0.019871; Test accuracy: 9933/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.005764
Epoch: 10 10000/60000 Training loss: 0.006765
Epoch: 10 20000/60000 Training loss: 0.000896
Epoch: 10 30000/60000 Training loss: 0.016901
Epoch: 10 40000/60000 Training loss: 0.015542
Epoch: 10 50000/60000 Training loss: 0.006142
Training loss: 0.025043
Test loss: 0.022386; Test accuracy: 9928/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.010333
Epoch: 11 10000/60000 Training loss: 0.015311
Epoch: 11 20000/60000 Training loss: 0.054644
Epoch: 11 30000/60000 Training loss: 0.033412
Epoch: 11 40000/60000 Training loss: 0.016299
Epoch: 11 50000/60000 Training loss: 0.038285
Training loss: 0.021722
Test loss: 0.020103; Test accuracy: 9934/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.004533
Epoch: 12 10000/60000 Training loss: 0.019861
Epoch: 12 20000/60000 Training loss: 0.048843
Epoch: 12 30000/60000 Training loss: 0.003205
Epoch: 12 40000/60000 Training loss: 0.015957
Epoch: 12 50000/60000 Training loss: 0.017342
Training loss: 0.019842
Test loss: 0.019515; Test accuracy: 9936/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.044678
Epoch: 13 10000/60000 Training loss: 0.015910
Epoch: 13 20000/60000 Training loss: 0.012264
Epoch: 13 30000/60000 Training loss: 0.025045
Epoch: 13 40000/60000 Training loss: 0.007970
Epoch: 13 50000/60000 Training loss: 0.004988
Training loss: 0.017687
Test loss: 0.019396; Test accuracy: 9933/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.005549
Epoch: 14 10000/60000 Training loss: 0.017451
Epoch: 14 20000/60000 Training loss: 0.003223
Epoch: 14 30000/60000 Training loss: 0.003862
Epoch: 14 40000/60000 Training loss: 0.009813
Epoch: 14 50000/60000 Training loss: 0.027745
Training loss: 0.016385
Test loss: 0.018725; Test accuracy: 9940/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.063841
Epoch: 15 10000/60000 Training loss: 0.002454
Epoch: 15 20000/60000 Training loss: 0.039950
Epoch: 15 30000/60000 Training loss: 0.083693
Epoch: 15 40000/60000 Training loss: 0.002059
Epoch: 15 50000/60000 Training loss: 0.040807
Training loss: 0.015340
Test loss: 0.020743; Test accuracy: 9937/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.004644
Epoch: 16 10000/60000 Training loss: 0.008385
Epoch: 16 20000/60000 Training loss: 0.003394
Epoch: 16 30000/60000 Training loss: 0.007929
Epoch: 16 40000/60000 Training loss: 0.028547
Epoch: 16 50000/60000 Training loss: 0.001524
Training loss: 0.013609
Test loss: 0.018331; Test accuracy: 9946/10000 (99.5%)

Epoch: 17 0/60000 Training loss: 0.014188
Epoch: 17 10000/60000 Training loss: 0.002911
Epoch: 17 20000/60000 Training loss: 0.011151
Epoch: 17 30000/60000 Training loss: 0.010468
Epoch: 17 40000/60000 Training loss: 0.008392
Epoch: 17 50000/60000 Training loss: 0.023200
Training loss: 0.014031
Test loss: 0.018248; Test accuracy: 9951/10000 (99.5%)

Epoch: 18 0/60000 Training loss: 0.018795
Epoch: 18 10000/60000 Training loss: 0.001805
Epoch: 18 20000/60000 Training loss: 0.006906
Epoch: 18 30000/60000 Training loss: 0.058070
Epoch: 18 40000/60000 Training loss: 0.011759
Epoch: 18 50000/60000 Training loss: 0.007117
Training loss: 0.012822
Test loss: 0.020653; Test accuracy: 9939/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.007765
Epoch: 19 10000/60000 Training loss: 0.001907
Epoch: 19 20000/60000 Training loss: 0.018794
Epoch: 19 30000/60000 Training loss: 0.016836
Epoch: 19 40000/60000 Training loss: 0.000834
Epoch: 19 50000/60000 Training loss: 0.005188
Training loss: 0.012256
Test loss: 0.021651; Test accuracy: 9941/10000 (99.4%)

[I 2022-11-04 05:13:24,164] Trial 84 finished with value: 0.01824786886572838 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 64, 'conv2_drop': 0.1438482603073212, 'fc1_neurons': 180, 'optimizer': 'Adam', 'learning_rate': 0.00023095560207427954}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.17704662248119024, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0001609423975615451}
Epoch: 0 0/60000 Training loss: 2.311207
Epoch: 0 10000/60000 Training loss: 0.236011
Epoch: 0 20000/60000 Training loss: 0.269042
Epoch: 0 30000/60000 Training loss: 0.204368
Epoch: 0 40000/60000 Training loss: 0.250812
Epoch: 0 50000/60000 Training loss: 0.140537
Training loss: 0.319902
Test loss: 0.068650; Test accuracy: 9780/10000 (97.8%)

Epoch: 1 0/60000 Training loss: 0.119204
Epoch: 1 10000/60000 Training loss: 0.127546
Epoch: 1 20000/60000 Training loss: 0.069440
Epoch: 1 30000/60000 Training loss: 0.113667
Epoch: 1 40000/60000 Training loss: 0.052698
Epoch: 1 50000/60000 Training loss: 0.055518
Training loss: 0.095647
Test loss: 0.043325; Test accuracy: 9867/10000 (98.7%)

Epoch: 2 0/60000 Training loss: 0.029170
Epoch: 2 10000/60000 Training loss: 0.081384
Epoch: 2 20000/60000 Training loss: 0.071725
Epoch: 2 30000/60000 Training loss: 0.080775
Epoch: 2 40000/60000 Training loss: 0.039823
Epoch: 2 50000/60000 Training loss: 0.041007
Training loss: 0.067587
Test loss: 0.033959; Test accuracy: 9892/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.024496
Epoch: 3 10000/60000 Training loss: 0.008818
Epoch: 3 20000/60000 Training loss: 0.081858
Epoch: 3 30000/60000 Training loss: 0.027285
Epoch: 3 40000/60000 Training loss: 0.077173
Epoch: 3 50000/60000 Training loss: 0.029744
Training loss: 0.055097
Test loss: 0.029741; Test accuracy: 9895/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.074793
Epoch: 4 10000/60000 Training loss: 0.033660
Epoch: 4 20000/60000 Training loss: 0.055662
Epoch: 4 30000/60000 Training loss: 0.039318
Epoch: 4 40000/60000 Training loss: 0.106698
Epoch: 4 50000/60000 Training loss: 0.074167
Training loss: 0.045754
Test loss: 0.025376; Test accuracy: 9909/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.015702
Epoch: 5 10000/60000 Training loss: 0.057562
Epoch: 5 20000/60000 Training loss: 0.033175
Epoch: 5 30000/60000 Training loss: 0.018557
Epoch: 5 40000/60000 Training loss: 0.016866
Epoch: 5 50000/60000 Training loss: 0.015663
Training loss: 0.038853
Test loss: 0.022912; Test accuracy: 9920/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.042152
Epoch: 6 10000/60000 Training loss: 0.017082
Epoch: 6 20000/60000 Training loss: 0.035714
Epoch: 6 30000/60000 Training loss: 0.024330
Epoch: 6 40000/60000 Training loss: 0.027085
Epoch: 6 50000/60000 Training loss: 0.050878
Training loss: 0.034004
Test loss: 0.022574; Test accuracy: 9926/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.008628
Epoch: 7 10000/60000 Training loss: 0.033305
Epoch: 7 20000/60000 Training loss: 0.085956
Epoch: 7 30000/60000 Training loss: 0.165139
Epoch: 7 40000/60000 Training loss: 0.021904
Epoch: 7 50000/60000 Training loss: 0.049945
Training loss: 0.030303
Test loss: 0.020333; Test accuracy: 9937/10000 (99.4%)

Epoch: 8 0/60000 Training loss: 0.015970
Epoch: 8 10000/60000 Training loss: 0.068636
Epoch: 8 20000/60000 Training loss: 0.019993
Epoch: 8 30000/60000 Training loss: 0.044593
Epoch: 8 40000/60000 Training loss: 0.006403
Epoch: 8 50000/60000 Training loss: 0.020669
Training loss: 0.027969
Test loss: 0.019681; Test accuracy: 9935/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.028068
Epoch: 9 10000/60000 Training loss: 0.029111
Epoch: 9 20000/60000 Training loss: 0.015722
Epoch: 9 30000/60000 Training loss: 0.002079
Epoch: 9 40000/60000 Training loss: 0.068715
Epoch: 9 50000/60000 Training loss: 0.004917
Training loss: 0.024827
Test loss: 0.018272; Test accuracy: 9934/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.028173
Epoch: 10 10000/60000 Training loss: 0.019958
Epoch: 10 20000/60000 Training loss: 0.046530
Epoch: 10 30000/60000 Training loss: 0.003911
Epoch: 10 40000/60000 Training loss: 0.046303
Epoch: 10 50000/60000 Training loss: 0.004732
Training loss: 0.022510
Test loss: 0.018309; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.005343
Epoch: 11 10000/60000 Training loss: 0.019540
Epoch: 11 20000/60000 Training loss: 0.029389
Epoch: 11 30000/60000 Training loss: 0.018807
Epoch: 11 40000/60000 Training loss: 0.004878
Epoch: 11 50000/60000 Training loss: 0.004614
Training loss: 0.019845
Test loss: 0.017858; Test accuracy: 9933/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.018599
Epoch: 12 10000/60000 Training loss: 0.014126
Epoch: 12 20000/60000 Training loss: 0.014283
Epoch: 12 30000/60000 Training loss: 0.032433
Epoch: 12 40000/60000 Training loss: 0.006425
Epoch: 12 50000/60000 Training loss: 0.028791
Training loss: 0.017839
Test loss: 0.019315; Test accuracy: 9937/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.056475
Epoch: 13 10000/60000 Training loss: 0.001332
Epoch: 13 20000/60000 Training loss: 0.001962
Epoch: 13 30000/60000 Training loss: 0.010542
Epoch: 13 40000/60000 Training loss: 0.001471
Epoch: 13 50000/60000 Training loss: 0.036601
Training loss: 0.017303
Test loss: 0.017803; Test accuracy: 9937/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.028057
Epoch: 14 10000/60000 Training loss: 0.001770
Epoch: 14 20000/60000 Training loss: 0.000926
Epoch: 14 30000/60000 Training loss: 0.028508
Epoch: 14 40000/60000 Training loss: 0.004766
Epoch: 14 50000/60000 Training loss: 0.008255
Training loss: 0.014402
Test loss: 0.018970; Test accuracy: 9934/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.009865
Epoch: 15 10000/60000 Training loss: 0.008074
Epoch: 15 20000/60000 Training loss: 0.000577
Epoch: 15 30000/60000 Training loss: 0.018378
Epoch: 15 40000/60000 Training loss: 0.003628
Epoch: 15 50000/60000 Training loss: 0.018113
Training loss: 0.014166
Test loss: 0.018966; Test accuracy: 9940/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.002151
Epoch: 16 10000/60000 Training loss: 0.022714
Epoch: 16 20000/60000 Training loss: 0.025280
Epoch: 16 30000/60000 Training loss: 0.006039
Epoch: 16 40000/60000 Training loss: 0.001523
Epoch: 16 50000/60000 Training loss: 0.002486
Training loss: 0.012854
Test loss: 0.021186; Test accuracy: 9935/10000 (99.3%)

[I 2022-11-04 05:17:21,943] Trial 85 finished with value: 0.017803024500608444 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.17704662248119024, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 0.0001609423975615451}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.19991555667957706, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 8.948877592517693e-05}
Epoch: 0 0/60000 Training loss: 2.307950
Epoch: 0 10000/60000 Training loss: 0.574900
Epoch: 0 20000/60000 Training loss: 0.336912
Epoch: 0 30000/60000 Training loss: 0.274265
Epoch: 0 40000/60000 Training loss: 0.189866
Epoch: 0 50000/60000 Training loss: 0.214740
Training loss: 0.436516
Test loss: 0.095847; Test accuracy: 9725/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.155116
Epoch: 1 10000/60000 Training loss: 0.225109
Epoch: 1 20000/60000 Training loss: 0.240418
Epoch: 1 30000/60000 Training loss: 0.111986
Epoch: 1 40000/60000 Training loss: 0.055612
Epoch: 1 50000/60000 Training loss: 0.084901
Training loss: 0.124894
Test loss: 0.054007; Test accuracy: 9822/10000 (98.2%)

Epoch: 2 0/60000 Training loss: 0.112483
Epoch: 2 10000/60000 Training loss: 0.017982
Epoch: 2 20000/60000 Training loss: 0.093205
Epoch: 2 30000/60000 Training loss: 0.061257
Epoch: 2 40000/60000 Training loss: 0.096697
Epoch: 2 50000/60000 Training loss: 0.050567
Training loss: 0.089397
Test loss: 0.040298; Test accuracy: 9875/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.104538
Epoch: 3 10000/60000 Training loss: 0.147895
Epoch: 3 20000/60000 Training loss: 0.034280
Epoch: 3 30000/60000 Training loss: 0.094050
Epoch: 3 40000/60000 Training loss: 0.041308
Epoch: 3 50000/60000 Training loss: 0.083444
Training loss: 0.071624
Test loss: 0.035007; Test accuracy: 9890/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.062764
Epoch: 4 10000/60000 Training loss: 0.039650
Epoch: 4 20000/60000 Training loss: 0.053566
Epoch: 4 30000/60000 Training loss: 0.053811
Epoch: 4 40000/60000 Training loss: 0.053847
Epoch: 4 50000/60000 Training loss: 0.011913
Training loss: 0.058362
Test loss: 0.031178; Test accuracy: 9903/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.083403
Epoch: 5 10000/60000 Training loss: 0.081684
Epoch: 5 20000/60000 Training loss: 0.107548
Epoch: 5 30000/60000 Training loss: 0.016884
Epoch: 5 40000/60000 Training loss: 0.032889
Epoch: 5 50000/60000 Training loss: 0.017567
Training loss: 0.052814
Test loss: 0.027566; Test accuracy: 9907/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.065164
Epoch: 6 10000/60000 Training loss: 0.020861
Epoch: 6 20000/60000 Training loss: 0.060707
Epoch: 6 30000/60000 Training loss: 0.019728
Epoch: 6 40000/60000 Training loss: 0.017247
Epoch: 6 50000/60000 Training loss: 0.039338
Training loss: 0.046501
Test loss: 0.025713; Test accuracy: 9911/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.057584
Epoch: 7 10000/60000 Training loss: 0.006807
Epoch: 7 20000/60000 Training loss: 0.011552
Epoch: 7 30000/60000 Training loss: 0.012949
Epoch: 7 40000/60000 Training loss: 0.089412
Epoch: 7 50000/60000 Training loss: 0.058096
Training loss: 0.043131
Test loss: 0.022951; Test accuracy: 9923/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.065999
Epoch: 8 10000/60000 Training loss: 0.012045
Epoch: 8 20000/60000 Training loss: 0.073044
Epoch: 8 30000/60000 Training loss: 0.077496
Epoch: 8 40000/60000 Training loss: 0.027827
Epoch: 8 50000/60000 Training loss: 0.074481
Training loss: 0.037493
Test loss: 0.022250; Test accuracy: 9930/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.021221
Epoch: 9 10000/60000 Training loss: 0.027200
Epoch: 9 20000/60000 Training loss: 0.011932
Epoch: 9 30000/60000 Training loss: 0.040489
Epoch: 9 40000/60000 Training loss: 0.013996
Epoch: 9 50000/60000 Training loss: 0.040177
Training loss: 0.034729
Test loss: 0.022830; Test accuracy: 9925/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.004062
Epoch: 10 10000/60000 Training loss: 0.023023
Epoch: 10 20000/60000 Training loss: 0.047698
Epoch: 10 30000/60000 Training loss: 0.010103
Epoch: 10 40000/60000 Training loss: 0.067451
Epoch: 10 50000/60000 Training loss: 0.014566
Training loss: 0.031382
Test loss: 0.020418; Test accuracy: 9935/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.029784
Epoch: 11 10000/60000 Training loss: 0.031958
Epoch: 11 20000/60000 Training loss: 0.039787
Epoch: 11 30000/60000 Training loss: 0.016796
Epoch: 11 40000/60000 Training loss: 0.026624
Epoch: 11 50000/60000 Training loss: 0.001318
Training loss: 0.029052
Test loss: 0.022353; Test accuracy: 9924/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.015310
Epoch: 12 10000/60000 Training loss: 0.011272
Epoch: 12 20000/60000 Training loss: 0.022162
Epoch: 12 30000/60000 Training loss: 0.019928
Epoch: 12 40000/60000 Training loss: 0.065356
Epoch: 12 50000/60000 Training loss: 0.044299
Training loss: 0.026819
Test loss: 0.018690; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.012899
Epoch: 13 10000/60000 Training loss: 0.010226
Epoch: 13 20000/60000 Training loss: 0.014981
Epoch: 13 30000/60000 Training loss: 0.015988
Epoch: 13 40000/60000 Training loss: 0.002374
Epoch: 13 50000/60000 Training loss: 0.004365
Training loss: 0.025051
Test loss: 0.017904; Test accuracy: 9945/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.006949
Epoch: 14 10000/60000 Training loss: 0.010952
Epoch: 14 20000/60000 Training loss: 0.005200
Epoch: 14 30000/60000 Training loss: 0.023361
Epoch: 14 40000/60000 Training loss: 0.047914
Epoch: 14 50000/60000 Training loss: 0.021564
Training loss: 0.022392
Test loss: 0.017305; Test accuracy: 9942/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.048291
Epoch: 15 10000/60000 Training loss: 0.016338
Epoch: 15 20000/60000 Training loss: 0.013956
Epoch: 15 30000/60000 Training loss: 0.018215
Epoch: 15 40000/60000 Training loss: 0.005555
Epoch: 15 50000/60000 Training loss: 0.012008
Training loss: 0.021811
Test loss: 0.019036; Test accuracy: 9941/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.003497
Epoch: 16 10000/60000 Training loss: 0.025057
Epoch: 16 20000/60000 Training loss: 0.004596
Epoch: 16 30000/60000 Training loss: 0.016307
Epoch: 16 40000/60000 Training loss: 0.007834
Epoch: 16 50000/60000 Training loss: 0.005520
Training loss: 0.020020
Test loss: 0.017304; Test accuracy: 9943/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.006324
Epoch: 17 10000/60000 Training loss: 0.012484
Epoch: 17 20000/60000 Training loss: 0.001909
Epoch: 17 30000/60000 Training loss: 0.012465
Epoch: 17 40000/60000 Training loss: 0.018863
Epoch: 17 50000/60000 Training loss: 0.018927
Training loss: 0.017981
Test loss: 0.019721; Test accuracy: 9943/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.069953
Epoch: 18 10000/60000 Training loss: 0.005844
Epoch: 18 20000/60000 Training loss: 0.004864
Epoch: 18 30000/60000 Training loss: 0.020003
Epoch: 18 40000/60000 Training loss: 0.049994
Epoch: 18 50000/60000 Training loss: 0.003779
Training loss: 0.017376
Test loss: 0.018597; Test accuracy: 9930/10000 (99.3%)

Epoch: 19 0/60000 Training loss: 0.008059
Epoch: 19 10000/60000 Training loss: 0.001277
Epoch: 19 20000/60000 Training loss: 0.008222
Epoch: 19 30000/60000 Training loss: 0.007967
Epoch: 19 40000/60000 Training loss: 0.003948
Epoch: 19 50000/60000 Training loss: 0.003298
Training loss: 0.015143
Test loss: 0.019275; Test accuracy: 9939/10000 (99.4%)

[I 2022-11-04 05:22:02,840] Trial 86 finished with value: 0.01730378158390522 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 112, 'conv2_drop': 0.19991555667957706, 'fc1_neurons': 170, 'optimizer': 'Adam', 'learning_rate': 8.948877592517693e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1983177840269442, 'fc1_neurons': 180, 'optimizer': 'SGD', 'learning_rate': 8.934204923832032e-05}
Epoch: 0 0/60000 Training loss: 2.328727
Epoch: 0 10000/60000 Training loss: 2.308888
Epoch: 0 20000/60000 Training loss: 2.326236
Epoch: 0 30000/60000 Training loss: 2.297518
Epoch: 0 40000/60000 Training loss: 2.283504
Epoch: 0 50000/60000 Training loss: 2.290050
Training loss: 2.300438
Test loss: 2.274710; Test accuracy: 2428/10000 (24.3%)

Epoch: 1 0/60000 Training loss: 2.269892
Epoch: 1 10000/60000 Training loss: 2.291230
Epoch: 1 20000/60000 Training loss: 2.276513
Epoch: 1 30000/60000 Training loss: 2.262631
Epoch: 1 40000/60000 Training loss: 2.287229
Epoch: 1 50000/60000 Training loss: 2.256789
Training loss: 2.272660
Test loss: 2.245329; Test accuracy: 3663/10000 (36.6%)

Epoch: 2 0/60000 Training loss: 2.249061
Epoch: 2 10000/60000 Training loss: 2.261480
Epoch: 2 20000/60000 Training loss: 2.264783
Epoch: 2 30000/60000 Training loss: 2.253068
Epoch: 2 40000/60000 Training loss: 2.248731
Epoch: 2 50000/60000 Training loss: 2.244788
Training loss: 2.246656
Test loss: 2.216307; Test accuracy: 4961/10000 (49.6%)

Epoch: 3 0/60000 Training loss: 2.241050
Epoch: 3 10000/60000 Training loss: 2.227969
Epoch: 3 20000/60000 Training loss: 2.216437
Epoch: 3 30000/60000 Training loss: 2.208464
Epoch: 3 40000/60000 Training loss: 2.212803
Epoch: 3 50000/60000 Training loss: 2.184179
Training loss: 2.220209
Test loss: 2.185937; Test accuracy: 6057/10000 (60.6%)

Epoch: 4 0/60000 Training loss: 2.202094
Epoch: 4 10000/60000 Training loss: 2.181997
Epoch: 4 20000/60000 Training loss: 2.200965
Epoch: 4 30000/60000 Training loss: 2.196872
Epoch: 4 40000/60000 Training loss: 2.188184
Epoch: 4 50000/60000 Training loss: 2.186751
Training loss: 2.191210
Test loss: 2.152062; Test accuracy: 6745/10000 (67.4%)

Epoch: 5 0/60000 Training loss: 2.161737
Epoch: 5 10000/60000 Training loss: 2.176436
Epoch: 5 20000/60000 Training loss: 2.146858
Epoch: 5 30000/60000 Training loss: 2.133435
Epoch: 5 40000/60000 Training loss: 2.181899
Epoch: 5 50000/60000 Training loss: 2.156159
Training loss: 2.159792
Test loss: 2.113075; Test accuracy: 7123/10000 (71.2%)

Epoch: 6 0/60000 Training loss: 2.115258
Epoch: 6 10000/60000 Training loss: 2.163236
Epoch: 6 20000/60000 Training loss: 2.135123
Epoch: 6 30000/60000 Training loss: 2.102541
Epoch: 6 40000/60000 Training loss: 2.109724
Epoch: 6 50000/60000 Training loss: 2.088761
Training loss: 2.122182
Test loss: 2.067556; Test accuracy: 7325/10000 (73.2%)

Epoch: 7 0/60000 Training loss: 2.089897
Epoch: 7 10000/60000 Training loss: 2.055562
Epoch: 7 20000/60000 Training loss: 2.083066
Epoch: 7 30000/60000 Training loss: 2.056873
Epoch: 7 40000/60000 Training loss: 2.106614
Epoch: 7 50000/60000 Training loss: 2.010730
Training loss: 2.081048
Test loss: 2.014901; Test accuracy: 7429/10000 (74.3%)

Epoch: 8 0/60000 Training loss: 2.017630
Epoch: 8 10000/60000 Training loss: 2.075670
Epoch: 8 20000/60000 Training loss: 2.015445
Epoch: 8 30000/60000 Training loss: 2.030945
Epoch: 8 40000/60000 Training loss: 1.978730
Epoch: 8 50000/60000 Training loss: 2.014630
Training loss: 2.030502
Test loss: 1.953563; Test accuracy: 7519/10000 (75.2%)

Epoch: 9 0/60000 Training loss: 1.989019
Epoch: 9 10000/60000 Training loss: 1.961320
Epoch: 9 20000/60000 Training loss: 1.955777
Epoch: 9 30000/60000 Training loss: 1.944317
Epoch: 9 40000/60000 Training loss: 2.000983
Epoch: 9 50000/60000 Training loss: 1.974792
Training loss: 1.971904
Test loss: 1.882282; Test accuracy: 7563/10000 (75.6%)

Epoch: 10 0/60000 Training loss: 1.906508
Epoch: 10 10000/60000 Training loss: 1.904194
Epoch: 10 20000/60000 Training loss: 1.966053
Epoch: 10 30000/60000 Training loss: 1.976137
Epoch: 10 40000/60000 Training loss: 1.865802
Epoch: 10 50000/60000 Training loss: 1.869938
Training loss: 1.905626
Test loss: 1.800460; Test accuracy: 7576/10000 (75.8%)

Epoch: 11 0/60000 Training loss: 1.859475
Epoch: 11 10000/60000 Training loss: 1.843300
Epoch: 11 20000/60000 Training loss: 1.868860
Epoch: 11 30000/60000 Training loss: 1.815838
Epoch: 11 40000/60000 Training loss: 1.822355
Epoch: 11 50000/60000 Training loss: 1.801730
Training loss: 1.831797
Test loss: 1.708414; Test accuracy: 7605/10000 (76.0%)

Epoch: 12 0/60000 Training loss: 1.799956
Epoch: 12 10000/60000 Training loss: 1.809619
Epoch: 12 20000/60000 Training loss: 1.743760
Epoch: 12 30000/60000 Training loss: 1.756587
Epoch: 12 40000/60000 Training loss: 1.752288
Epoch: 12 50000/60000 Training loss: 1.763466
Training loss: 1.751448
Test loss: 1.608233; Test accuracy: 7677/10000 (76.8%)

Epoch: 13 0/60000 Training loss: 1.720577
Epoch: 13 10000/60000 Training loss: 1.673900
Epoch: 13 20000/60000 Training loss: 1.724591
Epoch: 13 30000/60000 Training loss: 1.657741
Epoch: 13 40000/60000 Training loss: 1.695836
Epoch: 13 50000/60000 Training loss: 1.667720
Training loss: 1.664042
Test loss: 1.502560; Test accuracy: 7701/10000 (77.0%)

Epoch: 14 0/60000 Training loss: 1.686742
Epoch: 14 10000/60000 Training loss: 1.628259
Epoch: 14 20000/60000 Training loss: 1.554184
Epoch: 14 30000/60000 Training loss: 1.677508
Epoch: 14 40000/60000 Training loss: 1.629858
Epoch: 14 50000/60000 Training loss: 1.520176
Training loss: 1.573703
Test loss: 1.394833; Test accuracy: 7801/10000 (78.0%)

Epoch: 15 0/60000 Training loss: 1.534021
Epoch: 15 10000/60000 Training loss: 1.507093
Epoch: 15 20000/60000 Training loss: 1.459225
Epoch: 15 30000/60000 Training loss: 1.559817
Epoch: 15 40000/60000 Training loss: 1.478967
Epoch: 15 50000/60000 Training loss: 1.534637
Training loss: 1.484124
Test loss: 1.289022; Test accuracy: 7926/10000 (79.3%)

Epoch: 16 0/60000 Training loss: 1.436404
Epoch: 16 10000/60000 Training loss: 1.472528
Epoch: 16 20000/60000 Training loss: 1.513396
Epoch: 16 30000/60000 Training loss: 1.408633
Epoch: 16 40000/60000 Training loss: 1.315567
Epoch: 16 50000/60000 Training loss: 1.361352
Training loss: 1.392306
Test loss: 1.187308; Test accuracy: 8051/10000 (80.5%)

Epoch: 17 0/60000 Training loss: 1.418121
Epoch: 17 10000/60000 Training loss: 1.359575
Epoch: 17 20000/60000 Training loss: 1.383980
Epoch: 17 30000/60000 Training loss: 1.285118
Epoch: 17 40000/60000 Training loss: 1.269326
Epoch: 17 50000/60000 Training loss: 1.353430
Training loss: 1.312704
Test loss: 1.094169; Test accuracy: 8197/10000 (82.0%)

Epoch: 18 0/60000 Training loss: 1.330923
Epoch: 18 10000/60000 Training loss: 1.210547
Epoch: 18 20000/60000 Training loss: 1.243221
Epoch: 18 30000/60000 Training loss: 1.185726
Epoch: 18 40000/60000 Training loss: 1.187786
Epoch: 18 50000/60000 Training loss: 1.327651
Training loss: 1.237578
Test loss: 1.009430; Test accuracy: 8313/10000 (83.1%)

Epoch: 19 0/60000 Training loss: 1.140324
Epoch: 19 10000/60000 Training loss: 1.215973
Epoch: 19 20000/60000 Training loss: 1.264518
Epoch: 19 30000/60000 Training loss: 1.215760
Epoch: 19 40000/60000 Training loss: 0.985096
Epoch: 19 50000/60000 Training loss: 1.070974
Training loss: 1.162033
Test loss: 0.933334; Test accuracy: 8397/10000 (84.0%)

[I 2022-11-04 05:26:42,042] Trial 87 finished with value: 0.9333335757255554 and parameters: {'num_conv1_channels': 64, 'num_conv2_channels': 80, 'conv2_drop': 0.1983177840269442, 'fc1_neurons': 180, 'optimizer': 'SGD', 'learning_rate': 8.934204923832032e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18840064602857895, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.0001360350732888287}
Epoch: 0 0/60000 Training loss: 2.334518
Epoch: 0 10000/60000 Training loss: 0.630187
Epoch: 0 20000/60000 Training loss: 0.209029
Epoch: 0 30000/60000 Training loss: 0.168962
Epoch: 0 40000/60000 Training loss: 0.193610
Epoch: 0 50000/60000 Training loss: 0.127567
Training loss: 0.387201
Test loss: 0.078610; Test accuracy: 9762/10000 (97.6%)

Epoch: 1 0/60000 Training loss: 0.337170
Epoch: 1 10000/60000 Training loss: 0.189561
Epoch: 1 20000/60000 Training loss: 0.093995
Epoch: 1 30000/60000 Training loss: 0.063901
Epoch: 1 40000/60000 Training loss: 0.154021
Epoch: 1 50000/60000 Training loss: 0.127375
Training loss: 0.115264
Test loss: 0.048064; Test accuracy: 9838/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.052823
Epoch: 2 10000/60000 Training loss: 0.104719
Epoch: 2 20000/60000 Training loss: 0.103063
Epoch: 2 30000/60000 Training loss: 0.064362
Epoch: 2 40000/60000 Training loss: 0.129887
Epoch: 2 50000/60000 Training loss: 0.200508
Training loss: 0.082622
Test loss: 0.036020; Test accuracy: 9880/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.093768
Epoch: 3 10000/60000 Training loss: 0.120274
Epoch: 3 20000/60000 Training loss: 0.018758
Epoch: 3 30000/60000 Training loss: 0.195852
Epoch: 3 40000/60000 Training loss: 0.035690
Epoch: 3 50000/60000 Training loss: 0.025026
Training loss: 0.064375
Test loss: 0.030369; Test accuracy: 9897/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.040436
Epoch: 4 10000/60000 Training loss: 0.059529
Epoch: 4 20000/60000 Training loss: 0.034695
Epoch: 4 30000/60000 Training loss: 0.023417
Epoch: 4 40000/60000 Training loss: 0.139865
Epoch: 4 50000/60000 Training loss: 0.136483
Training loss: 0.055737
Test loss: 0.027003; Test accuracy: 9907/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.073056
Epoch: 5 10000/60000 Training loss: 0.050687
Epoch: 5 20000/60000 Training loss: 0.016881
Epoch: 5 30000/60000 Training loss: 0.094580
Epoch: 5 40000/60000 Training loss: 0.023749
Epoch: 5 50000/60000 Training loss: 0.025162
Training loss: 0.048392
Test loss: 0.026331; Test accuracy: 9910/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.058051
Epoch: 6 10000/60000 Training loss: 0.049249
Epoch: 6 20000/60000 Training loss: 0.018095
Epoch: 6 30000/60000 Training loss: 0.015876
Epoch: 6 40000/60000 Training loss: 0.096873
Epoch: 6 50000/60000 Training loss: 0.023547
Training loss: 0.041798
Test loss: 0.023757; Test accuracy: 9921/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.020803
Epoch: 7 10000/60000 Training loss: 0.052160
Epoch: 7 20000/60000 Training loss: 0.010760
Epoch: 7 30000/60000 Training loss: 0.046471
Epoch: 7 40000/60000 Training loss: 0.028635
Epoch: 7 50000/60000 Training loss: 0.029659
Training loss: 0.038735
Test loss: 0.025977; Test accuracy: 9901/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.041131
Epoch: 8 10000/60000 Training loss: 0.010328
Epoch: 8 20000/60000 Training loss: 0.017692
Epoch: 8 30000/60000 Training loss: 0.011090
Epoch: 8 40000/60000 Training loss: 0.006501
Epoch: 8 50000/60000 Training loss: 0.106044
Training loss: 0.033415
Test loss: 0.020338; Test accuracy: 9930/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.022015
Epoch: 9 10000/60000 Training loss: 0.049835
Epoch: 9 20000/60000 Training loss: 0.009058
Epoch: 9 30000/60000 Training loss: 0.027107
Epoch: 9 40000/60000 Training loss: 0.023445
Epoch: 9 50000/60000 Training loss: 0.010955
Training loss: 0.029606
Test loss: 0.020517; Test accuracy: 9925/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.001811
Epoch: 10 10000/60000 Training loss: 0.038738
Epoch: 10 20000/60000 Training loss: 0.081257
Epoch: 10 30000/60000 Training loss: 0.129346
Epoch: 10 40000/60000 Training loss: 0.042895
Epoch: 10 50000/60000 Training loss: 0.004153
Training loss: 0.028073
Test loss: 0.018881; Test accuracy: 9938/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.054704
Epoch: 11 10000/60000 Training loss: 0.037940
Epoch: 11 20000/60000 Training loss: 0.004355
Epoch: 11 30000/60000 Training loss: 0.060427
Epoch: 11 40000/60000 Training loss: 0.027071
Epoch: 11 50000/60000 Training loss: 0.035052
Training loss: 0.026134
Test loss: 0.017422; Test accuracy: 9943/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.031391
Epoch: 12 10000/60000 Training loss: 0.049826
Epoch: 12 20000/60000 Training loss: 0.008930
Epoch: 12 30000/60000 Training loss: 0.015249
Epoch: 12 40000/60000 Training loss: 0.022465
Epoch: 12 50000/60000 Training loss: 0.015416
Training loss: 0.024037
Test loss: 0.019583; Test accuracy: 9933/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.012297
Epoch: 13 10000/60000 Training loss: 0.024318
Epoch: 13 20000/60000 Training loss: 0.024969
Epoch: 13 30000/60000 Training loss: 0.075539
Epoch: 13 40000/60000 Training loss: 0.037318
Epoch: 13 50000/60000 Training loss: 0.005571
Training loss: 0.022041
Test loss: 0.018454; Test accuracy: 9939/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.017771
Epoch: 14 10000/60000 Training loss: 0.002390
Epoch: 14 20000/60000 Training loss: 0.103838
Epoch: 14 30000/60000 Training loss: 0.010168
Epoch: 14 40000/60000 Training loss: 0.002870
Epoch: 14 50000/60000 Training loss: 0.032461
Training loss: 0.019983
Test loss: 0.018107; Test accuracy: 9943/10000 (99.4%)

[I 2022-11-04 05:30:12,077] Trial 88 finished with value: 0.017421703785657883 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18840064602857895, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.0001360350732888287}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.18911860155537355, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001373505923930741}
Epoch: 0 0/60000 Training loss: 2.330474
Epoch: 0 10000/60000 Training loss: 0.440561
Epoch: 0 20000/60000 Training loss: 0.349821
Epoch: 0 30000/60000 Training loss: 0.173490
Epoch: 0 40000/60000 Training loss: 0.117833
Epoch: 0 50000/60000 Training loss: 0.141044
Training loss: 0.395952
Test loss: 0.082463; Test accuracy: 9753/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.144382
Epoch: 1 10000/60000 Training loss: 0.187655
Epoch: 1 20000/60000 Training loss: 0.244634
Epoch: 1 30000/60000 Training loss: 0.061029
Epoch: 1 40000/60000 Training loss: 0.046418
Epoch: 1 50000/60000 Training loss: 0.111913
Training loss: 0.120439
Test loss: 0.050891; Test accuracy: 9839/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.065172
Epoch: 2 10000/60000 Training loss: 0.037198
Epoch: 2 20000/60000 Training loss: 0.059024
Epoch: 2 30000/60000 Training loss: 0.087394
Epoch: 2 40000/60000 Training loss: 0.122168
Epoch: 2 50000/60000 Training loss: 0.067151
Training loss: 0.086985
Test loss: 0.038311; Test accuracy: 9882/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.096837
Epoch: 3 10000/60000 Training loss: 0.025823
Epoch: 3 20000/60000 Training loss: 0.065068
Epoch: 3 30000/60000 Training loss: 0.071152
Epoch: 3 40000/60000 Training loss: 0.022287
Epoch: 3 50000/60000 Training loss: 0.050921
Training loss: 0.070161
Test loss: 0.032277; Test accuracy: 9897/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.118768
Epoch: 4 10000/60000 Training loss: 0.047660
Epoch: 4 20000/60000 Training loss: 0.036113
Epoch: 4 30000/60000 Training loss: 0.033843
Epoch: 4 40000/60000 Training loss: 0.069159
Epoch: 4 50000/60000 Training loss: 0.038182
Training loss: 0.059974
Test loss: 0.029063; Test accuracy: 9900/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.174906
Epoch: 5 10000/60000 Training loss: 0.073355
Epoch: 5 20000/60000 Training loss: 0.073952
Epoch: 5 30000/60000 Training loss: 0.024093
Epoch: 5 40000/60000 Training loss: 0.018093
Epoch: 5 50000/60000 Training loss: 0.057065
Training loss: 0.051773
Test loss: 0.026911; Test accuracy: 9906/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.048967
Epoch: 6 10000/60000 Training loss: 0.047570
Epoch: 6 20000/60000 Training loss: 0.068531
Epoch: 6 30000/60000 Training loss: 0.010661
Epoch: 6 40000/60000 Training loss: 0.049775
Epoch: 6 50000/60000 Training loss: 0.011105
Training loss: 0.045499
Test loss: 0.025253; Test accuracy: 9917/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.042031
Epoch: 7 10000/60000 Training loss: 0.004631
Epoch: 7 20000/60000 Training loss: 0.034766
Epoch: 7 30000/60000 Training loss: 0.051918
Epoch: 7 40000/60000 Training loss: 0.022504
Epoch: 7 50000/60000 Training loss: 0.032822
Training loss: 0.041114
Test loss: 0.024668; Test accuracy: 9912/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.025614
Epoch: 8 10000/60000 Training loss: 0.004606
Epoch: 8 20000/60000 Training loss: 0.057902
Epoch: 8 30000/60000 Training loss: 0.014798
Epoch: 8 40000/60000 Training loss: 0.012021
Epoch: 8 50000/60000 Training loss: 0.059522
Training loss: 0.036371
Test loss: 0.022164; Test accuracy: 9925/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.005442
Epoch: 9 10000/60000 Training loss: 0.037046
Epoch: 9 20000/60000 Training loss: 0.065924
Epoch: 9 30000/60000 Training loss: 0.032338
Epoch: 9 40000/60000 Training loss: 0.039710
Epoch: 9 50000/60000 Training loss: 0.018246
Training loss: 0.032744
Test loss: 0.020894; Test accuracy: 9925/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.027761
Epoch: 10 10000/60000 Training loss: 0.063600
Epoch: 10 20000/60000 Training loss: 0.086103
Epoch: 10 30000/60000 Training loss: 0.023259
Epoch: 10 40000/60000 Training loss: 0.007320
Epoch: 10 50000/60000 Training loss: 0.013605
Training loss: 0.031317
Test loss: 0.019908; Test accuracy: 9937/10000 (99.4%)

Epoch: 11 0/60000 Training loss: 0.002447
Epoch: 11 10000/60000 Training loss: 0.020891
Epoch: 11 20000/60000 Training loss: 0.007978
Epoch: 11 30000/60000 Training loss: 0.032002
Epoch: 11 40000/60000 Training loss: 0.012399
Epoch: 11 50000/60000 Training loss: 0.027879
Training loss: 0.028274
Test loss: 0.020301; Test accuracy: 9927/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.009992
Epoch: 12 10000/60000 Training loss: 0.014139
Epoch: 12 20000/60000 Training loss: 0.008727
Epoch: 12 30000/60000 Training loss: 0.028298
Epoch: 12 40000/60000 Training loss: 0.011472
Epoch: 12 50000/60000 Training loss: 0.074870
Training loss: 0.025918
Test loss: 0.017982; Test accuracy: 9936/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.091702
Epoch: 13 10000/60000 Training loss: 0.014181
Epoch: 13 20000/60000 Training loss: 0.005076
Epoch: 13 30000/60000 Training loss: 0.080250
Epoch: 13 40000/60000 Training loss: 0.060124
Epoch: 13 50000/60000 Training loss: 0.038237
Training loss: 0.024419
Test loss: 0.019509; Test accuracy: 9942/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.005603
Epoch: 14 10000/60000 Training loss: 0.011458
Epoch: 14 20000/60000 Training loss: 0.010323
Epoch: 14 30000/60000 Training loss: 0.010957
Epoch: 14 40000/60000 Training loss: 0.005657
Epoch: 14 50000/60000 Training loss: 0.023812
Training loss: 0.022006
Test loss: 0.017369; Test accuracy: 9944/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.007901
Epoch: 15 10000/60000 Training loss: 0.021637
Epoch: 15 20000/60000 Training loss: 0.100544
Epoch: 15 30000/60000 Training loss: 0.004095
Epoch: 15 40000/60000 Training loss: 0.005370
Epoch: 15 50000/60000 Training loss: 0.001280
Training loss: 0.021498
Test loss: 0.017989; Test accuracy: 9944/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.007751
Epoch: 16 10000/60000 Training loss: 0.010329
Epoch: 16 20000/60000 Training loss: 0.114389
Epoch: 16 30000/60000 Training loss: 0.030769
Epoch: 16 40000/60000 Training loss: 0.008852
Epoch: 16 50000/60000 Training loss: 0.034812
Training loss: 0.021383
Test loss: 0.017359; Test accuracy: 9945/10000 (99.4%)

Epoch: 17 0/60000 Training loss: 0.008523
Epoch: 17 10000/60000 Training loss: 0.002120
Epoch: 17 20000/60000 Training loss: 0.002057
Epoch: 17 30000/60000 Training loss: 0.009063
Epoch: 17 40000/60000 Training loss: 0.003328
Epoch: 17 50000/60000 Training loss: 0.013915
Training loss: 0.016952
Test loss: 0.017770; Test accuracy: 9942/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.006151
Epoch: 18 10000/60000 Training loss: 0.063654
Epoch: 18 20000/60000 Training loss: 0.015869
Epoch: 18 30000/60000 Training loss: 0.003202
Epoch: 18 40000/60000 Training loss: 0.007009
Epoch: 18 50000/60000 Training loss: 0.004480
Training loss: 0.017843
Test loss: 0.018399; Test accuracy: 9941/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.002193
Epoch: 19 10000/60000 Training loss: 0.006733
Epoch: 19 20000/60000 Training loss: 0.016435
Epoch: 19 30000/60000 Training loss: 0.009137
Epoch: 19 40000/60000 Training loss: 0.005318
Epoch: 19 50000/60000 Training loss: 0.002679
Training loss: 0.015352
Test loss: 0.018962; Test accuracy: 9949/10000 (99.5%)

[I 2022-11-04 05:34:51,733] Trial 89 finished with value: 0.01735905557870865 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.18911860155537355, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001373505923930741}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 128, 'num_conv2_channels': 80, 'conv2_drop': 0.18883965349563342, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00013922930071172076}
Epoch: 0 0/60000 Training loss: 2.293822
Epoch: 0 10000/60000 Training loss: 0.446703
Epoch: 0 20000/60000 Training loss: 0.275866
Epoch: 0 30000/60000 Training loss: 0.135290
Epoch: 0 40000/60000 Training loss: 0.203183
Epoch: 0 50000/60000 Training loss: 0.166100
Training loss: 0.386509
Test loss: 0.082766; Test accuracy: 9745/10000 (97.4%)

Epoch: 1 0/60000 Training loss: 0.127757
Epoch: 1 10000/60000 Training loss: 0.079656
Epoch: 1 20000/60000 Training loss: 0.102976
Epoch: 1 30000/60000 Training loss: 0.173866
Epoch: 1 40000/60000 Training loss: 0.093670
Epoch: 1 50000/60000 Training loss: 0.022108
Training loss: 0.115780
Test loss: 0.048645; Test accuracy: 9847/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.058926
Epoch: 2 10000/60000 Training loss: 0.205262
Epoch: 2 20000/60000 Training loss: 0.071801
Epoch: 2 30000/60000 Training loss: 0.023904
Epoch: 2 40000/60000 Training loss: 0.049921
Epoch: 2 50000/60000 Training loss: 0.040414
Training loss: 0.082877
Test loss: 0.037037; Test accuracy: 9882/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.066733
Epoch: 3 10000/60000 Training loss: 0.028271
Epoch: 3 20000/60000 Training loss: 0.071625
Epoch: 3 30000/60000 Training loss: 0.062038
Epoch: 3 40000/60000 Training loss: 0.038029
Epoch: 3 50000/60000 Training loss: 0.095098
Training loss: 0.065101
Test loss: 0.032349; Test accuracy: 9889/10000 (98.9%)

Epoch: 4 0/60000 Training loss: 0.037359
Epoch: 4 10000/60000 Training loss: 0.053989
Epoch: 4 20000/60000 Training loss: 0.036306
Epoch: 4 30000/60000 Training loss: 0.017636
Epoch: 4 40000/60000 Training loss: 0.087975
Epoch: 4 50000/60000 Training loss: 0.031879
Training loss: 0.055340
Test loss: 0.027861; Test accuracy: 9910/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.091738
Epoch: 5 10000/60000 Training loss: 0.021226
Epoch: 5 20000/60000 Training loss: 0.025789
Epoch: 5 30000/60000 Training loss: 0.167939
Epoch: 5 40000/60000 Training loss: 0.038531
Epoch: 5 50000/60000 Training loss: 0.114164
Training loss: 0.048008
Test loss: 0.027578; Test accuracy: 9904/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.025804
Epoch: 6 10000/60000 Training loss: 0.038733
Epoch: 6 20000/60000 Training loss: 0.021965
Epoch: 6 30000/60000 Training loss: 0.011805
Epoch: 6 40000/60000 Training loss: 0.032316
Epoch: 6 50000/60000 Training loss: 0.008391
Training loss: 0.042429
Test loss: 0.024783; Test accuracy: 9917/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.034697
Epoch: 7 10000/60000 Training loss: 0.031414
Epoch: 7 20000/60000 Training loss: 0.032166
Epoch: 7 30000/60000 Training loss: 0.039049
Epoch: 7 40000/60000 Training loss: 0.015654
Epoch: 7 50000/60000 Training loss: 0.063655
Training loss: 0.038110
Test loss: 0.024623; Test accuracy: 9919/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.014298
Epoch: 8 10000/60000 Training loss: 0.073244
Epoch: 8 20000/60000 Training loss: 0.039718
Epoch: 8 30000/60000 Training loss: 0.014537
Epoch: 8 40000/60000 Training loss: 0.005640
Epoch: 8 50000/60000 Training loss: 0.003229
Training loss: 0.033671
Test loss: 0.021764; Test accuracy: 9924/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.063598
Epoch: 9 10000/60000 Training loss: 0.055853
Epoch: 9 20000/60000 Training loss: 0.003798
Epoch: 9 30000/60000 Training loss: 0.010024
Epoch: 9 40000/60000 Training loss: 0.097537
Epoch: 9 50000/60000 Training loss: 0.005190
Training loss: 0.031436
Test loss: 0.019864; Test accuracy: 9928/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.003887
Epoch: 10 10000/60000 Training loss: 0.020602
Epoch: 10 20000/60000 Training loss: 0.014313
Epoch: 10 30000/60000 Training loss: 0.012043
Epoch: 10 40000/60000 Training loss: 0.046029
Epoch: 10 50000/60000 Training loss: 0.007712
Training loss: 0.028674
Test loss: 0.020803; Test accuracy: 9930/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.016602
Epoch: 11 10000/60000 Training loss: 0.006245
Epoch: 11 20000/60000 Training loss: 0.013977
Epoch: 11 30000/60000 Training loss: 0.006022
Epoch: 11 40000/60000 Training loss: 0.039112
Epoch: 11 50000/60000 Training loss: 0.008000
Training loss: 0.026110
Test loss: 0.020143; Test accuracy: 9938/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.007227
Epoch: 12 10000/60000 Training loss: 0.023816
Epoch: 12 20000/60000 Training loss: 0.006240
Epoch: 12 30000/60000 Training loss: 0.008686
Epoch: 12 40000/60000 Training loss: 0.010744
Epoch: 12 50000/60000 Training loss: 0.004793
Training loss: 0.024715
Test loss: 0.018631; Test accuracy: 9928/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.024132
Epoch: 13 10000/60000 Training loss: 0.043211
Epoch: 13 20000/60000 Training loss: 0.021788
Epoch: 13 30000/60000 Training loss: 0.012846
Epoch: 13 40000/60000 Training loss: 0.026333
Epoch: 13 50000/60000 Training loss: 0.015985
Training loss: 0.021776
Test loss: 0.019410; Test accuracy: 9939/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.046058
Epoch: 14 10000/60000 Training loss: 0.016929
Epoch: 14 20000/60000 Training loss: 0.020848
Epoch: 14 30000/60000 Training loss: 0.002554
Epoch: 14 40000/60000 Training loss: 0.004988
Epoch: 14 50000/60000 Training loss: 0.001579
Training loss: 0.021182
Test loss: 0.018676; Test accuracy: 9933/10000 (99.3%)

Epoch: 15 0/60000 Training loss: 0.012898
Epoch: 15 10000/60000 Training loss: 0.008586
Epoch: 15 20000/60000 Training loss: 0.038223
Epoch: 15 30000/60000 Training loss: 0.020260
Epoch: 15 40000/60000 Training loss: 0.002872
Epoch: 15 50000/60000 Training loss: 0.015606
Training loss: 0.018257
Test loss: 0.019650; Test accuracy: 9933/10000 (99.3%)

[I 2022-11-04 05:38:35,317] Trial 90 finished with value: 0.018631208688020706 and parameters: {'num_conv1_channels': 128, 'num_conv2_channels': 80, 'conv2_drop': 0.18883965349563342, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00013922930071172076}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.19445979647921005, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00016283612806364402}
Epoch: 0 0/60000 Training loss: 2.321554
Epoch: 0 10000/60000 Training loss: 0.556762
Epoch: 0 20000/60000 Training loss: 0.450688
Epoch: 0 30000/60000 Training loss: 0.257213
Epoch: 0 40000/60000 Training loss: 0.153883
Epoch: 0 50000/60000 Training loss: 0.071178
Training loss: 0.370833
Test loss: 0.080314; Test accuracy: 9755/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.101784
Epoch: 1 10000/60000 Training loss: 0.211910
Epoch: 1 20000/60000 Training loss: 0.091966
Epoch: 1 30000/60000 Training loss: 0.170668
Epoch: 1 40000/60000 Training loss: 0.090529
Epoch: 1 50000/60000 Training loss: 0.084798
Training loss: 0.116327
Test loss: 0.050210; Test accuracy: 9845/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.036997
Epoch: 2 10000/60000 Training loss: 0.085337
Epoch: 2 20000/60000 Training loss: 0.096610
Epoch: 2 30000/60000 Training loss: 0.113399
Epoch: 2 40000/60000 Training loss: 0.050845
Epoch: 2 50000/60000 Training loss: 0.061619
Training loss: 0.084060
Test loss: 0.036076; Test accuracy: 9886/10000 (98.9%)

Epoch: 3 0/60000 Training loss: 0.030502
Epoch: 3 10000/60000 Training loss: 0.064599
Epoch: 3 20000/60000 Training loss: 0.009988
Epoch: 3 30000/60000 Training loss: 0.105820
Epoch: 3 40000/60000 Training loss: 0.127851
Epoch: 3 50000/60000 Training loss: 0.108515
Training loss: 0.066727
Test loss: 0.030544; Test accuracy: 9904/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.067484
Epoch: 4 10000/60000 Training loss: 0.039951
Epoch: 4 20000/60000 Training loss: 0.028902
Epoch: 4 30000/60000 Training loss: 0.010403
Epoch: 4 40000/60000 Training loss: 0.074908
Epoch: 4 50000/60000 Training loss: 0.032871
Training loss: 0.056607
Test loss: 0.029180; Test accuracy: 9904/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.067481
Epoch: 5 10000/60000 Training loss: 0.020017
Epoch: 5 20000/60000 Training loss: 0.068464
Epoch: 5 30000/60000 Training loss: 0.026823
Epoch: 5 40000/60000 Training loss: 0.019102
Epoch: 5 50000/60000 Training loss: 0.070327
Training loss: 0.048269
Test loss: 0.024127; Test accuracy: 9917/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.013534
Epoch: 6 10000/60000 Training loss: 0.015810
Epoch: 6 20000/60000 Training loss: 0.038124
Epoch: 6 30000/60000 Training loss: 0.048771
Epoch: 6 40000/60000 Training loss: 0.013038
Epoch: 6 50000/60000 Training loss: 0.010178
Training loss: 0.042322
Test loss: 0.022118; Test accuracy: 9928/10000 (99.3%)

Epoch: 7 0/60000 Training loss: 0.014016
Epoch: 7 10000/60000 Training loss: 0.079114
Epoch: 7 20000/60000 Training loss: 0.035093
Epoch: 7 30000/60000 Training loss: 0.023491
Epoch: 7 40000/60000 Training loss: 0.066388
Epoch: 7 50000/60000 Training loss: 0.010164
Training loss: 0.039700
Test loss: 0.022550; Test accuracy: 9922/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.028249
Epoch: 8 10000/60000 Training loss: 0.028853
Epoch: 8 20000/60000 Training loss: 0.017963
Epoch: 8 30000/60000 Training loss: 0.068529
Epoch: 8 40000/60000 Training loss: 0.045935
Epoch: 8 50000/60000 Training loss: 0.011270
Training loss: 0.034081
Test loss: 0.025696; Test accuracy: 9915/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.035452
Epoch: 9 10000/60000 Training loss: 0.013285
Epoch: 9 20000/60000 Training loss: 0.010562
Epoch: 9 30000/60000 Training loss: 0.026349
Epoch: 9 40000/60000 Training loss: 0.054290
Epoch: 9 50000/60000 Training loss: 0.004871
Training loss: 0.031476
Test loss: 0.024068; Test accuracy: 9920/10000 (99.2%)

[I 2022-11-04 05:40:55,617] Trial 91 finished with value: 0.022117972373962402 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 64, 'conv2_drop': 0.19445979647921005, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00016283612806364402}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.1915034709345788, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00012426831473941283}
Epoch: 0 0/60000 Training loss: 2.323249
Epoch: 0 10000/60000 Training loss: 0.506959
Epoch: 0 20000/60000 Training loss: 0.298645
Epoch: 0 30000/60000 Training loss: 0.285493
Epoch: 0 40000/60000 Training loss: 0.187001
Epoch: 0 50000/60000 Training loss: 0.146326
Training loss: 0.397995
Test loss: 0.087243; Test accuracy: 9747/10000 (97.5%)

Epoch: 1 0/60000 Training loss: 0.160746
Epoch: 1 10000/60000 Training loss: 0.148411
Epoch: 1 20000/60000 Training loss: 0.203141
Epoch: 1 30000/60000 Training loss: 0.153133
Epoch: 1 40000/60000 Training loss: 0.077349
Epoch: 1 50000/60000 Training loss: 0.091081
Training loss: 0.120742
Test loss: 0.050202; Test accuracy: 9840/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.128828
Epoch: 2 10000/60000 Training loss: 0.064042
Epoch: 2 20000/60000 Training loss: 0.049868
Epoch: 2 30000/60000 Training loss: 0.051580
Epoch: 2 40000/60000 Training loss: 0.108592
Epoch: 2 50000/60000 Training loss: 0.163163
Training loss: 0.083488
Test loss: 0.036775; Test accuracy: 9874/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.070916
Epoch: 3 10000/60000 Training loss: 0.152327
Epoch: 3 20000/60000 Training loss: 0.167717
Epoch: 3 30000/60000 Training loss: 0.019879
Epoch: 3 40000/60000 Training loss: 0.124720
Epoch: 3 50000/60000 Training loss: 0.037295
Training loss: 0.068127
Test loss: 0.029308; Test accuracy: 9904/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.049341
Epoch: 4 10000/60000 Training loss: 0.030894
Epoch: 4 20000/60000 Training loss: 0.081817
Epoch: 4 30000/60000 Training loss: 0.063478
Epoch: 4 40000/60000 Training loss: 0.051483
Epoch: 4 50000/60000 Training loss: 0.052490
Training loss: 0.056745
Test loss: 0.026808; Test accuracy: 9910/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.009427
Epoch: 5 10000/60000 Training loss: 0.086503
Epoch: 5 20000/60000 Training loss: 0.013840
Epoch: 5 30000/60000 Training loss: 0.068210
Epoch: 5 40000/60000 Training loss: 0.022383
Epoch: 5 50000/60000 Training loss: 0.037010
Training loss: 0.048469
Test loss: 0.025015; Test accuracy: 9910/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.032156
Epoch: 6 10000/60000 Training loss: 0.115221
Epoch: 6 20000/60000 Training loss: 0.099221
Epoch: 6 30000/60000 Training loss: 0.012675
Epoch: 6 40000/60000 Training loss: 0.083365
Epoch: 6 50000/60000 Training loss: 0.153988
Training loss: 0.044629
Test loss: 0.023421; Test accuracy: 9914/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.029800
Epoch: 7 10000/60000 Training loss: 0.081828
Epoch: 7 20000/60000 Training loss: 0.011912
Epoch: 7 30000/60000 Training loss: 0.011356
Epoch: 7 40000/60000 Training loss: 0.007322
Epoch: 7 50000/60000 Training loss: 0.048832
Training loss: 0.039119
Test loss: 0.020370; Test accuracy: 9927/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.015018
Epoch: 8 10000/60000 Training loss: 0.031957
Epoch: 8 20000/60000 Training loss: 0.008348
Epoch: 8 30000/60000 Training loss: 0.018051
Epoch: 8 40000/60000 Training loss: 0.011481
Epoch: 8 50000/60000 Training loss: 0.012106
Training loss: 0.035527
Test loss: 0.019554; Test accuracy: 9932/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.043605
Epoch: 9 10000/60000 Training loss: 0.036660
Epoch: 9 20000/60000 Training loss: 0.035191
Epoch: 9 30000/60000 Training loss: 0.074228
Epoch: 9 40000/60000 Training loss: 0.019841
Epoch: 9 50000/60000 Training loss: 0.008388
Training loss: 0.031416
Test loss: 0.020802; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.013458
Epoch: 10 10000/60000 Training loss: 0.086430
Epoch: 10 20000/60000 Training loss: 0.014175
Epoch: 10 30000/60000 Training loss: 0.054149
Epoch: 10 40000/60000 Training loss: 0.028385
Epoch: 10 50000/60000 Training loss: 0.012349
Training loss: 0.030098
Test loss: 0.020627; Test accuracy: 9929/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.018162
Epoch: 11 10000/60000 Training loss: 0.002787
Epoch: 11 20000/60000 Training loss: 0.008017
Epoch: 11 30000/60000 Training loss: 0.042886
Epoch: 11 40000/60000 Training loss: 0.021237
Epoch: 11 50000/60000 Training loss: 0.026793
Training loss: 0.026843
Test loss: 0.018094; Test accuracy: 9934/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.014066
Epoch: 12 10000/60000 Training loss: 0.016712
Epoch: 12 20000/60000 Training loss: 0.027214
Epoch: 12 30000/60000 Training loss: 0.027983
Epoch: 12 40000/60000 Training loss: 0.076071
Epoch: 12 50000/60000 Training loss: 0.007595
Training loss: 0.025735
Test loss: 0.018347; Test accuracy: 9936/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.007560
Epoch: 13 10000/60000 Training loss: 0.011773
Epoch: 13 20000/60000 Training loss: 0.077027
Epoch: 13 30000/60000 Training loss: 0.080888
Epoch: 13 40000/60000 Training loss: 0.040873
Epoch: 13 50000/60000 Training loss: 0.002554
Training loss: 0.023989
Test loss: 0.019763; Test accuracy: 9934/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.036907
Epoch: 14 10000/60000 Training loss: 0.018337
Epoch: 14 20000/60000 Training loss: 0.006403
Epoch: 14 30000/60000 Training loss: 0.004971
Epoch: 14 40000/60000 Training loss: 0.026792
Epoch: 14 50000/60000 Training loss: 0.003579
Training loss: 0.019804
Test loss: 0.019721; Test accuracy: 9939/10000 (99.4%)

[I 2022-11-04 05:44:26,273] Trial 92 finished with value: 0.018093908205628395 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.1915034709345788, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00012426831473941283}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.18459720446145994, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 8.920204608100692e-05}
Epoch: 0 0/60000 Training loss: 2.320495
Epoch: 0 10000/60000 Training loss: 0.721201
Epoch: 0 20000/60000 Training loss: 0.496974
Epoch: 0 30000/60000 Training loss: 0.402702
Epoch: 0 40000/60000 Training loss: 0.158197
Epoch: 0 50000/60000 Training loss: 0.282062
Training loss: 0.544665
Test loss: 0.121041; Test accuracy: 9641/10000 (96.4%)

Epoch: 1 0/60000 Training loss: 0.216338
Epoch: 1 10000/60000 Training loss: 0.186321
Epoch: 1 20000/60000 Training loss: 0.163646
Epoch: 1 30000/60000 Training loss: 0.274677
Epoch: 1 40000/60000 Training loss: 0.075511
Epoch: 1 50000/60000 Training loss: 0.129502
Training loss: 0.169720
Test loss: 0.072145; Test accuracy: 9775/10000 (97.8%)

Epoch: 2 0/60000 Training loss: 0.135844
Epoch: 2 10000/60000 Training loss: 0.123951
Epoch: 2 20000/60000 Training loss: 0.147611
Epoch: 2 30000/60000 Training loss: 0.200243
Epoch: 2 40000/60000 Training loss: 0.137857
Epoch: 2 50000/60000 Training loss: 0.106657
Training loss: 0.119799
Test loss: 0.054326; Test accuracy: 9833/10000 (98.3%)

Epoch: 3 0/60000 Training loss: 0.082084
Epoch: 3 10000/60000 Training loss: 0.069419
Epoch: 3 20000/60000 Training loss: 0.116634
Epoch: 3 30000/60000 Training loss: 0.043215
Epoch: 3 40000/60000 Training loss: 0.071713
Epoch: 3 50000/60000 Training loss: 0.096540
Training loss: 0.095492
Test loss: 0.043441; Test accuracy: 9852/10000 (98.5%)

Epoch: 4 0/60000 Training loss: 0.061849
Epoch: 4 10000/60000 Training loss: 0.123799
Epoch: 4 20000/60000 Training loss: 0.049943
Epoch: 4 30000/60000 Training loss: 0.121867
Epoch: 4 40000/60000 Training loss: 0.099489
Epoch: 4 50000/60000 Training loss: 0.087528
Training loss: 0.081019
Test loss: 0.036304; Test accuracy: 9870/10000 (98.7%)

Epoch: 5 0/60000 Training loss: 0.052919
Epoch: 5 10000/60000 Training loss: 0.037579
Epoch: 5 20000/60000 Training loss: 0.043511
Epoch: 5 30000/60000 Training loss: 0.079702
Epoch: 5 40000/60000 Training loss: 0.143455
Epoch: 5 50000/60000 Training loss: 0.105007
Training loss: 0.072247
Test loss: 0.034321; Test accuracy: 9883/10000 (98.8%)

Epoch: 6 0/60000 Training loss: 0.074643
Epoch: 6 10000/60000 Training loss: 0.047309
Epoch: 6 20000/60000 Training loss: 0.078302
Epoch: 6 30000/60000 Training loss: 0.092537
Epoch: 6 40000/60000 Training loss: 0.044567
Epoch: 6 50000/60000 Training loss: 0.038422
Training loss: 0.062853
Test loss: 0.029914; Test accuracy: 9899/10000 (99.0%)

Epoch: 7 0/60000 Training loss: 0.043873
Epoch: 7 10000/60000 Training loss: 0.132065
Epoch: 7 20000/60000 Training loss: 0.032764
Epoch: 7 30000/60000 Training loss: 0.023149
Epoch: 7 40000/60000 Training loss: 0.011421
Epoch: 7 50000/60000 Training loss: 0.031467
Training loss: 0.055900
Test loss: 0.028460; Test accuracy: 9904/10000 (99.0%)

Epoch: 8 0/60000 Training loss: 0.050279
Epoch: 8 10000/60000 Training loss: 0.067365
Epoch: 8 20000/60000 Training loss: 0.032493
Epoch: 8 30000/60000 Training loss: 0.038896
Epoch: 8 40000/60000 Training loss: 0.064675
Epoch: 8 50000/60000 Training loss: 0.062081
Training loss: 0.052027
Test loss: 0.026525; Test accuracy: 9908/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.106801
Epoch: 9 10000/60000 Training loss: 0.048041
Epoch: 9 20000/60000 Training loss: 0.050833
Epoch: 9 30000/60000 Training loss: 0.018463
Epoch: 9 40000/60000 Training loss: 0.022659
Epoch: 9 50000/60000 Training loss: 0.014668
Training loss: 0.049075
Test loss: 0.026310; Test accuracy: 9904/10000 (99.0%)

Epoch: 10 0/60000 Training loss: 0.070203
Epoch: 10 10000/60000 Training loss: 0.038346
Epoch: 10 20000/60000 Training loss: 0.067127
Epoch: 10 30000/60000 Training loss: 0.016928
Epoch: 10 40000/60000 Training loss: 0.061126
Epoch: 10 50000/60000 Training loss: 0.128867
Training loss: 0.044745
Test loss: 0.023056; Test accuracy: 9917/10000 (99.2%)

Epoch: 11 0/60000 Training loss: 0.020461
Epoch: 11 10000/60000 Training loss: 0.049932
Epoch: 11 20000/60000 Training loss: 0.019180
Epoch: 11 30000/60000 Training loss: 0.035603
Epoch: 11 40000/60000 Training loss: 0.033576
Epoch: 11 50000/60000 Training loss: 0.056308
Training loss: 0.042694
Test loss: 0.023005; Test accuracy: 9920/10000 (99.2%)

Epoch: 12 0/60000 Training loss: 0.056431
Epoch: 12 10000/60000 Training loss: 0.047139
Epoch: 12 20000/60000 Training loss: 0.016018
Epoch: 12 30000/60000 Training loss: 0.014113
Epoch: 12 40000/60000 Training loss: 0.107913
Epoch: 12 50000/60000 Training loss: 0.023267
Training loss: 0.039208
Test loss: 0.021852; Test accuracy: 9912/10000 (99.1%)

Epoch: 13 0/60000 Training loss: 0.032244
Epoch: 13 10000/60000 Training loss: 0.037305
Epoch: 13 20000/60000 Training loss: 0.042214
Epoch: 13 30000/60000 Training loss: 0.003022
Epoch: 13 40000/60000 Training loss: 0.041697
Epoch: 13 50000/60000 Training loss: 0.037084
Training loss: 0.036971
Test loss: 0.021315; Test accuracy: 9925/10000 (99.2%)

Epoch: 14 0/60000 Training loss: 0.060856
Epoch: 14 10000/60000 Training loss: 0.055868
Epoch: 14 20000/60000 Training loss: 0.033172
Epoch: 14 30000/60000 Training loss: 0.018281
Epoch: 14 40000/60000 Training loss: 0.023030
Epoch: 14 50000/60000 Training loss: 0.038678
Training loss: 0.033408
Test loss: 0.021440; Test accuracy: 9924/10000 (99.2%)

Epoch: 15 0/60000 Training loss: 0.005217
Epoch: 15 10000/60000 Training loss: 0.029818
Epoch: 15 20000/60000 Training loss: 0.006726
Epoch: 15 30000/60000 Training loss: 0.034868
Epoch: 15 40000/60000 Training loss: 0.011959
Epoch: 15 50000/60000 Training loss: 0.013068
Training loss: 0.032398
Test loss: 0.021611; Test accuracy: 9926/10000 (99.3%)

Epoch: 16 0/60000 Training loss: 0.043690
Epoch: 16 10000/60000 Training loss: 0.026342
Epoch: 16 20000/60000 Training loss: 0.006464
Epoch: 16 30000/60000 Training loss: 0.019208
Epoch: 16 40000/60000 Training loss: 0.013245
Epoch: 16 50000/60000 Training loss: 0.062720
Training loss: 0.030154
Test loss: 0.020375; Test accuracy: 9933/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.011653
Epoch: 17 10000/60000 Training loss: 0.055590
Epoch: 17 20000/60000 Training loss: 0.014619
Epoch: 17 30000/60000 Training loss: 0.013870
Epoch: 17 40000/60000 Training loss: 0.010964
Epoch: 17 50000/60000 Training loss: 0.037482
Training loss: 0.027874
Test loss: 0.019829; Test accuracy: 9933/10000 (99.3%)

Epoch: 18 0/60000 Training loss: 0.025652
Epoch: 18 10000/60000 Training loss: 0.049977
Epoch: 18 20000/60000 Training loss: 0.043101
Epoch: 18 30000/60000 Training loss: 0.065488
Epoch: 18 40000/60000 Training loss: 0.002815
Epoch: 18 50000/60000 Training loss: 0.010492
Training loss: 0.026781
Test loss: 0.019406; Test accuracy: 9941/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.016676
Epoch: 19 10000/60000 Training loss: 0.029020
Epoch: 19 20000/60000 Training loss: 0.006583
Epoch: 19 30000/60000 Training loss: 0.035024
Epoch: 19 40000/60000 Training loss: 0.013678
Epoch: 19 50000/60000 Training loss: 0.005138
Training loss: 0.026161
Test loss: 0.019245; Test accuracy: 9938/10000 (99.4%)

[I 2022-11-04 05:49:05,721] Trial 93 finished with value: 0.019245078787207603 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 64, 'conv2_drop': 0.18459720446145994, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 8.920204608100692e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.18820262566042856, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00016995088973224224}
Epoch: 0 0/60000 Training loss: 2.317077
Epoch: 0 10000/60000 Training loss: 0.401132
Epoch: 0 20000/60000 Training loss: 0.215205
Epoch: 0 30000/60000 Training loss: 0.158715
Epoch: 0 40000/60000 Training loss: 0.144526
Epoch: 0 50000/60000 Training loss: 0.298353
Training loss: 0.353140
Test loss: 0.079291; Test accuracy: 9764/10000 (97.6%)

Epoch: 1 0/60000 Training loss: 0.042366
Epoch: 1 10000/60000 Training loss: 0.067018
Epoch: 1 20000/60000 Training loss: 0.082186
Epoch: 1 30000/60000 Training loss: 0.148889
Epoch: 1 40000/60000 Training loss: 0.130901
Epoch: 1 50000/60000 Training loss: 0.151247
Training loss: 0.108401
Test loss: 0.045731; Test accuracy: 9853/10000 (98.5%)

Epoch: 2 0/60000 Training loss: 0.101680
Epoch: 2 10000/60000 Training loss: 0.091975
Epoch: 2 20000/60000 Training loss: 0.097922
Epoch: 2 30000/60000 Training loss: 0.143708
Epoch: 2 40000/60000 Training loss: 0.048283
Epoch: 2 50000/60000 Training loss: 0.134414
Training loss: 0.078334
Test loss: 0.035957; Test accuracy: 9882/10000 (98.8%)

Epoch: 3 0/60000 Training loss: 0.038539
Epoch: 3 10000/60000 Training loss: 0.072821
Epoch: 3 20000/60000 Training loss: 0.119626
Epoch: 3 30000/60000 Training loss: 0.055576
Epoch: 3 40000/60000 Training loss: 0.037404
Epoch: 3 50000/60000 Training loss: 0.080066
Training loss: 0.061512
Test loss: 0.028925; Test accuracy: 9903/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.086568
Epoch: 4 10000/60000 Training loss: 0.046437
Epoch: 4 20000/60000 Training loss: 0.009135
Epoch: 4 30000/60000 Training loss: 0.101365
Epoch: 4 40000/60000 Training loss: 0.121539
Epoch: 4 50000/60000 Training loss: 0.032190
Training loss: 0.052385
Test loss: 0.026415; Test accuracy: 9912/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.007622
Epoch: 5 10000/60000 Training loss: 0.035735
Epoch: 5 20000/60000 Training loss: 0.018191
Epoch: 5 30000/60000 Training loss: 0.032594
Epoch: 5 40000/60000 Training loss: 0.037039
Epoch: 5 50000/60000 Training loss: 0.009147
Training loss: 0.045360
Test loss: 0.024621; Test accuracy: 9919/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.055785
Epoch: 6 10000/60000 Training loss: 0.046367
Epoch: 6 20000/60000 Training loss: 0.012563
Epoch: 6 30000/60000 Training loss: 0.057746
Epoch: 6 40000/60000 Training loss: 0.037243
Epoch: 6 50000/60000 Training loss: 0.049374
Training loss: 0.040504
Test loss: 0.021953; Test accuracy: 9924/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.067157
Epoch: 7 10000/60000 Training loss: 0.032155
Epoch: 7 20000/60000 Training loss: 0.061027
Epoch: 7 30000/60000 Training loss: 0.026254
Epoch: 7 40000/60000 Training loss: 0.003092
Epoch: 7 50000/60000 Training loss: 0.023650
Training loss: 0.036924
Test loss: 0.021510; Test accuracy: 9928/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.052613
Epoch: 8 10000/60000 Training loss: 0.012863
Epoch: 8 20000/60000 Training loss: 0.012059
Epoch: 8 30000/60000 Training loss: 0.008741
Epoch: 8 40000/60000 Training loss: 0.006676
Epoch: 8 50000/60000 Training loss: 0.012199
Training loss: 0.032107
Test loss: 0.020802; Test accuracy: 9934/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.087372
Epoch: 9 10000/60000 Training loss: 0.019987
Epoch: 9 20000/60000 Training loss: 0.001679
Epoch: 9 30000/60000 Training loss: 0.017158
Epoch: 9 40000/60000 Training loss: 0.089688
Epoch: 9 50000/60000 Training loss: 0.054750
Training loss: 0.028801
Test loss: 0.020508; Test accuracy: 9929/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.007725
Epoch: 10 10000/60000 Training loss: 0.002716
Epoch: 10 20000/60000 Training loss: 0.026399
Epoch: 10 30000/60000 Training loss: 0.010218
Epoch: 10 40000/60000 Training loss: 0.009774
Epoch: 10 50000/60000 Training loss: 0.092826
Training loss: 0.026321
Test loss: 0.021038; Test accuracy: 9928/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.054544
Epoch: 11 10000/60000 Training loss: 0.038251
Epoch: 11 20000/60000 Training loss: 0.016412
Epoch: 11 30000/60000 Training loss: 0.006445
Epoch: 11 40000/60000 Training loss: 0.052830
Epoch: 11 50000/60000 Training loss: 0.021069
Training loss: 0.025638
Test loss: 0.020926; Test accuracy: 9929/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.023759
Epoch: 12 10000/60000 Training loss: 0.046364
Epoch: 12 20000/60000 Training loss: 0.018883
Epoch: 12 30000/60000 Training loss: 0.003075
Epoch: 12 40000/60000 Training loss: 0.009564
Epoch: 12 50000/60000 Training loss: 0.019378
Training loss: 0.023459
Test loss: 0.018434; Test accuracy: 9938/10000 (99.4%)

Epoch: 13 0/60000 Training loss: 0.032938
Epoch: 13 10000/60000 Training loss: 0.020509
Epoch: 13 20000/60000 Training loss: 0.038935
Epoch: 13 30000/60000 Training loss: 0.029409
Epoch: 13 40000/60000 Training loss: 0.021274
Epoch: 13 50000/60000 Training loss: 0.055261
Training loss: 0.021129
Test loss: 0.019900; Test accuracy: 9935/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.005014
Epoch: 14 10000/60000 Training loss: 0.041713
Epoch: 14 20000/60000 Training loss: 0.038357
Epoch: 14 30000/60000 Training loss: 0.012070
Epoch: 14 40000/60000 Training loss: 0.030882
Epoch: 14 50000/60000 Training loss: 0.015118
Training loss: 0.018993
Test loss: 0.018458; Test accuracy: 9937/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.001279
Epoch: 15 10000/60000 Training loss: 0.007567
Epoch: 15 20000/60000 Training loss: 0.014109
Epoch: 15 30000/60000 Training loss: 0.003764
Epoch: 15 40000/60000 Training loss: 0.023343
Epoch: 15 50000/60000 Training loss: 0.003533
Training loss: 0.017263
Test loss: 0.020467; Test accuracy: 9932/10000 (99.3%)

[I 2022-11-04 05:52:50,683] Trial 94 finished with value: 0.018433833494782448 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.18820262566042856, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00016995088973224224}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.17822682860252476, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00013344369888955047}
Epoch: 0 0/60000 Training loss: 2.290042
Epoch: 0 10000/60000 Training loss: 0.436116
Epoch: 0 20000/60000 Training loss: 0.333887
Epoch: 0 30000/60000 Training loss: 0.210017
Epoch: 0 40000/60000 Training loss: 0.292560
Epoch: 0 50000/60000 Training loss: 0.142227
Training loss: 0.394493
Test loss: 0.079521; Test accuracy: 9760/10000 (97.6%)

Epoch: 1 0/60000 Training loss: 0.109492
Epoch: 1 10000/60000 Training loss: 0.155360
Epoch: 1 20000/60000 Training loss: 0.169077
Epoch: 1 30000/60000 Training loss: 0.108363
Epoch: 1 40000/60000 Training loss: 0.055250
Epoch: 1 50000/60000 Training loss: 0.078591
Training loss: 0.116598
Test loss: 0.053915; Test accuracy: 9831/10000 (98.3%)

Epoch: 2 0/60000 Training loss: 0.069338
Epoch: 2 10000/60000 Training loss: 0.161034
Epoch: 2 20000/60000 Training loss: 0.104514
Epoch: 2 30000/60000 Training loss: 0.074348
Epoch: 2 40000/60000 Training loss: 0.091248
Epoch: 2 50000/60000 Training loss: 0.031579
Training loss: 0.086490
Test loss: 0.041246; Test accuracy: 9871/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.077137
Epoch: 3 10000/60000 Training loss: 0.072875
Epoch: 3 20000/60000 Training loss: 0.095446
Epoch: 3 30000/60000 Training loss: 0.130339
Epoch: 3 40000/60000 Training loss: 0.054215
Epoch: 3 50000/60000 Training loss: 0.096675
Training loss: 0.068107
Test loss: 0.031498; Test accuracy: 9902/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.018428
Epoch: 4 10000/60000 Training loss: 0.026268
Epoch: 4 20000/60000 Training loss: 0.032737
Epoch: 4 30000/60000 Training loss: 0.034018
Epoch: 4 40000/60000 Training loss: 0.037160
Epoch: 4 50000/60000 Training loss: 0.007272
Training loss: 0.057332
Test loss: 0.028479; Test accuracy: 9905/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.013432
Epoch: 5 10000/60000 Training loss: 0.029705
Epoch: 5 20000/60000 Training loss: 0.106560
Epoch: 5 30000/60000 Training loss: 0.024217
Epoch: 5 40000/60000 Training loss: 0.103066
Epoch: 5 50000/60000 Training loss: 0.134049
Training loss: 0.050093
Test loss: 0.023972; Test accuracy: 9918/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.061832
Epoch: 6 10000/60000 Training loss: 0.011817
Epoch: 6 20000/60000 Training loss: 0.026428
Epoch: 6 30000/60000 Training loss: 0.028979
Epoch: 6 40000/60000 Training loss: 0.034118
Epoch: 6 50000/60000 Training loss: 0.008196
Training loss: 0.042449
Test loss: 0.024081; Test accuracy: 9917/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.049718
Epoch: 7 10000/60000 Training loss: 0.017042
Epoch: 7 20000/60000 Training loss: 0.093544
Epoch: 7 30000/60000 Training loss: 0.022414
Epoch: 7 40000/60000 Training loss: 0.031173
Epoch: 7 50000/60000 Training loss: 0.093162
Training loss: 0.039000
Test loss: 0.021554; Test accuracy: 9924/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.005734
Epoch: 8 10000/60000 Training loss: 0.031393
Epoch: 8 20000/60000 Training loss: 0.129284
Epoch: 8 30000/60000 Training loss: 0.018048
Epoch: 8 40000/60000 Training loss: 0.012396
Epoch: 8 50000/60000 Training loss: 0.040835
Training loss: 0.032833
Test loss: 0.021397; Test accuracy: 9930/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.033854
Epoch: 9 10000/60000 Training loss: 0.017022
Epoch: 9 20000/60000 Training loss: 0.037136
Epoch: 9 30000/60000 Training loss: 0.049576
Epoch: 9 40000/60000 Training loss: 0.034771
Epoch: 9 50000/60000 Training loss: 0.030550
Training loss: 0.031142
Test loss: 0.022165; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.028041
Epoch: 10 10000/60000 Training loss: 0.004944
Epoch: 10 20000/60000 Training loss: 0.005190
Epoch: 10 30000/60000 Training loss: 0.008785
Epoch: 10 40000/60000 Training loss: 0.010946
Epoch: 10 50000/60000 Training loss: 0.117385
Training loss: 0.028319
Test loss: 0.020584; Test accuracy: 9927/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.008973
Epoch: 11 10000/60000 Training loss: 0.072294
Epoch: 11 20000/60000 Training loss: 0.018122
Epoch: 11 30000/60000 Training loss: 0.029364
Epoch: 11 40000/60000 Training loss: 0.020131
Epoch: 11 50000/60000 Training loss: 0.074179
Training loss: 0.026566
Test loss: 0.022213; Test accuracy: 9926/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.006239
Epoch: 12 10000/60000 Training loss: 0.024426
Epoch: 12 20000/60000 Training loss: 0.018033
Epoch: 12 30000/60000 Training loss: 0.007476
Epoch: 12 40000/60000 Training loss: 0.010625
Epoch: 12 50000/60000 Training loss: 0.080901
Training loss: 0.023469
Test loss: 0.018080; Test accuracy: 9947/10000 (99.5%)

Epoch: 13 0/60000 Training loss: 0.016852
Epoch: 13 10000/60000 Training loss: 0.012143
Epoch: 13 20000/60000 Training loss: 0.008172
Epoch: 13 30000/60000 Training loss: 0.005364
Epoch: 13 40000/60000 Training loss: 0.002990
Epoch: 13 50000/60000 Training loss: 0.063987
Training loss: 0.021544
Test loss: 0.016687; Test accuracy: 9949/10000 (99.5%)

Epoch: 14 0/60000 Training loss: 0.062935
Epoch: 14 10000/60000 Training loss: 0.002060
Epoch: 14 20000/60000 Training loss: 0.009150
Epoch: 14 30000/60000 Training loss: 0.026203
Epoch: 14 40000/60000 Training loss: 0.002764
Epoch: 14 50000/60000 Training loss: 0.022019
Training loss: 0.019239
Test loss: 0.018134; Test accuracy: 9941/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.026123
Epoch: 15 10000/60000 Training loss: 0.008788
Epoch: 15 20000/60000 Training loss: 0.069788
Epoch: 15 30000/60000 Training loss: 0.021972
Epoch: 15 40000/60000 Training loss: 0.013061
Epoch: 15 50000/60000 Training loss: 0.010913
Training loss: 0.020100
Test loss: 0.017776; Test accuracy: 9939/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.005949
Epoch: 16 10000/60000 Training loss: 0.014267
Epoch: 16 20000/60000 Training loss: 0.007908
Epoch: 16 30000/60000 Training loss: 0.031372
Epoch: 16 40000/60000 Training loss: 0.030984
Epoch: 16 50000/60000 Training loss: 0.005809
Training loss: 0.017307
Test loss: 0.018043; Test accuracy: 9935/10000 (99.3%)

[I 2022-11-04 05:56:48,528] Trial 95 finished with value: 0.016686923801898956 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.17822682860252476, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00013344369888955047}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.19175914053309617, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001378542253082712}
Epoch: 0 0/60000 Training loss: 2.344360
Epoch: 0 10000/60000 Training loss: 0.421977
Epoch: 0 20000/60000 Training loss: 0.334993
Epoch: 0 30000/60000 Training loss: 0.276958
Epoch: 0 40000/60000 Training loss: 0.219587
Epoch: 0 50000/60000 Training loss: 0.349700
Training loss: 0.392881
Test loss: 0.083495; Test accuracy: 9740/10000 (97.4%)

Epoch: 1 0/60000 Training loss: 0.153575
Epoch: 1 10000/60000 Training loss: 0.156860
Epoch: 1 20000/60000 Training loss: 0.093314
Epoch: 1 30000/60000 Training loss: 0.114879
Epoch: 1 40000/60000 Training loss: 0.080321
Epoch: 1 50000/60000 Training loss: 0.083127
Training loss: 0.122473
Test loss: 0.052343; Test accuracy: 9840/10000 (98.4%)

Epoch: 2 0/60000 Training loss: 0.118576
Epoch: 2 10000/60000 Training loss: 0.146887
Epoch: 2 20000/60000 Training loss: 0.070689
Epoch: 2 30000/60000 Training loss: 0.061893
Epoch: 2 40000/60000 Training loss: 0.101390
Epoch: 2 50000/60000 Training loss: 0.033693
Training loss: 0.087556
Test loss: 0.040066; Test accuracy: 9874/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.062928
Epoch: 3 10000/60000 Training loss: 0.029826
Epoch: 3 20000/60000 Training loss: 0.085113
Epoch: 3 30000/60000 Training loss: 0.035441
Epoch: 3 40000/60000 Training loss: 0.030515
Epoch: 3 50000/60000 Training loss: 0.062048
Training loss: 0.069622
Test loss: 0.031875; Test accuracy: 9898/10000 (99.0%)

Epoch: 4 0/60000 Training loss: 0.029503
Epoch: 4 10000/60000 Training loss: 0.071765
Epoch: 4 20000/60000 Training loss: 0.044502
Epoch: 4 30000/60000 Training loss: 0.033846
Epoch: 4 40000/60000 Training loss: 0.025512
Epoch: 4 50000/60000 Training loss: 0.067326
Training loss: 0.057818
Test loss: 0.028914; Test accuracy: 9914/10000 (99.1%)

Epoch: 5 0/60000 Training loss: 0.039972
Epoch: 5 10000/60000 Training loss: 0.028897
Epoch: 5 20000/60000 Training loss: 0.023943
Epoch: 5 30000/60000 Training loss: 0.038529
Epoch: 5 40000/60000 Training loss: 0.039432
Epoch: 5 50000/60000 Training loss: 0.011882
Training loss: 0.049652
Test loss: 0.025497; Test accuracy: 9921/10000 (99.2%)

Epoch: 6 0/60000 Training loss: 0.044295
Epoch: 6 10000/60000 Training loss: 0.024555
Epoch: 6 20000/60000 Training loss: 0.007816
Epoch: 6 30000/60000 Training loss: 0.056502
Epoch: 6 40000/60000 Training loss: 0.092873
Epoch: 6 50000/60000 Training loss: 0.020764
Training loss: 0.045605
Test loss: 0.023572; Test accuracy: 9925/10000 (99.2%)

Epoch: 7 0/60000 Training loss: 0.029085
Epoch: 7 10000/60000 Training loss: 0.036930
Epoch: 7 20000/60000 Training loss: 0.029840
Epoch: 7 30000/60000 Training loss: 0.027065
Epoch: 7 40000/60000 Training loss: 0.038267
Epoch: 7 50000/60000 Training loss: 0.031838
Training loss: 0.039566
Test loss: 0.022939; Test accuracy: 9932/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.026817
Epoch: 8 10000/60000 Training loss: 0.036870
Epoch: 8 20000/60000 Training loss: 0.030767
Epoch: 8 30000/60000 Training loss: 0.022497
Epoch: 8 40000/60000 Training loss: 0.084725
Epoch: 8 50000/60000 Training loss: 0.013478
Training loss: 0.035358
Test loss: 0.022800; Test accuracy: 9917/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.038907
Epoch: 9 10000/60000 Training loss: 0.022770
Epoch: 9 20000/60000 Training loss: 0.056102
Epoch: 9 30000/60000 Training loss: 0.061448
Epoch: 9 40000/60000 Training loss: 0.009119
Epoch: 9 50000/60000 Training loss: 0.015221
Training loss: 0.033748
Test loss: 0.020184; Test accuracy: 9926/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.029967
Epoch: 10 10000/60000 Training loss: 0.007349
Epoch: 10 20000/60000 Training loss: 0.026865
Epoch: 10 30000/60000 Training loss: 0.021107
Epoch: 10 40000/60000 Training loss: 0.021506
Epoch: 10 50000/60000 Training loss: 0.064211
Training loss: 0.030328
Test loss: 0.020626; Test accuracy: 9926/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.030015
Epoch: 11 10000/60000 Training loss: 0.005115
Epoch: 11 20000/60000 Training loss: 0.002376
Epoch: 11 30000/60000 Training loss: 0.019519
Epoch: 11 40000/60000 Training loss: 0.002545
Epoch: 11 50000/60000 Training loss: 0.014397
Training loss: 0.027458
Test loss: 0.019304; Test accuracy: 9934/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.144882
Epoch: 12 10000/60000 Training loss: 0.011905
Epoch: 12 20000/60000 Training loss: 0.064267
Epoch: 12 30000/60000 Training loss: 0.046063
Epoch: 12 40000/60000 Training loss: 0.041618
Epoch: 12 50000/60000 Training loss: 0.065339
Training loss: 0.026049
Test loss: 0.021239; Test accuracy: 9929/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.020785
Epoch: 13 10000/60000 Training loss: 0.006823
Epoch: 13 20000/60000 Training loss: 0.005133
Epoch: 13 30000/60000 Training loss: 0.014162
Epoch: 13 40000/60000 Training loss: 0.025962
Epoch: 13 50000/60000 Training loss: 0.033907
Training loss: 0.023364
Test loss: 0.019957; Test accuracy: 9936/10000 (99.4%)

Epoch: 14 0/60000 Training loss: 0.017454
Epoch: 14 10000/60000 Training loss: 0.014958
Epoch: 14 20000/60000 Training loss: 0.009924
Epoch: 14 30000/60000 Training loss: 0.036750
Epoch: 14 40000/60000 Training loss: 0.022459
Epoch: 14 50000/60000 Training loss: 0.095499
Training loss: 0.021571
Test loss: 0.019937; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 06:00:18,661] Trial 96 finished with value: 0.01930427923798561 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.19175914053309617, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.0001378542253082712}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 80, 'num_conv2_channels': 96, 'conv2_drop': 0.17946745339683878, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00012027804806229827}
Epoch: 0 0/60000 Training loss: 2.316151
Epoch: 0 10000/60000 Training loss: 0.555516
Epoch: 0 20000/60000 Training loss: 0.381576
Epoch: 0 30000/60000 Training loss: 0.289890
Epoch: 0 40000/60000 Training loss: 0.252065
Epoch: 0 50000/60000 Training loss: 0.146072
Training loss: 0.431580
Test loss: 0.094087; Test accuracy: 9722/10000 (97.2%)

Epoch: 1 0/60000 Training loss: 0.115872
Epoch: 1 10000/60000 Training loss: 0.288761
Epoch: 1 20000/60000 Training loss: 0.169756
Epoch: 1 30000/60000 Training loss: 0.056613
Epoch: 1 40000/60000 Training loss: 0.089077
Epoch: 1 50000/60000 Training loss: 0.088789
Training loss: 0.129709
Test loss: 0.058457; Test accuracy: 9819/10000 (98.2%)

Epoch: 2 0/60000 Training loss: 0.035812
Epoch: 2 10000/60000 Training loss: 0.087880
Epoch: 2 20000/60000 Training loss: 0.032331
Epoch: 2 30000/60000 Training loss: 0.064136
Epoch: 2 40000/60000 Training loss: 0.094414
Epoch: 2 50000/60000 Training loss: 0.058326
Training loss: 0.090470
Test loss: 0.041758; Test accuracy: 9866/10000 (98.7%)

Epoch: 3 0/60000 Training loss: 0.051017
Epoch: 3 10000/60000 Training loss: 0.021911
Epoch: 3 20000/60000 Training loss: 0.150746
Epoch: 3 30000/60000 Training loss: 0.100731
Epoch: 3 40000/60000 Training loss: 0.066591
Epoch: 3 50000/60000 Training loss: 0.084332
Training loss: 0.073518
Test loss: 0.036063; Test accuracy: 9879/10000 (98.8%)

Epoch: 4 0/60000 Training loss: 0.069814
Epoch: 4 10000/60000 Training loss: 0.082530
Epoch: 4 20000/60000 Training loss: 0.181461
Epoch: 4 30000/60000 Training loss: 0.037684
Epoch: 4 40000/60000 Training loss: 0.052991
Epoch: 4 50000/60000 Training loss: 0.059423
Training loss: 0.063779
Test loss: 0.030616; Test accuracy: 9904/10000 (99.0%)

Epoch: 5 0/60000 Training loss: 0.057308
Epoch: 5 10000/60000 Training loss: 0.058507
Epoch: 5 20000/60000 Training loss: 0.031408
Epoch: 5 30000/60000 Training loss: 0.038986
Epoch: 5 40000/60000 Training loss: 0.016950
Epoch: 5 50000/60000 Training loss: 0.042052
Training loss: 0.053576
Test loss: 0.027519; Test accuracy: 9911/10000 (99.1%)

Epoch: 6 0/60000 Training loss: 0.023413
Epoch: 6 10000/60000 Training loss: 0.079790
Epoch: 6 20000/60000 Training loss: 0.013329
Epoch: 6 30000/60000 Training loss: 0.012006
Epoch: 6 40000/60000 Training loss: 0.019645
Epoch: 6 50000/60000 Training loss: 0.024611
Training loss: 0.047100
Test loss: 0.027116; Test accuracy: 9911/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.015404
Epoch: 7 10000/60000 Training loss: 0.035072
Epoch: 7 20000/60000 Training loss: 0.037801
Epoch: 7 30000/60000 Training loss: 0.017814
Epoch: 7 40000/60000 Training loss: 0.022772
Epoch: 7 50000/60000 Training loss: 0.044740
Training loss: 0.042182
Test loss: 0.025833; Test accuracy: 9916/10000 (99.2%)

Epoch: 8 0/60000 Training loss: 0.063617
Epoch: 8 10000/60000 Training loss: 0.018728
Epoch: 8 20000/60000 Training loss: 0.009039
Epoch: 8 30000/60000 Training loss: 0.097948
Epoch: 8 40000/60000 Training loss: 0.007861
Epoch: 8 50000/60000 Training loss: 0.007856
Training loss: 0.038884
Test loss: 0.023098; Test accuracy: 9924/10000 (99.2%)

Epoch: 9 0/60000 Training loss: 0.042771
Epoch: 9 10000/60000 Training loss: 0.050782
Epoch: 9 20000/60000 Training loss: 0.035558
Epoch: 9 30000/60000 Training loss: 0.039380
Epoch: 9 40000/60000 Training loss: 0.046808
Epoch: 9 50000/60000 Training loss: 0.009477
Training loss: 0.035056
Test loss: 0.021739; Test accuracy: 9929/10000 (99.3%)

Epoch: 10 0/60000 Training loss: 0.067017
Epoch: 10 10000/60000 Training loss: 0.052542
Epoch: 10 20000/60000 Training loss: 0.046678
Epoch: 10 30000/60000 Training loss: 0.005778
Epoch: 10 40000/60000 Training loss: 0.019084
Epoch: 10 50000/60000 Training loss: 0.008614
Training loss: 0.031793
Test loss: 0.020412; Test accuracy: 9929/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.028719
Epoch: 11 10000/60000 Training loss: 0.022828
Epoch: 11 20000/60000 Training loss: 0.046151
Epoch: 11 30000/60000 Training loss: 0.011868
Epoch: 11 40000/60000 Training loss: 0.023204
Epoch: 11 50000/60000 Training loss: 0.011692
Training loss: 0.028968
Test loss: 0.019586; Test accuracy: 9937/10000 (99.4%)

Epoch: 12 0/60000 Training loss: 0.004526
Epoch: 12 10000/60000 Training loss: 0.009774
Epoch: 12 20000/60000 Training loss: 0.006884
Epoch: 12 30000/60000 Training loss: 0.021804
Epoch: 12 40000/60000 Training loss: 0.017139
Epoch: 12 50000/60000 Training loss: 0.047170
Training loss: 0.028250
Test loss: 0.020606; Test accuracy: 9931/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.007408
Epoch: 13 10000/60000 Training loss: 0.039610
Epoch: 13 20000/60000 Training loss: 0.009438
Epoch: 13 30000/60000 Training loss: 0.012601
Epoch: 13 40000/60000 Training loss: 0.033739
Epoch: 13 50000/60000 Training loss: 0.100871
Training loss: 0.024480
Test loss: 0.020256; Test accuracy: 9934/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.017249
Epoch: 14 10000/60000 Training loss: 0.006543
Epoch: 14 20000/60000 Training loss: 0.042597
Epoch: 14 30000/60000 Training loss: 0.017553
Epoch: 14 40000/60000 Training loss: 0.008168
Epoch: 14 50000/60000 Training loss: 0.008437
Training loss: 0.024295
Test loss: 0.019642; Test accuracy: 9940/10000 (99.4%)

[I 2022-11-04 06:03:49,071] Trial 97 finished with value: 0.01958591863512993 and parameters: {'num_conv1_channels': 80, 'num_conv2_channels': 96, 'conv2_drop': 0.17946745339683878, 'fc1_neurons': 140, 'optimizer': 'Adam', 'learning_rate': 0.00012027804806229827}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.1953286706994828, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 9.968237726327636e-05}
Epoch: 0 0/60000 Training loss: 2.304762
Epoch: 0 10000/60000 Training loss: 0.697079
Epoch: 0 20000/60000 Training loss: 0.316461
Epoch: 0 30000/60000 Training loss: 0.205235
Epoch: 0 40000/60000 Training loss: 0.178255
Epoch: 0 50000/60000 Training loss: 0.256405
Training loss: 0.465551
Test loss: 0.101860; Test accuracy: 9685/10000 (96.8%)

Epoch: 1 0/60000 Training loss: 0.182800
Epoch: 1 10000/60000 Training loss: 0.176415
Epoch: 1 20000/60000 Training loss: 0.098396
Epoch: 1 30000/60000 Training loss: 0.108613
Epoch: 1 40000/60000 Training loss: 0.260573
Epoch: 1 50000/60000 Training loss: 0.242903
Training loss: 0.145222
Test loss: 0.063281; Test accuracy: 9787/10000 (97.9%)

Epoch: 2 0/60000 Training loss: 0.094604
Epoch: 2 10000/60000 Training loss: 0.069189
Epoch: 2 20000/60000 Training loss: 0.048165
Epoch: 2 30000/60000 Training loss: 0.075550
Epoch: 2 40000/60000 Training loss: 0.234888
Epoch: 2 50000/60000 Training loss: 0.014337
Training loss: 0.102365
Test loss: 0.044682; Test accuracy: 9845/10000 (98.4%)

Epoch: 3 0/60000 Training loss: 0.045086
Epoch: 3 10000/60000 Training loss: 0.083915
Epoch: 3 20000/60000 Training loss: 0.049012
Epoch: 3 30000/60000 Training loss: 0.140262
Epoch: 3 40000/60000 Training loss: 0.043798
Epoch: 3 50000/60000 Training loss: 0.086818
Training loss: 0.081558
Test loss: 0.036360; Test accuracy: 9872/10000 (98.7%)

Epoch: 4 0/60000 Training loss: 0.021006
Epoch: 4 10000/60000 Training loss: 0.044553
Epoch: 4 20000/60000 Training loss: 0.044434
Epoch: 4 30000/60000 Training loss: 0.046555
Epoch: 4 40000/60000 Training loss: 0.123618
Epoch: 4 50000/60000 Training loss: 0.153254
Training loss: 0.070053
Test loss: 0.032714; Test accuracy: 9893/10000 (98.9%)

Epoch: 5 0/60000 Training loss: 0.017059
Epoch: 5 10000/60000 Training loss: 0.030051
Epoch: 5 20000/60000 Training loss: 0.089525
Epoch: 5 30000/60000 Training loss: 0.055734
Epoch: 5 40000/60000 Training loss: 0.052312
Epoch: 5 50000/60000 Training loss: 0.052686
Training loss: 0.058776
Test loss: 0.029494; Test accuracy: 9903/10000 (99.0%)

Epoch: 6 0/60000 Training loss: 0.044245
Epoch: 6 10000/60000 Training loss: 0.056686
Epoch: 6 20000/60000 Training loss: 0.066493
Epoch: 6 30000/60000 Training loss: 0.079021
Epoch: 6 40000/60000 Training loss: 0.128817
Epoch: 6 50000/60000 Training loss: 0.063598
Training loss: 0.054062
Test loss: 0.026838; Test accuracy: 9908/10000 (99.1%)

Epoch: 7 0/60000 Training loss: 0.026944
Epoch: 7 10000/60000 Training loss: 0.067157
Epoch: 7 20000/60000 Training loss: 0.030281
Epoch: 7 30000/60000 Training loss: 0.044838
Epoch: 7 40000/60000 Training loss: 0.005748
Epoch: 7 50000/60000 Training loss: 0.043707
Training loss: 0.047656
Test loss: 0.025122; Test accuracy: 9912/10000 (99.1%)

Epoch: 8 0/60000 Training loss: 0.036724
Epoch: 8 10000/60000 Training loss: 0.031038
Epoch: 8 20000/60000 Training loss: 0.033295
Epoch: 8 30000/60000 Training loss: 0.006195
Epoch: 8 40000/60000 Training loss: 0.005120
Epoch: 8 50000/60000 Training loss: 0.022715
Training loss: 0.043374
Test loss: 0.024571; Test accuracy: 9912/10000 (99.1%)

Epoch: 9 0/60000 Training loss: 0.040040
Epoch: 9 10000/60000 Training loss: 0.019246
Epoch: 9 20000/60000 Training loss: 0.021480
Epoch: 9 30000/60000 Training loss: 0.022846
Epoch: 9 40000/60000 Training loss: 0.023067
Epoch: 9 50000/60000 Training loss: 0.171687
Training loss: 0.040000
Test loss: 0.022187; Test accuracy: 9920/10000 (99.2%)

Epoch: 10 0/60000 Training loss: 0.037840
Epoch: 10 10000/60000 Training loss: 0.055613
Epoch: 10 20000/60000 Training loss: 0.049183
Epoch: 10 30000/60000 Training loss: 0.018887
Epoch: 10 40000/60000 Training loss: 0.010264
Epoch: 10 50000/60000 Training loss: 0.063454
Training loss: 0.036922
Test loss: 0.020426; Test accuracy: 9932/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.018256
Epoch: 11 10000/60000 Training loss: 0.009879
Epoch: 11 20000/60000 Training loss: 0.065166
Epoch: 11 30000/60000 Training loss: 0.022789
Epoch: 11 40000/60000 Training loss: 0.006361
Epoch: 11 50000/60000 Training loss: 0.012006
Training loss: 0.034285
Test loss: 0.020191; Test accuracy: 9930/10000 (99.3%)

Epoch: 12 0/60000 Training loss: 0.032804
Epoch: 12 10000/60000 Training loss: 0.008186
Epoch: 12 20000/60000 Training loss: 0.034033
Epoch: 12 30000/60000 Training loss: 0.046203
Epoch: 12 40000/60000 Training loss: 0.022944
Epoch: 12 50000/60000 Training loss: 0.030823
Training loss: 0.031149
Test loss: 0.019415; Test accuracy: 9935/10000 (99.3%)

Epoch: 13 0/60000 Training loss: 0.003800
Epoch: 13 10000/60000 Training loss: 0.015829
Epoch: 13 20000/60000 Training loss: 0.026012
Epoch: 13 30000/60000 Training loss: 0.003477
Epoch: 13 40000/60000 Training loss: 0.009468
Epoch: 13 50000/60000 Training loss: 0.026310
Training loss: 0.029007
Test loss: 0.021304; Test accuracy: 9928/10000 (99.3%)

Epoch: 14 0/60000 Training loss: 0.043659
Epoch: 14 10000/60000 Training loss: 0.003653
Epoch: 14 20000/60000 Training loss: 0.073385
Epoch: 14 30000/60000 Training loss: 0.013631
Epoch: 14 40000/60000 Training loss: 0.010065
Epoch: 14 50000/60000 Training loss: 0.011460
Training loss: 0.026831
Test loss: 0.019323; Test accuracy: 9937/10000 (99.4%)

Epoch: 15 0/60000 Training loss: 0.017767
Epoch: 15 10000/60000 Training loss: 0.001726
Epoch: 15 20000/60000 Training loss: 0.008797
Epoch: 15 30000/60000 Training loss: 0.041466
Epoch: 15 40000/60000 Training loss: 0.017441
Epoch: 15 50000/60000 Training loss: 0.002810
Training loss: 0.024793
Test loss: 0.018549; Test accuracy: 9943/10000 (99.4%)

Epoch: 16 0/60000 Training loss: 0.008867
Epoch: 16 10000/60000 Training loss: 0.002902
Epoch: 16 20000/60000 Training loss: 0.040519
Epoch: 16 30000/60000 Training loss: 0.009868
Epoch: 16 40000/60000 Training loss: 0.006392
Epoch: 16 50000/60000 Training loss: 0.003024
Training loss: 0.024395
Test loss: 0.018659; Test accuracy: 9935/10000 (99.3%)

Epoch: 17 0/60000 Training loss: 0.002776
Epoch: 17 10000/60000 Training loss: 0.034364
Epoch: 17 20000/60000 Training loss: 0.015037
Epoch: 17 30000/60000 Training loss: 0.029911
Epoch: 17 40000/60000 Training loss: 0.001751
Epoch: 17 50000/60000 Training loss: 0.014539
Training loss: 0.022442
Test loss: 0.018853; Test accuracy: 9941/10000 (99.4%)

Epoch: 18 0/60000 Training loss: 0.032913
Epoch: 18 10000/60000 Training loss: 0.004709
Epoch: 18 20000/60000 Training loss: 0.015875
Epoch: 18 30000/60000 Training loss: 0.002513
Epoch: 18 40000/60000 Training loss: 0.018303
Epoch: 18 50000/60000 Training loss: 0.004763
Training loss: 0.021879
Test loss: 0.018455; Test accuracy: 9938/10000 (99.4%)

Epoch: 19 0/60000 Training loss: 0.005968
Epoch: 19 10000/60000 Training loss: 0.010702
Epoch: 19 20000/60000 Training loss: 0.003752
Epoch: 19 30000/60000 Training loss: 0.009359
Epoch: 19 40000/60000 Training loss: 0.002347
Epoch: 19 50000/60000 Training loss: 0.130084
Training loss: 0.020397
Test loss: 0.018379; Test accuracy: 9936/10000 (99.4%)

[I 2022-11-04 06:08:29,168] Trial 98 finished with value: 0.018378546461462975 and parameters: {'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.1953286706994828, 'fc1_neurons': 130, 'optimizer': 'Adam', 'learning_rate': 9.968237726327636e-05}. Best is trial 25 with value: 0.01626817137002945.
params: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18637705079141892, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00020433642977015916}
Epoch: 0 0/60000 Training loss: 2.352747
Epoch: 0 10000/60000 Training loss: 0.457590
Epoch: 0 20000/60000 Training loss: 0.166642
Epoch: 0 30000/60000 Training loss: 0.179717
Epoch: 0 40000/60000 Training loss: 0.090172
Epoch: 0 50000/60000 Training loss: 0.220368
Training loss: 0.286544
Test loss: 0.058609; Test accuracy: 9805/10000 (98.0%)

Epoch: 1 0/60000 Training loss: 0.083933
Epoch: 1 10000/60000 Training loss: 0.031618
Epoch: 1 20000/60000 Training loss: 0.050165
Epoch: 1 30000/60000 Training loss: 0.112366
Epoch: 1 40000/60000 Training loss: 0.074450
Epoch: 1 50000/60000 Training loss: 0.049310
Training loss: 0.087254
Test loss: 0.038911; Test accuracy: 9874/10000 (98.7%)

Epoch: 2 0/60000 Training loss: 0.052410
Epoch: 2 10000/60000 Training loss: 0.063537
Epoch: 2 20000/60000 Training loss: 0.086369
Epoch: 2 30000/60000 Training loss: 0.053253
Epoch: 2 40000/60000 Training loss: 0.020954
Epoch: 2 50000/60000 Training loss: 0.109202
Training loss: 0.062135
Test loss: 0.030847; Test accuracy: 9897/10000 (99.0%)

Epoch: 3 0/60000 Training loss: 0.046322
Epoch: 3 10000/60000 Training loss: 0.024858
Epoch: 3 20000/60000 Training loss: 0.033487
Epoch: 3 30000/60000 Training loss: 0.025190
Epoch: 3 40000/60000 Training loss: 0.011892
Epoch: 3 50000/60000 Training loss: 0.050640
Training loss: 0.049899
Test loss: 0.022765; Test accuracy: 9921/10000 (99.2%)

Epoch: 4 0/60000 Training loss: 0.055340
Epoch: 4 10000/60000 Training loss: 0.086282
Epoch: 4 20000/60000 Training loss: 0.011195
Epoch: 4 30000/60000 Training loss: 0.137969
Epoch: 4 40000/60000 Training loss: 0.024182
Epoch: 4 50000/60000 Training loss: 0.039072
Training loss: 0.042031
Test loss: 0.022873; Test accuracy: 9928/10000 (99.3%)

Epoch: 5 0/60000 Training loss: 0.023715
Epoch: 5 10000/60000 Training loss: 0.052942
Epoch: 5 20000/60000 Training loss: 0.015473
Epoch: 5 30000/60000 Training loss: 0.020188
Epoch: 5 40000/60000 Training loss: 0.008531
Epoch: 5 50000/60000 Training loss: 0.039417
Training loss: 0.036932
Test loss: 0.020113; Test accuracy: 9931/10000 (99.3%)

Epoch: 6 0/60000 Training loss: 0.023053
Epoch: 6 10000/60000 Training loss: 0.014960
Epoch: 6 20000/60000 Training loss: 0.026914
Epoch: 6 30000/60000 Training loss: 0.026459
Epoch: 6 40000/60000 Training loss: 0.005186
Epoch: 6 50000/60000 Training loss: 0.014852
Training loss: 0.032330
Test loss: 0.019576; Test accuracy: 9942/10000 (99.4%)

Epoch: 7 0/60000 Training loss: 0.023143
Epoch: 7 10000/60000 Training loss: 0.005761
Epoch: 7 20000/60000 Training loss: 0.004955
Epoch: 7 30000/60000 Training loss: 0.113002
Epoch: 7 40000/60000 Training loss: 0.024396
Epoch: 7 50000/60000 Training loss: 0.090016
Training loss: 0.028090
Test loss: 0.022185; Test accuracy: 9933/10000 (99.3%)

Epoch: 8 0/60000 Training loss: 0.007097
Epoch: 8 10000/60000 Training loss: 0.021954
Epoch: 8 20000/60000 Training loss: 0.044115
Epoch: 8 30000/60000 Training loss: 0.003208
Epoch: 8 40000/60000 Training loss: 0.013096
Epoch: 8 50000/60000 Training loss: 0.027626
Training loss: 0.025689
Test loss: 0.018970; Test accuracy: 9935/10000 (99.3%)

Epoch: 9 0/60000 Training loss: 0.030431
Epoch: 9 10000/60000 Training loss: 0.015935
Epoch: 9 20000/60000 Training loss: 0.002043
Epoch: 9 30000/60000 Training loss: 0.005300
Epoch: 9 40000/60000 Training loss: 0.005538
Epoch: 9 50000/60000 Training loss: 0.009122
Training loss: 0.022024
Test loss: 0.021809; Test accuracy: 9939/10000 (99.4%)

Epoch: 10 0/60000 Training loss: 0.005089
Epoch: 10 10000/60000 Training loss: 0.051903
Epoch: 10 20000/60000 Training loss: 0.008511
Epoch: 10 30000/60000 Training loss: 0.006586
Epoch: 10 40000/60000 Training loss: 0.027400
Epoch: 10 50000/60000 Training loss: 0.017273
Training loss: 0.021178
Test loss: 0.020386; Test accuracy: 9935/10000 (99.3%)

Epoch: 11 0/60000 Training loss: 0.001811
Epoch: 11 10000/60000 Training loss: 0.023744
Epoch: 11 20000/60000 Training loss: 0.000994
Epoch: 11 30000/60000 Training loss: 0.008550
Epoch: 11 40000/60000 Training loss: 0.046778
Epoch: 11 50000/60000 Training loss: 0.013121
Training loss: 0.018323
Test loss: 0.021538; Test accuracy: 9942/10000 (99.4%)

Optimized_param_vals:
Value: FrozenTrial(number=25, values=[0.01626817137002945], datetime_start=datetime.datetime(2022, 11, 4, 1, 22, 38, 233334), datetime_complete=datetime.datetime(2022, 11, 4, 1, 27, 3, 764516), params={'num_conv1_channels': 112, 'num_conv2_channels': 80, 'conv2_drop': 0.158451845708855, 'fc1_neurons': 150, 'optimizer': 'Adam', 'learning_rate': 0.00019454816172831765}, distributions={'num_conv1_channels': IntDistribution(high=128, log=False, low=16, step=16), 'num_conv2_channels': IntDistribution(high=128, log=False, low=16, step=16), 'conv2_drop': FloatDistribution(high=0.2, log=False, low=0.05, step=None), 'fc1_neurons': IntDistribution(high=200, log=False, low=10, step=10), 'optimizer': CategoricalDistribution(choices=('Adam', 'SGD')), 'learning_rate': FloatDistribution(high=0.001, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=25, state=TrialState.COMPLETE, value=None)
params
num_conv1_channels, 112
num_conv2_channels, 80
conv2_drop, 0.158451845708855
fc1_neurons, 150
optimizer, Adam
learning_rate, 0.00019454816172831765
[I 2022-11-04 06:11:15,099] Trial 99 finished with value: 0.018970075994729996 and parameters: {'num_conv1_channels': 96, 'num_conv2_channels': 96, 'conv2_drop': 0.18637705079141892, 'fc1_neurons': 160, 'optimizer': 'Adam', 'learning_rate': 0.00020433642977015916}. Best is trial 25 with value: 0.01626817137002945.
most important hyperparams
optimizer, 66.16624235252566
learning_rate, 20.221356515623103
num_conv1_channels, 4.919703348677335
fc1_neurons, 3.5382465262359637
num_conv2_channels, 3.5288980166744555
conv2_drop, 1.6255532402634851

Process finished with exit code 0
